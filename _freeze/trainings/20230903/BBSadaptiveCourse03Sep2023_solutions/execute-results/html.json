{
  "hash": "a466da71dc8c73bb975554da507179cc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Solutions to the exercises for the CEN 2023 pre-conference course 'Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact' on 3Sep2023\"\nauthor: \"Kaspar Rufibach (Roche), Marc Vandemeulebroecke (Novartis), Gernot Wassmer (rpact), Marcel Wolbers (Roche)\"\ndate: 2023-09-03\ndate-modified: last-modified\nexecute:\n  freeze: auto  # re-render only when source changes\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n    toc-title: Contents\n    toc-location: left\n    number-sections: true\n    number-depth: 2\n    code_download: true\n---\n\n\n# Purpose of this document {-}\n\nThis R markdown file contains the solutions to the exercises of the [CEN 2023](https://cen2023.github.io/home/index.html) pre-conference course [Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact](https://cen2023.github.io/home/courses.html#Advanced_group-sequential_and_adaptive_confirmatory_clinical_trial_designs,_with_R_practicals_using_rpact).  \n\nAll materials related to this course are available on the [BBS](http://www.bbsbasel.ch) webpage at this [link](https://baselbiometrics.github.io/home/docs/trainings/20230903/20230903_gsd_adaptive.html). Solutions to the exercises will also be available through that webpage after the course. \n\n# Load `rpact` {-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load rpact\nlibrary(rpact)\npackageVersion(\"rpact\") # version should be version 3.0 or higher\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '4.0.0'\n```\n\n\n:::\n\n```{.r .cell-code}\nsetLogLevel(\"DISABLED\") # disable progress messages from e.g. getAnalysisResults \n\n# Also load tictoc for timing of the simulations\nlibrary(tictoc)\n```\n:::\n\n\n# Exercise 1 (Group-sequential survival trial with efficacy and futility interim analyses) {-}\n\nAssume we plan a phase III, randomized, multicenter, open-label, two-arm trial with a time-to-event endpoint of OS. The **general assumptions for the sample size assessment** are:\n\n- 2:1 randomization.\n- Uniform recruitment of 480 patients over 10 months (48 per month). \n- The dropout rate is 5% in both arms over 12 months.\n\nThe **sample size section for OS** states that the following additional assumptions were made:\n\n- Exponentially distributed OS in the control arm with a median of 12 months.\n- Median OS improvement vs. control of 4.9 months (medians 16.9 vs. 12 months, i.e. a HR of approximately 0.71).\n- Log-rank test at a one-sided significance level of 0.025, power 80%.\n- One interim analyses for efficacy (IA) and one final analysis using the O\\'Brien-Fleming boundaries approximated using the Lan-DeMets method. The first IA will be performed after 60% of information. \n\n## Exercise 1a (Sample size calculation) {-}\n\nCalculate the required number of events and timing of analysis for OS using the information fraction of 60%. Use the `rpact` functions `getDesignGroupSequential` and `getSampleSizeSurvival`. \n\n**Solution:**\nWe perform calculations at a one-sided significance level of 2.5% which gives the same sample size but is more compatible with the futility interim added in Part 1b. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# basic parameters\ninfofrac <- c(0.6, 1)   # information fractions\nalpha <- 0.05 / 2       # one-sided\nbeta <- 0.2\naccrualTime <- c(0, 10)\naccrualIntensity <- 48  # 48 pts over 10 months\nrandoratio <- 2         # 2:1 randomization\nm2 <- 12                # median control\nm1 <- 16.9              # median treatment\ndo <- 0.05              # dropout same in both arms\ndoTime <- 12            # time at which dropout happens\n\nmaxn <- accrualIntensity * accrualTime[2]\n\n# Specify the group-sequential design \ndesign1 <- getDesignGroupSequential(sided = 1, alpha = alpha, beta = beta,\n    informationRates = infofrac, typeOfDesign = \"asOF\")\n\n# Calculate sample size for OS for this design\nsampleSizeOS1 <- getSampleSizeSurvival(design1,\n    allocationRatioPlanned = randoratio,    \n    median2 = m2, median1 = m1, \n    dropoutRate1 = do, dropoutRate2 = do, dropoutTime = doTime,\n    accrualTime = accrualTime, accrualIntensity = accrualIntensity)  \n\n# rpact summary\nsummary(sampleSizeOS1)\n```\n\n::: {.cell-output-display}\n*Sample size calculation for a survival endpoint*\n\nSequential analysis with a maximum of 2 looks (group sequential design), overall \nsignificance level 2.5% (one-sided).\nThe results were calculated for a two-sample logrank test, \nH0: hazard ratio = 1, H1: treatment median(1) = 16.9, control median(2) = 12, \nplanned allocation ratio = 2, accrual time = 10, accrual intensity = 48, \ndropout rate(1) = 0.05, dropout rate(2) = 0.05, dropout time = 12, power 80%.\n\n| Stage                                    |      1 |      2 |\n| ----- | ----- | ----- |\n| Planned information rate                 |    60% |   100% |\n| Efficacy boundary (z-value scale)        |  2.669 |  1.981 |\n| Cumulative power                         | 0.3123 | 0.8000 |\n| Number of subjects                       |  480.0 |  480.0 |\n| Expected number of subjects under H1     |  480.0 | |\n| Cumulative number of events              |  182.3 |  303.8 |\n| Analysis time                            |  15.82 |  28.67 |\n| Expected study duration                  |  24.65 | |\n| Cumulative alpha spent                   | 0.0038 | 0.0250 |\n| One-sided local significance level       | 0.0038 | 0.0238 |\n| Efficacy boundary (t)                    |  0.658 |  0.786 |\n| Exit probability for efficacy (under H0) | 0.0038 | |\n| Exit probability for efficacy (under H1) | 0.3123 | |\n\nLegend:\n\n* *(t)*: treatment effect scale\n\n:::\n:::\n\n\n## Exercise 1b (Addition of a futility interim analysis) {-}\n\nNow add an interim analysis for futility ONLY (i.e. no stopping for efficacy possible) after 30% of information where we stop the trial if the observed hazard ratio is above 1.\n\nHint: Use significance levels from design with efficacy only, add futility interim with minimal alpha-spending. The argument `userAlphaSpending` in `getDesignGroupSequential` helps.\n\n**Solution:**\n\nWe spend a minimal alpha of 0.00001 at the futility interim analysis and use the alpha-spending from the O'Brien-Fleming-type alpha-spending function for the efficacy interim and the final analysis. In rpact, the `futilityBounds` are specified on the $Z$-scale and an observed hazard ratio 1 at the futility interim corresponds to a $Z$-score of 0. This leads to the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add the futility using the sig levels computed above and \n# spending epsilon alpha at the futility\ndesign2 <- getDesignGroupSequential(informationRates = c(0.3, infofrac),\n                                    sided = 1, alpha = alpha, beta = beta,\n                                    typeOfDesign = \"asUser\", \n                                    userAlphaSpending = c(0.0001, design1$alphaSpent),\n                                    futilityBounds = c(0, -Inf),\n                                    bindingFutility = FALSE)\n\n# Calculate sample size for this design\nsampleSizeOS2 <- getSampleSizeSurvival(design2,\n    allocationRatioPlanned = randoratio,    \n    median2 = m2, median1 = m1, \n    dropoutRate1 = do, dropoutRate2 = do, dropoutTime = doTime,\n    accrualTime = accrualTime, accrualIntensity = accrualIntensity)  \n\n# rpact summary\nsummary(sampleSizeOS2)\n```\n\n::: {.cell-output-display}\n*Sample size calculation for a survival endpoint*\n\nSequential analysis with a maximum of 3 looks (group sequential design), overall \nsignificance level 2.5% (one-sided).\nThe results were calculated for a two-sample logrank test, \nH0: hazard ratio = 1, H1: treatment median(1) = 16.9, control median(2) = 12, \nplanned allocation ratio = 2, accrual time = 10, accrual intensity = 48, \ndropout rate(1) = 0.05, dropout rate(2) = 0.05, dropout time = 12, power 80%.\n\n| Stage                                    |       1 |       2 |       3 |\n| ----- | ----- | ----- | ----- |\n| Planned information rate                 |     30% |     60% |    100% |\n| Efficacy boundary (z-value scale)        |   3.719 |   2.672 |   1.981 |\n| Futility boundary (z-value scale)        |       0 |    -Inf | |\n| Cumulative power                         |  0.0166 |  0.3354 |  0.8000 |\n| Number of subjects                       |   480.0 |   480.0 |   480.0 |\n| Expected number of subjects under H1     |   480.0 | | |\n| Cumulative number of events              |    96.9 |   193.7 |   322.9 |\n| Analysis time                            |   10.12 |   16.72 |   31.74 |\n| Expected study duration                  |   25.38 | | |\n| Cumulative alpha spent                   | <0.0001 |  0.0038 |  0.0250 |\n| One-sided local significance level       | <0.0001 |  0.0038 |  0.0238 |\n| Efficacy boundary (t)                    |   0.449 |   0.665 |   0.791 |\n| Futility boundary (t)                    |   1.000 |          |\n| Overall exit probability (under H0)      |  0.5001 |  0.0037 | |\n| Overall exit probability (under H1)      |  0.0726 |  0.3188 | |\n| Exit probability for efficacy (under H0) | <0.0001 |  0.0037 | |\n| Exit probability for efficacy (under H1) |  0.0166 |  0.3188 | |\n| Exit probability for futility (under H0) |  0.5000 |       0 | |\n| Exit probability for futility (under H1) |  0.0561 |       0 | |\n\nLegend:\n\n* *(t)*: treatment effect scale\n\n:::\n:::\n\n\nWe see that by adding the futility interim we increase the maximal number of events from 303.827705 to 322.9028532. \n\n## Exercise 1c (Power loss associated with the futility interim analysis) {-}\n\nHow large is the power loss from adding this futility interim analysis, assuming we would not increase the number of events compared to the initial design above?\n\nTo compute the power loss of adding the futility, _conservatively_ assuming it will be adhered to, i.e. we compute the power of the design _with_ futility using the number of events of the design _without_ futility.\n\n**Solution:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# power of design with futility at the number of events without futility\npower <- getPowerSurvival(design2, allocationRatioPlanned = randoratio, \n    maxNumberOfEvents = ceiling(sampleSizeOS1$maxNumberOfEvents),\n    median2 = m2, median1 = m1, \n    dropoutRate1 = do, dropoutRate2 = do, dropoutTime = doTime,\n    accrualTime = accrualTime, accrualIntensity = accrualIntensity,\n    directionUpper = FALSE)\n\n# power, as compared to the specified 80%\npower$overallReject\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.776275\n```\n\n\n:::\n:::\n\n\nSo the power loss of adding the futility amounts to 0.023725.\n\n## Bonus Exercise 1d (Timing of OS events)  {-}\n\nHow many OS events would be expected to occur until exactly 16 and 24 months, respectively, from first patient randomized?\n\nHint: `getEventProbabilities`.\n\n**Solution:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Probability of an event until 16 months and 24 months  \nprobOS <- getEventProbabilities(time = c(16, 24), \n    allocationRatioPlanned = randoratio,    \n    lambda2 = getLambdaByMedian(m2),lambda1 = getLambdaByMedian(m1),\n    dropoutRate1 = do, dropoutRate2 = do, dropoutTime = doTime,\n    accrualTime = accrualTime, accrualIntensity = accrualIntensity)\nprobOS\n```\n\n::: {.cell-output-display}\n*Event probabilities at given time*\n\n*User defined parameters*\n\n* *Time*: 16.00, 24.00 \n* *Accrual time*: 10.00 \n* *Accrual intensity*: 48.0 \n* *lambda(1)*: 0.041 \n* *lambda(2)*: 0.0578 \n* *Planned allocation ratio*: 2 \n* *Drop-out rate (1)*: 0.050 \n* *Drop-out rate (2)*: 0.050 \n\n*Default parameters*\n\n* *kappa*: 1 \n* *Drop-out time*: 12.00 \n\n*Time and output*\n\n* *Hazard ratio*: 0.710 \n* *Maximum number of subjects*: 480 \n* *Cumulative event probabilities*: 0.3847, 0.5595 \n* *Event probabilities (1)*: 0.3506, 0.5193 \n* *Event probabilities (2)*: 0.4529, 0.6400 \n\n*Legend*\n\n* *(i)*: values of treatment arm i\n\n:::\n\n```{.r .cell-code}\n# Expected number of OS events \nmaxn * probOS$overallEventProbabilities\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 184.6677 268.5770\n```\n\n\n:::\n:::\n\n\nExpected number of events are 185 and 269 until months 16 and 24, respecticely.\n\n***\n\n# Exercise 2 (Adaptive trial with a continuous endpoint) {-}\n\nA confirmatory, randomized and blinded study of an investigational drug against Placebo is planned in mild to moderate Alzheimer's disease.\nThe primary endpoint is the change from baseline in ADAS-Cog, a neuropsychological test battery measuring cognitive abilities, assessed 6 months after treatment initiation.\nThe ADAS-Cog has a range of 0-70; we reverse its scale so that greater values are good.\nWe consider our primary endpoint as approximately normally distributed, and for simplicity we assume a known standard deviation of 10.\nWe believe that the improvement in the primary endpoint that can be achieved with the investigational drug is at least 4 points better than that under Placebo; and we want to have 80% chance of achieving a significant result if this is indeed the case.\nHowever, if the investigational drug is no better than Placebo, we want to have no more than 2.5% chance to claim success.\nThis yields a sample size of approximately  n=100  per treatment group for a trial with fixed sample size.\n\n\n## Exercise 2a (the \"alpha calculus\") {-}\n\nWe want to build in a \"sanity check\" mid-way through the trial. More precisely, we implement an interim analysis using the inverse normal method, with the following characteristics (all with respect to the primary endpoint):\n\n- Stop for futility if the investigational drug appears worse than Placebo\n\n- Stop for efficacy if the investigational drug appears \"very significantly better\" than Placebo ($p < 0.0001$)\n\nWhich set of $(\\alpha,\\alpha_0,\\alpha_1,\\alpha_2)$ satisfies these conditions?\n\nHint: Use `getDesignInverseNormal` with a user-defined alpha-spending function and a binding futility boundary.\n\n**Solution:** \n\nThe exercise specifies alpha=0.025, alpha0=0.5 (equivalent to a binding futility boundary at a $Z$-score of 0), and alpha1=0.0001. We compute alpha2 as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- getDesignInverseNormal(typeOfDesign = \"asUser\", userAlphaSpending = c(0.0001,0.025), \n  futilityBounds = 0, bindingFutility = TRUE)\nd\n```\n\n::: {.cell-output-display}\n*Design parameters and output of inverse normal combination test design*\n\n*User defined parameters*\n\n* *Type of design*: User defined alpha spending \n* *Futility bounds (binding)*: 0.000 \n* *Binding futility*: TRUE \n* *User defined alpha spending*: 0.0001, 0.0250 \n\n*Derived from user defined parameters*\n\n* *Maximum number of stages*: 2 \n* *Stages*: 1, 2 \n* *Information rates*: 0.500, 1.000 \n\n*Default parameters*\n\n* *Significance level*: 0.0250 \n* *Type II error rate*: 0.2000 \n* *Two-sided power*: FALSE \n* *Test*: one-sided \n* *Tolerance*: 1e-08 \n* *Type of beta spending*: none \n\n*Output*\n\n* *Cumulative alpha spending*: 0.0001, 0.0250 \n* *Critical values*: 3.719, 1.955 \n* *Stage levels (one-sided)*: 0.00010, 0.02531 \n\n:::\n:::\n\n\nThis yields $\\alpha_2$ = d\\$stageLevels[2] = 0.0253.\n\n**What regulatory issues could this raise?**\n\n**Solution**\nThe Regulator may not like that the final test is performed at a greater level ($\\alpha_2$) than the overall level ($\\alpha$). This is caused by cutting off a greater rejection region by the futility stop (right of $\\alpha_0$) than adding to it by the efficacy stop (left of $\\alpha_1$), and by compensating for this imbalance through a higher conditional error function ($\\alpha_2 > \\alpha$; so-called “buy-back alpha” from the futility stop).\n\n## Exercise 2b (early stopping and sample size adaptation) {-}\n\n 1. At the interim analysis after $n_1$ = 50 patients per group, we observe an average ADAS-Cog improvement of 4 points under the investigational drug and of 1 point under Placebo. Should we stop or continue the trial?\n\nHint: `getDataset` to define the input dataset and `getAnalysisResults` to analyse it.\n\n**Solution**\n\nWe should continue the trial, since our drug is neither worse nor very significantly better than Placebo:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- getDataset(means1 = 4, means2 = 1, \n                  stDev1 = 10, stDev2 = 10, \n                  n1 = 50, n2 = 50)\n\nresult1 <- getAnalysisResults(design = d, dataInput = dat, nPlanned = 100,normalApproximation = TRUE)\n\nsummary(result1)\n```\n\n::: {.cell-output-display}\n*Analysis results for a continuous endpoint*\n\nSequential analysis with 2 looks (inverse normal combination test design).\nThe results were calculated using a two-sample t-test (one-sided, alpha = 0.025), \nnormal approximation test, equal variances option.\nH0: mu(1) - mu(2) = 0 against H1: mu(1) - mu(2) > 0. \nThe conditional power calculation with planned sample size is based on \noverall effect = 3 and overall standard deviation = 10.\n\n| Stage                                  |                1 |                2 |\n| ----- | ----- | ----- |\n| Fixed weight                           |            0.707 |            0.707 |\n| Efficacy boundary (z-value scale)      |            3.719 |            1.955 |\n| Futility boundary (z-value scale)      |                0 | |\n| Cumulative alpha spent                 |          <0.0001 |           0.0250 |\n| Stage level                            |          <0.0001 |           0.0253 |\n| Cumulative effect size                 |            3.000 |                  \n| Cumulative (pooled) standard deviation |           10.000 |                  \n| Stage-wise test statistic              |            1.500 |                  \n| Stage-wise p-value                     |           0.0668 |                  \n| Inverse normal combination             |            1.500 |                  \n| Test action                            |         continue |                  \n| Conditional rejection probability      |           0.1030 |                  \n| Planned sample size                    |                  |              100 |\n| Conditional power                      |                  |           0.5931 |\n| 95% repeated confidence interval       |  [-4.438; 10.438]|                  \n| Repeated p-value                       |                  |                  \n:::\n:::\n\n\n$\\rightarrow$   $p_1=0.0668$, and $\\alpha_1=0.0001<0.0668<0.5=\\alpha_0$.\n\n\n 2. At the same time, there is a change in strategy, and we now want 90% power at an improvement of 4 points over placebo. Determine the sample size per treatment group for the second stage of the trial, in light of the interim results.\n\nHint: Calculate second stage sample size using `getSampleSizeMeans` with type I error equal to the conditional rejection probability from the previous part.\n\n**Solution**\n\nWe compute the sample size necessary for 90% conditional power; we round up and check:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetSampleSizeMeans(alpha=result1$conditionalRejectionProbabilities[1], beta = 0.1, \n  alternative = 4, stDev = 10, normalApproximation = TRUE)$nFixed\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 162.0456\n```\n\n\n:::\n\n```{.r .cell-code}\nresult2 <- getAnalysisResults(design = d, dataInput = dat, nPlanned = 164, thetaH1 = 4,\n  assumedStDev = 10, normalApproximation = TRUE)\n\nsummary(result2)\n```\n\n::: {.cell-output-display}\n*Analysis results for a continuous endpoint*\n\nSequential analysis with 2 looks (inverse normal combination test design).\nThe results were calculated using a two-sample t-test (one-sided, alpha = 0.025), \nnormal approximation test, equal variances option.\nH0: mu(1) - mu(2) = 0 against H1: mu(1) - mu(2) > 0. \nThe conditional power calculation with planned sample size is based on \nassumed effect = 4 and assumed standard deviation = 10.\n\n| Stage                                  |                1 |                2 |\n| ----- | ----- | ----- |\n| Fixed weight                           |            0.707 |            0.707 |\n| Efficacy boundary (z-value scale)      |            3.719 |            1.955 |\n| Futility boundary (z-value scale)      |                0 | |\n| Cumulative alpha spent                 |          <0.0001 |           0.0250 |\n| Stage level                            |          <0.0001 |           0.0253 |\n| Cumulative effect size                 |            3.000 |                  \n| Cumulative (pooled) standard deviation |           10.000 |                  \n| Stage-wise test statistic              |            1.500 |                  \n| Stage-wise p-value                     |           0.0668 |                  \n| Inverse normal combination             |            1.500 |                  \n| Test action                            |         continue |                  \n| Conditional rejection probability      |           0.1030 |                  \n| Planned sample size                    |                  |              164 |\n| Conditional power                      |                  |           0.9027 |\n| 95% repeated confidence interval       |  [-4.438; 10.438]|                  \n| Repeated p-value                       |                  |                  \n:::\n:::\n\n\n$\\rightarrow$ $n_2=82$ per treatment group\n\n## Exercise 2c (final inference) {-}\n\nIn the second stage of the trial, we observe an average ADAS-Cog improvement of only **3 points** under the investigational drug and of 1 point under Placebo.\n\n1. Can we reject the null hypothesis and claim superiority of the investigational drug over placebo?\n\n**Solution**\n\nUsing the inverse normal method as planned, we can reject the null hypothesis and claim superiority of the investigational drug over placebo.\nMore precisely, the combination test statistic after the second stage is 1.966, exceeding the critical value $u_{0.0253}=1.955$ (where $u_\\alpha$     is the $(1-\\alpha)$-quantile of $N(0,1)$).\nNote that we test at the local level $\\alpha_2=0.0253$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2 <- getDataset(means1 = c(4,3), means2 = c(1,1), \n                   stDev1 = c(10,10), stDev2 = c(10,10),\n                   n1 = c(50,82), n2 = c(50,82))\n\nsummary(getAnalysisResults(design = d, dataInput = dat2, normalApproximation = TRUE))\n```\n\n::: {.cell-output-display}\n*Analysis results for a continuous endpoint*\n\nSequential analysis with 2 looks (inverse normal combination test design).\nThe results were calculated using a two-sample t-test (one-sided, alpha = 0.025), \nnormal approximation test, equal variances option.\nH0: mu(1) - mu(2) = 0 against H1: mu(1) - mu(2) > 0.\n\n| Stage                                  |                1 |                2 |\n| ----- | ----- | ----- |\n| Fixed weight                           |            0.707 |            0.707 |\n| Efficacy boundary (z-value scale)      |            3.719 |            1.955 |\n| Futility boundary (z-value scale)      |                0 | |\n| Cumulative alpha spent                 |          <0.0001 |           0.0250 |\n| Stage level                            |          <0.0001 |           0.0253 |\n| Cumulative effect size                 |            3.000 |            2.379 |\n| Cumulative (pooled) standard deviation |           10.000 |            9.968 |\n| Stage-wise test statistic              |            1.500 |            1.281 |\n| Stage-wise p-value                     |           0.0668 |           0.1002 |\n| Inverse normal combination             |            1.500 |            1.966 |\n| Test action                            |         continue |           reject |\n| Conditional rejection probability      |           0.1030 |                  \n| 95% repeated confidence interval       |  [-4.438; 10.438]|  [0.014 ; 4.863 ]|\n| Repeated p-value                       |                  |                  \n| Final p-value                          |                  |           0.0243 |\n| Final confidence interval              |                  |    [0.014; 4.933]|\n| Median unbiased estimate               |                  |            2.450 |\n:::\n:::\n\n\n\n 2. Compute the overall (\"exact\") p-value and confidence interval for the adaptive trial.\n\n**Solution**\n\nFrom the commands above we also obtain: $p=0.02435; \\; CI=(0.014,4.93)$\n\n 3. What would a \"naive\" z-test have concluded, based on all observations and ignoring the adaptive nature of the trial? What is your interpretation of the situation?\n\n**Solution**\n\nA \"naive\" z-test would not have been able to reject the null hypothesis:\n    \n$$z = \\sqrt{\\frac{n_1 + n_2}{2}}\\frac{\\bar x - \\bar y}{\\sigma} = \\sqrt{\\frac{132}{2}} \\frac{\\frac{50\\cdot 4 + 82 \\cdot 3}{132}- 1}{10} = 1.9325 < 1.960 = u_{0.025}$$\n    \nIn rpact, use the following commands:\n    \n\n::: {.cell}\n\n```{.r .cell-code}\ndGS <- getDesignGroupSequential(typeOfDesign = \"asUser\", userAlphaSpending = c(0.0001,0.025),\n  futilityBounds = 0, bindingFutility = TRUE)\n\ndat3 <- getDataset(cumulativeMeans1 = c(4,(50*4+82*3)/132), cumulativeMeans2 = c(1,1),\n  cumulativeStDev1 = c(10,10), cumulativeStDev2 = c(10,10), \n  cumulativeN1 = c(50,132), cumulativeN2 = c(50,132))\n\nsummary(getAnalysisResults(design = dGS, dataInput = dat3, normalApproximation = TRUE))\n```\n\n::: {.cell-output-display}\n*Analysis results for a continuous endpoint*\n\nSequential analysis with 2 looks (group sequential design).\nThe results were calculated using a two-sample t-test (one-sided, alpha = 0.025), \nnormal approximation test, equal variances option.\nH0: mu(1) - mu(2) = 0 against H1: mu(1) - mu(2) > 0.\n\n| Stage                                  |                1 |                2 |\n| ----- | ----- | ----- |\n| Planned information rate               |              50% |             100% |\n| Efficacy boundary (z-value scale)      |            3.719 |            1.955 |\n| Futility boundary (z-value scale)      |                0 | |\n| Cumulative alpha spent                 |          <0.0001 |           0.0250 |\n| Stage level                            |          <0.0001 |           0.0253 |\n| Cumulative effect size                 |            3.000 |            2.379 |\n| Cumulative (pooled) standard deviation |           10.000 |           10.000 |\n| Overall test statistic                 |            1.500 |            1.933 |\n| Overall p-value                        |           0.0668 |           0.0266 |\n| Test action                            |         continue |           accept |\n| Conditional rejection probability      |           0.1030 |                  \n| 95% repeated confidence interval       |  [-4.438; 10.438]|  [-0.027; 4.785 ]|\n| Repeated p-value                       |                  |                  \n| Final p-value                          |                  |           0.0263 |\n| Final confidence interval              |                  |   [-0.027; 4.816]|\n| Median unbiased estimate               |                  |            2.390 |\n:::\n:::\n\n\nNote that the definition of dat3 with the \"cumulative\" commands is necessary because otherwise always a \"global\" variance (accounting for the mean difference in the stages) is calculated. \n\nHere we ignore the adaptive nature of the trial: we lump all data together (ignoring the sample size adaptation), and we test at the nominal level $\\alpha =0.025$ (ignoring the possibility of early stopping). The second stage of the trial, showing less of a treatment effect, carries greater weight in this \"naive\" (that is, incorrect) version of the test. Note that it can go both ways: in other examples, the adaptive (correct) version of the test may be the one that fails to reject the null hypothesis. In less borderline situations, both tests will lead to the same conclusion. Proposals have been made in the literature for dealing with borderline situations.\n\n***\n\n# Exercise 3 (Sample size calculation for testing proportions) {-}\n\nSuppose a trial should be conducted in 3 stages where at the first stage 50%, at the second stage 75%, and at the final stage 100% of the information should be observed. O'Brien-Fleming boundaries should be used with one-sided $\\alpha = 0.025$ and non-binding futility bounds 0 and 0.5 for the first and the second stage, respectively, on the z-value scale.\n\nThe endpoints are binary (failure rates) and should be compared in a parallel group design, i.e., the null hypothesis to be tested is\n$H_0:\\pi_1 - \\pi_2 = 0\\,,$ which is tested against the alternative $H_1: \\pi_1 - \\pi_2 < 0\\,.$\n\n## Exercise 3a (sample size calculation) {-}\n\nWhat is the necessary sample size to achieve 90% power if the failure rates are assumed to be $\\pi_1 = 0.40$ and $\\pi_2 = 0.60$? What is the optimum allocation ratio?\n\n**Solution**\n\nThe summary command provides a table for the study design parameters: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndGS <- getDesignGroupSequential(informationRates = c(0.5,0.75,1), alpha = 0.025, beta = 0.1,\n    typeOfDesign = \"OF\", futilityBounds = c(0,0.5))\nr <- getSampleSizeRates(dGS, pi1 = 0.4, pi2 = 0.6)\n\nsummary(r)\n```\n\n::: {.cell-output-display}\n*Sample size calculation for a binary endpoint*\n\nSequential analysis with a maximum of 3 looks (group sequential design), overall \nsignificance level 2.5% (one-sided).\nThe results were calculated for a two-sample test for rates (normal approximation),\nH0: pi(1) - pi(2) = 0, H1: treatment rate pi(1) = 0.4, control rate pi(2) = 0.6, \npower 90%.\n\n| Stage                                    |      1 |      2 |      3 |\n| ----- | ----- | ----- | ----- |\n| Planned information rate                 |    50% |    75% |   100% |\n| Efficacy boundary (z-value scale)        |  2.863 |  2.337 |  2.024 |\n| Futility boundary (z-value scale)        |      0 |  0.500 | |\n| Cumulative power                         | 0.2958 | 0.6998 | 0.9000 |\n| Number of subjects                       |  133.1 |  199.7 |  266.3 |\n| Expected number of subjects under H1     |  198.3 | | |\n| Cumulative alpha spent                   | 0.0021 | 0.0105 | 0.0250 |\n| One-sided local significance level       | 0.0021 | 0.0097 | 0.0215 |\n| Efficacy boundary (t)                    | -0.248 | -0.165 | -0.124 |\n| Futility boundary (t)                    |  0.000 | -0.035 | |\n| Overall exit probability (under H0)      | 0.5021 | 0.2275 | |\n| Overall exit probability (under H1)      | 0.3058 | 0.4095 | |\n| Exit probability for efficacy (under H0) | 0.0021 | 0.0083 | |\n| Exit probability for efficacy (under H1) | 0.2958 | 0.4040 | |\n| Exit probability for futility (under H0) | 0.5000 | 0.2191 | |\n| Exit probability for futility (under H1) | 0.0100 | 0.0056 | |\n\nLegend:\n\n* *(t)*: treatment effect scale\n\n:::\n:::\n\n\nThe optimum allocation ratio is 1 in this case but calculated numerically, therefore slightly unequal 1:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- getSampleSizeRates(dGS, pi1 = 0.4, pi2 = 0.6, allocationRatioPlanned = 0)\nr$allocationRatioPlanned\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9999976\n```\n\n\n:::\n\n```{.r .cell-code}\nround(r$allocationRatioPlanned,5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n\n## Exercise 3b (boundary plots) {-}\n\nIllustrate the decision boundaries on different scales.\n\n**Solution**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(r, type = 1)\n```\n\n::: {.cell-output-display}\n![](BBSadaptiveCourse03Sep2023_solutions_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(r, type = 2)\n```\n\n::: {.cell-output-display}\n![](BBSadaptiveCourse03Sep2023_solutions_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(r, type = 3)\n```\n\n::: {.cell-output-display}\n![](BBSadaptiveCourse03Sep2023_solutions_files/figure-html/unnamed-chunk-13-3.png){width=672}\n:::\n:::\n\n\n## Exercise 3c (power assessment) {-}\n\nSuppose that $N = 280$ subjects were planned for the study. What is the power if the failure rate in the active treatment group is $\\pi_1 = 0.50$?\n\n**Solution**\n\nThe power is much reduced as compared to the case pi1 = 0.4 (where it exceeds 90%):\n  \n\n\n::: {.cell}\n\n```{.r .cell-code}\npower <- getPowerRates(dGS, maxNumberOfSubjects = 280, pi1 = c(0.4, 0.5), pi2 = 0.6, \n      directionUpper = FALSE)\n\npower$overallReject\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.914045 0.377853\n```\n\n\n:::\n:::\n\n\n## Exercise 3d (power illustration) {-}\n\nIllustrate power, expected sample size, and early/futility stop for a range of alternative values.\n\n**Solution**\n\nSpecifying pi1 = c(0.3,0.6) provides a range of power and ANS values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npower <- getPowerRates(dGS, maxNumberOfSubjects = 280, pi1 = c(0.3,0.6), pi2 = 0.6,\n     directionUpper = FALSE)\n\nplot(power, type = 6)\n```\n\n::: {.cell-output-display}\n![](BBSadaptiveCourse03Sep2023_solutions_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n***\n\n# Exercise 4 (Sample size reassessment for testing proportions) {-}\n\nUsing an adaptive design, the sample size from Example 3 in the last interim can be increased up to a 4-fold of the originally planned sample size for the last stage. Conditional power 90% *based on the observed effect sizes (failure rates)* is used to increase the sample size.\n\n## Exercise 4a (assess power) {-}\n\nUse the inverse normal method to allow for the sample size increase and compare the test characteristics with the group sequential design from Example 3.\n\n**Solution**\n\nDefine the inverse normal design and perform two simulations, one without and one with SSR:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndIN <- getDesignInverseNormal(informationRates = c(0.5,0.75,1), alpha = 0.025, beta = 0.1,\n    futilityBounds = c(0,0.5))\n\nmaxiter <- 1000\n\nsim1 <- getSimulationRates(dIN, plannedSubjects = c(140,210,280), pi1 = seq(0.4,0.5,0.01), pi2 = 0.6,\n  directionUpper = FALSE, maxNumberOfIterations = maxiter, conditionalPower = 0.9,\n  minNumberOfSubjectsPerStage = c(140,70,70), maxNumberOfSubjectsPerStage = c(140,70,70),\n  seed = 1234)\n\nsim2 <- getSimulationRates(dIN, plannedSubjects = c(140,210,280), pi1 = seq(0.4,0.5,0.01), pi2 = 0.6,\n  directionUpper = FALSE, maxNumberOfIterations = maxiter, conditionalPower = 0.9, \n  minNumberOfSubjectsPerStage = c(NA,70,70), maxNumberOfSubjectsPerStage = c(NA,70,4*70),\n  seed = 5678)\n```\n:::\n\n\nNote that the sample sizes will be calculated under the assumption that the *conditional power for the subsequent stage* is 90%. If the resulting sample size is larger, the upper bound (4*70 = 280) is used. \n\n## Exercise 4b (illustrate power difference) {-}\n\nIllustrate the gain in power when using the adaptive sample size recalculation.\n\n**Solution**\n\nWe use ggplot2 for doing this. First, a data set df is defined with the additional variable SSR. Using mytheme and the following ggplots commands, the difference in power and ASN of the two strategies is illustrated. It shows that at least for effect difference > 0.15 an overall power of more than around 85% can be achieved with the proposed sample size recalculation strategy.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\ndataSim1 <- as.data.frame(sim1, niceColumnNamesEnabled = FALSE)\ndataSim2 <- as.data.frame(sim2, niceColumnNamesEnabled = FALSE)\n\ndataSim1$SSR <- rep(\"no SSR\", nrow(dataSim1))\ndataSim2$SSR <- rep(\"SSR\", nrow(dataSim2))\ndf <- rbind(dataSim1, dataSim2)\n\nmyTheme = theme(\n  axis.title.x = element_text(size = 12), axis.text.x = element_text(size = 12),\n  axis.title.y = element_text(size = 12), axis.text.y = element_text(size = 12),\n  plot.title = element_text(size = 14,hjust = 0.5), \n    plot.subtitle = element_text(size = 12,hjust = 0.5))\n\np <- ggplot(data = df,aes(x = effect,y = overallReject, group = SSR, color = SSR)) +\n  geom_line(size = 1.1) +\n  geom_line(aes(x = effect,y = expectedNumberOfSubjects/400, group = SSR, color = SSR), size = 1.1, \n    linetype = \"dashed\") +\n  scale_y_continuous( \"Power\",  sec.axis = sec_axis(~ . * 400, name = \"ASN\"), limits = c(0.2,1)) +\n  theme_classic() +  xlab(\"effect\") +  ggtitle(\"Power and ASN\",\"Power solid, ASN dashed\") +\n  geom_hline(size = 0.5, yintercept = 0.8, linetype = \"dotted\") +\n  geom_hline(size = 0.5, yintercept = 0.9, linetype = \"dotted\") +\n  geom_vline(size = 0.5, xintercept = c(-0.2, -0.15), linetype = \"dashed\") +\n  myTheme\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(p)\n```\n\n::: {.cell-output-display}\n![](BBSadaptiveCourse03Sep2023_solutions_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Note: for saving the plot, you could e.g. use the commented code below\n# ggplot2::ggsave(filename = \"C:/yourdirectory/comparison.png\",\n#        plot = ggplot2::last_plot(), device = NULL, path = NULL,\n#        scale = 1.2, width = 20, height = 12, units = \"cm\", dpi = 600, limitsize = TRUE)\n```\n:::\n\n\n\n## Exercise 4c (histogram of sample sizes) {-}\n\nCreate a histogram for the attained sample size of the study when using the adaptive sample size recalculation. How often will the maximum sample size be achieved?\n\n\n**Solution**\n\nWith the getData command the simulation results are obtained. Depending on pi1, you can create the histogram of the simulated total sample size \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\n\nsimdata<- getData(sim2)\nstr(simdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t24488 obs. of  19 variables:\n $ iterationNumber          : num  1 1 2 3 4 4 5 6 6 6 ...\n $ stageNumber              : num  1 2 1 1 1 2 1 1 2 3 ...\n $ pi1                      : num  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 ...\n $ pi2                      : num  0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 ...\n $ numberOfSubjects         : num  140 70 140 140 140 70 140 140 70 280 ...\n $ numberOfCumulatedSubjects: num  140 210 140 140 140 210 140 140 210 490 ...\n $ rejectPerStage           : num  0 1 1 1 0 1 1 0 0 1 ...\n $ futilityPerStage         : num  0 0 0 0 0 0 0 0 0 0 ...\n $ testStatistic            : num  2.7 3.45 3.39 3.38 2.22 ...\n $ testStatisticsPerStage   : num  2.7 2.15 3.39 3.38 2.22 ...\n $ overallRate1             : num  0.386 0.381 0.386 0.343 0.343 ...\n $ overallRate2             : num  0.614 0.619 0.671 0.629 0.529 ...\n $ stagewiseRates1          : num  0.386 0.371 0.386 0.343 0.343 ...\n $ stagewiseRates2          : num  0.614 0.629 0.671 0.629 0.529 ...\n $ sampleSizesPerStage1     : num  70 35 70 70 70 35 70 70 35 140 ...\n $ sampleSizesPerStage2     : num  70 35 70 70 70 35 70 70 35 140 ...\n $ trialStop                : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...\n $ conditionalPowerAchieved : num  NA 0.959 NA NA NA ...\n $ pValue                   : num  0.00342 0.015722 0.000354 0.00036 0.013353 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nsimPart <- simdata[simdata$pi1 == 0.5,] \ntic()\noverallSampleSizes <- sapply(1:maxiter, function(i) sum(simPart[simPart$iterationNumber==i,]$numberOfSubjects))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.14 sec elapsed\n```\n\n\n:::\n\n```{.r .cell-code}\n# tic()\n# overallSampleSizes <- numeric(maxiter)\n# for (i in 1:maxiter) overallSampleSizes[i] <- sum(simPart[simPart$iterationNumber==i,]$numberOfSubjects)\n# toc()\n\nhist(overallSampleSizes)\n```\n\n::: {.cell-output-display}\n![](BBSadaptiveCourse03Sep2023_solutions_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nHow often the maximum sample size is reached can be obtained as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimdata<- getData(sim2)\n\nsimdataPart <- simdata[simdata$pi1 == 0.5,] \n\nsubjectsRange <- cut(simdataPart$numberOfSubjects, c(69, 70, 139, 140, 210, 279, 280))\n\nround(prop.table(table(simdataPart$stageNumber,subjectsRange), margin = 1)*100,1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   subjectsRange\n    (69,70] (70,139] (139,140] (140,210] (210,279] (279,280]\n  1     0.0      0.0     100.0       0.0       0.0       0.0\n  2   100.0      0.0       0.0       0.0       0.0       0.0\n  3     0.0      9.0       0.3       8.8       4.7      77.2\n```\n\n\n:::\n:::\n\n\n***\n\n# Exercise 5 (Multi-armed design with continuous endpoint) {-}\n\nSuppose a trial is conducted with three active treatment arms (+ one control arm).\nAn adaptive design using the equally weighted inverse normal method with two interim analyses using O'Brien & Fleming boundaries is chosen where in both interim analyses a selection of treatment arms is foreseen (overall $\\alpha = 0.025$ one-sided).\nIt is decided to test the intersection tests in the closed system of hypotheses with Dunnett's test. In the designing stage, it was decided to conduct the study with 20 patients per treatment arm and stage where at\ninterim the sample size can be redefined.\n\n## Exercise 5a (First stage and conditional power) {-}\n\n\nSuppose, at the first stage, the following results were obtained:\n\n| arm | n | mean | std |\n| ----- | ----- | ----- | ----- |\n| 1 | 19 | 3.11 | 1.77 |\n| 2 | 22 | 3.87 | 1.23 |\n| 3 | 23 | 4.12 | 1.64 |\n| control | 21 | 3.02 | 1.72 |\n\nPerform the closed test and assess the conditional power in order to decide which treatment arm(s) should be selected and if the sample size should be redefined.\n\n**Solution**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataExample <- getDataset(\n  n1      = c(19),\n  n2      = c(22),\n  n3      = c(23),\n  n4      = c(21),\n  means1  = c(3.11),\n  means2  = c(3.87),\n  means3  = c(4.12),\n  means4  = c(3.02),\n  stDevs1 = c(1.77),\n  stDevs2 = c(1.23),\n  stDevs3 = c(1.64),\n  stDevs4 = c(1.72)\n)\n\nalpha <- 0.025\nintersectionTest <- \"Dunnett\"\nvarianceOption <- \"overallPooled\"\nnormalApproximation <- FALSE\n\ndesign <- getDesignInverseNormal(kMax = 3, alpha = alpha, typeOfDesign = \"OF\")\n\nstageResults <- getAnalysisResults(design = design,\n  dataInput = dataExample, thetaH0 = 0, stage = 1,\n  directionUpper = TRUE, normalApproximation = normalApproximation,\n  intersectionTest = intersectionTest, varianceOption = varianceOption,\n  nPlanned = c(40, 40))\n\nsummary(stageResults)\n```\n\n::: {.cell-output-display}\n*Multi-arm analysis results for a continuous endpoint (3 active arms vs. control)*\n\nSequential analysis with 3 looks (inverse normal combination test design).\nThe results were calculated using a multi-arm t-test (one-sided, alpha = 0.025), \nDunnett intersection test, overall pooled variances option.\nH0: mu(i) - mu(control) = 0 against H1: mu(i) - mu(control) > 0. \nThe conditional power calculation with planned sample size is based on \noverall effect: thetaH1(1) = 0.09, thetaH1(2) = 0.85, thetaH1(3) = 1.1 and \noverall standard deviation: sd(1) = 1.74, sd(2) = 1.49, sd(3) = 1.68.\n\n| Stage                                     |               1 |               2 |               3 |\n| ----- | ----- | ----- | ----- |\n| Fixed weight                              |           0.577 |           0.577 |           0.577 |\n| Efficacy boundary (z-value scale)         |           3.471 |           2.454 |           2.004 |\n| Cumulative alpha spent                    |          0.0003 |          0.0072 |          0.0250 |\n| Stage level                               |          0.0003 |          0.0071 |          0.0225 |\n| Cumulative effect size (1)                |           0.090 |                 |                 \n| Cumulative effect size (2)                |           0.850 |                 |                 \n| Cumulative effect size (3)                |           1.100 |                 |                 \n| Cumulative (pooled) standard deviation    |           1.597 |                 |                 \n| Stage-wise test statistic (1)             |           0.178 |                 |                 \n| Stage-wise test statistic (2)             |           1.745 |                 |                 \n| Stage-wise test statistic (3)             |           2.283 |                 |                 \n| Stage-wise p-value (1)                    |          0.4296 |                 |                 \n| Stage-wise p-value (2)                    |          0.0424 |                 |                 \n| Stage-wise p-value (3)                    |          0.0125 |                 |                 \n| Adjusted stage-wise p-value (1, 2, 3)     |          0.0325 |                 |                 \n| Adjusted stage-wise p-value (1, 2)        |          0.0751 |                 |                 \n| Adjusted stage-wise p-value (1, 3)        |          0.0232 |                 |                 \n| Adjusted stage-wise p-value (2, 3)        |          0.0231 |                 |                 \n| Adjusted stage-wise p-value (1)           |          0.4296 |                 |                 \n| Adjusted stage-wise p-value (2)           |          0.0424 |                 |                 \n| Adjusted stage-wise p-value (3)           |          0.0125 |                 |                 \n| Overall adjusted test statistic (1, 2, 3) |           1.845 |                 |                 \n| Overall adjusted test statistic (1, 2)    |           1.439 |                 |                 \n| Overall adjusted test statistic (1, 3)    |           1.991 |                 |                 \n| Overall adjusted test statistic (2, 3)    |           1.994 |                 |                 \n| Overall adjusted test statistic (1)       |           0.177 |                 |                 \n| Overall adjusted test statistic (2)       |           1.724 |                 |                 \n| Overall adjusted test statistic (3)       |           2.240 |                 |                 \n| Test action: reject (1)                   |           FALSE |                 |                 \n| Test action: reject (2)                   |           FALSE |                 |                 \n| Test action: reject (3)                   |           FALSE |                 |                 \n| Conditional rejection probability (1)     |          0.0101 |                 |                 \n| Conditional rejection probability (2)     |          0.0831 |                 |                 \n| Conditional rejection probability (3)     |          0.1432 |                 |                 \n| Planned sample size                       |                 |              40 |              40 |\n| Conditional power (1)                     |                 |          0.0009 |          0.0182 |\n| Conditional power (2)                     |                 |          0.4102 |          0.8723 |\n| Conditional power (3)                     |                 |          0.6722 |          0.9652 |\n| 95% repeated confidence interval (1)      |       [-1.897; ]|                 |                 \n| 95% repeated confidence interval (2)      |  [-1.065; 2.765]|                 |                 \n| 95% repeated confidence interval (3)      |       [-0.794; ]|                 |                 \n| Repeated p-value (1)                      |            >0.5 |                 |                 \n| Repeated p-value (2)                      |          0.2633 |                 |                 \n| Repeated p-value (3)                      |          0.1794 |                 |                 \n\nLegend:\n\n* *(i)*: results of treatment arm i vs. control arm\n* *(i, j, ...)*: comparison of treatment arms 'i, j, ...' vs. control arm\n\n:::\n:::\n\n\n\n## Exercise 5b (Second stage) {-}\n\nSuppose it was decided to drop treatment arm 1 for stage 2 and leave the sample size for the remaining arms unchanged. For the second stage, the following results were obtained:\n\n| arm | n | mean | std |\n| ----- | ----- | ----- | ----- |\n| 2 | 23 | 3.66 | 1.11 |\n| 3 | 19 | 3.98 | 1.21 |\n| control | 22 | 2.99 | 1.82 |\n\nPerform the closed test and discuss whether or not to stop the study and determine overall $p\\,$-values and confidence intervals.\n\n**Solution**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataExample <- getDataset(\n  n1      = c(19, NA),\n  n2      = c(22, 23),\n  n3      = c(23, 19),\n  n4      = c(21, 22),\n  means1  = c(3.11, NA),\n  means2  = c(3.87, 3.66),\n  means3  = c(4.12, 3.98),\n  means4  = c(3.02, 2.99),\n  stDevs1 = c(1.77, NA),\n  stDevs2 = c(1.23, 1.11),\n  stDevs3 = c(1.64, 1.21),\n  stDevs4 = c(1.72, 1.82)\n)\n\nstageResults <- getAnalysisResults(design = design,\n  dataInput = dataExample, thetaH0 = 0, stage = 2,\n  directionUpper = TRUE, normalApproximation = normalApproximation,\n  intersectionTest = intersectionTest, varianceOption = varianceOption)\n\nsummary(stageResults)\n```\n\n::: {.cell-output-display}\n*Multi-arm analysis results for a continuous endpoint (3 active arms vs. control)*\n\nSequential analysis with 3 looks (inverse normal combination test design).\nThe results were calculated using a multi-arm t-test (one-sided, alpha = 0.025), \nDunnett intersection test, overall pooled variances option.\nH0: mu(i) - mu(control) = 0 against H1: mu(i) - mu(control) > 0.\n\n| Stage                                     |               1 |               2 |               3 |\n| ----- | ----- | ----- | ----- |\n| Fixed weight                              |           0.577 |           0.577 |           0.577 |\n| Efficacy boundary (z-value scale)         |           3.471 |           2.454 |           2.004 |\n| Cumulative alpha spent                    |          0.0003 |          0.0072 |          0.0250 |\n| Stage level                               |          0.0003 |          0.0071 |          0.0225 |\n| Cumulative effect size (1)                |           0.090 |                 |                 \n| Cumulative effect size (2)                |           0.850 |           0.758 |                 \n| Cumulative effect size (3)                |           1.100 |           1.052 |                 \n| Cumulative (pooled) standard deviation    |           1.597 |           1.468 |                 \n| Stage-wise test statistic (1)             |           0.178 |                 |                 \n| Stage-wise test statistic (2)             |           1.745 |           1.582 |                 \n| Stage-wise test statistic (3)             |           2.283 |           2.226 |                 \n| Stage-wise p-value (1)                    |          0.4296 |                 |                 \n| Stage-wise p-value (2)                    |          0.0424 |          0.0594 |                 \n| Stage-wise p-value (3)                    |          0.0125 |          0.0149 |                 \n| Adjusted stage-wise p-value (1, 2, 3)     |          0.0325 |          0.0274 |                 \n| Adjusted stage-wise p-value (1, 2)        |          0.0751 |          0.0594 |                 \n| Adjusted stage-wise p-value (1, 3)        |          0.0232 |          0.0149 |                 \n| Adjusted stage-wise p-value (2, 3)        |          0.0231 |          0.0274 |                 \n| Adjusted stage-wise p-value (1)           |          0.4296 |                 |                 \n| Adjusted stage-wise p-value (2)           |          0.0424 |          0.0594 |                 \n| Adjusted stage-wise p-value (3)           |          0.0125 |          0.0149 |                 \n| Overall adjusted test statistic (1, 2, 3) |           1.845 |           2.662 |                 \n| Overall adjusted test statistic (1, 2)    |           1.439 |           2.121 |                 \n| Overall adjusted test statistic (1, 3)    |           1.991 |           2.945 |                 \n| Overall adjusted test statistic (2, 3)    |           1.994 |           2.767 |                 \n| Overall adjusted test statistic (1)       |           0.177 |                 |                 \n| Overall adjusted test statistic (2)       |           1.724 |           2.322 |                 \n| Overall adjusted test statistic (3)       |           2.240 |           3.121 |                 \n| Test action: reject (1)                   |           FALSE |           FALSE |                 \n| Test action: reject (2)                   |           FALSE |           FALSE |                 \n| Test action: reject (3)                   |           FALSE |            TRUE |                 \n| Conditional rejection probability (1)     |          0.0101 |                 |                 \n| Conditional rejection probability (2)     |          0.0831 |          0.3184 |                 \n| Conditional rejection probability (3)     |          0.1432 |          0.6154 |                 \n| 95% repeated confidence interval (1)      |       [-1.897; ]|                 |                 \n| 95% repeated confidence interval (2)      |  [-1.065; 2.765]|  [-0.203; 1.716]|                 \n| 95% repeated confidence interval (3)      |  [-0.794;      ]|  [0.066 ; 2.022]|                 \n| Repeated p-value (1)                      |            >0.5 |                 |                 \n| Repeated p-value (2)                      |          0.2633 |          0.0476 |                 \n| Repeated p-value (3)                      |          0.1794 |          0.0162 |                 \n\nLegend:\n\n* *(i)*: results of treatment arm i vs. control arm\n* *(i, j, ...)*: comparison of treatment arms 'i, j, ...' vs. control arm\n\n:::\n:::\n\n\n## Exercise 5c (Intersection tests) {-}\n\nWould the Bonferroni and the Simes test intersection tests provide the same results?\n\n**Solution**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstageResults <- getAnalysisResults(design = design,\n  dataInput = dataExample, thetaH0 = 0, stage = 2,\n  directionUpper = TRUE, normalApproximation = normalApproximation,\n  intersectionTest = \"Bonferroni\", varianceOption = varianceOption)\nsummary(stageResults)\n```\n\n::: {.cell-output-display}\n*Multi-arm analysis results for a continuous endpoint (3 active arms vs. control)*\n\nSequential analysis with 3 looks (inverse normal combination test design).\nThe results were calculated using a multi-arm t-test (one-sided, alpha = 0.025), \nBonferroni intersection test, overall pooled variances option.\nH0: mu(i) - mu(control) = 0 against H1: mu(i) - mu(control) > 0.\n\n| Stage                                     |               1 |               2 |               3 |\n| ----- | ----- | ----- | ----- |\n| Fixed weight                              |           0.577 |           0.577 |           0.577 |\n| Efficacy boundary (z-value scale)         |           3.471 |           2.454 |           2.004 |\n| Cumulative alpha spent                    |          0.0003 |          0.0072 |          0.0250 |\n| Stage level                               |          0.0003 |          0.0071 |          0.0225 |\n| Cumulative effect size (1)                |           0.090 |                 |                 \n| Cumulative effect size (2)                |           0.850 |           0.758 |                 \n| Cumulative effect size (3)                |           1.100 |           1.052 |                 \n| Cumulative (pooled) standard deviation    |           1.597 |           1.468 |                 \n| Stage-wise test statistic (1)             |           0.178 |                 |                 \n| Stage-wise test statistic (2)             |           1.745 |           1.582 |                 \n| Stage-wise test statistic (3)             |           2.283 |           2.226 |                 \n| Stage-wise p-value (1)                    |          0.4296 |                 |                 \n| Stage-wise p-value (2)                    |          0.0424 |          0.0594 |                 \n| Stage-wise p-value (3)                    |          0.0125 |          0.0149 |                 \n| Adjusted stage-wise p-value (1, 2, 3)     |          0.0376 |          0.0297 |                 \n| Adjusted stage-wise p-value (1, 2)        |          0.0848 |          0.0594 |                 \n| Adjusted stage-wise p-value (1, 3)        |          0.0251 |          0.0149 |                 \n| Adjusted stage-wise p-value (2, 3)        |          0.0251 |          0.0297 |                 \n| Adjusted stage-wise p-value (1)           |          0.4296 |                 |                 \n| Adjusted stage-wise p-value (2)           |          0.0424 |          0.0594 |                 \n| Adjusted stage-wise p-value (3)           |          0.0125 |          0.0149 |                 \n| Overall adjusted test statistic (1, 2, 3) |           1.779 |           2.591 |                 \n| Overall adjusted test statistic (1, 2)    |           1.374 |           2.074 |                 \n| Overall adjusted test statistic (1, 3)    |           1.959 |           2.922 |                 \n| Overall adjusted test statistic (2, 3)    |           1.959 |           2.718 |                 \n| Overall adjusted test statistic (1)       |           0.177 |                 |                 \n| Overall adjusted test statistic (2)       |           1.724 |           2.322 |                 \n| Overall adjusted test statistic (3)       |           2.240 |           3.121 |                 \n| Test action: reject (1)                   |           FALSE |           FALSE |                 \n| Test action: reject (2)                   |           FALSE |           FALSE |                 \n| Test action: reject (3)                   |           FALSE |            TRUE |                 \n| Conditional rejection probability (1)     |          0.0101 |                 |                 \n| Conditional rejection probability (2)     |          0.0756 |          0.2954 |                 \n| Conditional rejection probability (3)     |          0.1317 |          0.5764 |                 \n| 95% repeated confidence interval (1)      |  [-1.901; 2.081]|                 |                 \n| 95% repeated confidence interval (2)      |  [-1.068; 2.768]|  [-0.227; 1.747]|                 \n| 95% repeated confidence interval (3)      |  [-0.798; 2.998]|  [0.041 ; 2.051]|                 \n| Repeated p-value (1)                      |            >0.5 |                 |                 \n| Repeated p-value (2)                      |          0.2789 |          0.0518 |                 \n| Repeated p-value (3)                      |          0.1915 |          0.0189 |                 \n\nLegend:\n\n* *(i)*: results of treatment arm i vs. control arm\n* *(i, j, ...)*: comparison of treatment arms 'i, j, ...' vs. control arm\n\n:::\n\n```{.r .cell-code}\nstageResults <- getAnalysisResults(design = design,\n  dataInput = dataExample, thetaH0 = 0, stage = 2,\n  directionUpper = TRUE, normalApproximation = normalApproximation,\n  intersectionTest = \"Simes\", varianceOption = varianceOption)\nsummary(stageResults)\n```\n\n::: {.cell-output-display}\n*Multi-arm analysis results for a continuous endpoint (3 active arms vs. control)*\n\nSequential analysis with 3 looks (inverse normal combination test design).\nThe results were calculated using a multi-arm t-test (one-sided, alpha = 0.025), \nSimes intersection test, overall pooled variances option.\nH0: mu(i) - mu(control) = 0 against H1: mu(i) - mu(control) > 0.\n\n| Stage                                     |               1 |               2 |               3 |\n| ----- | ----- | ----- | ----- |\n| Fixed weight                              |           0.577 |           0.577 |           0.577 |\n| Efficacy boundary (z-value scale)         |           3.471 |           2.454 |           2.004 |\n| Cumulative alpha spent                    |          0.0003 |          0.0072 |          0.0250 |\n| Stage level                               |          0.0003 |          0.0071 |          0.0225 |\n| Cumulative effect size (1)                |           0.090 |                 |                 \n| Cumulative effect size (2)                |           0.850 |           0.758 |                 \n| Cumulative effect size (3)                |           1.100 |           1.052 |                 \n| Cumulative (pooled) standard deviation    |           1.597 |           1.468 |                 \n| Stage-wise test statistic (1)             |           0.178 |                 |                 \n| Stage-wise test statistic (2)             |           1.745 |           1.582 |                 \n| Stage-wise test statistic (3)             |           2.283 |           2.226 |                 \n| Stage-wise p-value (1)                    |          0.4296 |                 |                 \n| Stage-wise p-value (2)                    |          0.0424 |          0.0594 |                 \n| Stage-wise p-value (3)                    |          0.0125 |          0.0149 |                 \n| Adjusted stage-wise p-value (1, 2, 3)     |          0.0376 |          0.0297 |                 \n| Adjusted stage-wise p-value (1, 2)        |          0.0848 |          0.0594 |                 \n| Adjusted stage-wise p-value (1, 3)        |          0.0251 |          0.0149 |                 \n| Adjusted stage-wise p-value (2, 3)        |          0.0251 |          0.0297 |                 \n| Adjusted stage-wise p-value (1)           |          0.4296 |                 |                 \n| Adjusted stage-wise p-value (2)           |          0.0424 |          0.0594 |                 \n| Adjusted stage-wise p-value (3)           |          0.0125 |          0.0149 |                 \n| Overall adjusted test statistic (1, 2, 3) |           1.779 |           2.591 |                 \n| Overall adjusted test statistic (1, 2)    |           1.374 |           2.074 |                 \n| Overall adjusted test statistic (1, 3)    |           1.959 |           2.922 |                 \n| Overall adjusted test statistic (2, 3)    |           1.959 |           2.718 |                 \n| Overall adjusted test statistic (1)       |           0.177 |                 |                 \n| Overall adjusted test statistic (2)       |           1.724 |           2.322 |                 \n| Overall adjusted test statistic (3)       |           2.240 |           3.121 |                 \n| Test action: reject (1)                   |           FALSE |           FALSE |                 \n| Test action: reject (2)                   |           FALSE |           FALSE |                 \n| Test action: reject (3)                   |           FALSE |            TRUE |                 \n| Conditional rejection probability (1)     |          0.0101 |                 |                 \n| Conditional rejection probability (2)     |          0.0756 |          0.2954 |                 \n| Conditional rejection probability (3)     |          0.1317 |          0.5764 |                 \n| 95% repeated confidence interval (1)      |  [-1.901; 2.081]|                 |                 \n| 95% repeated confidence interval (2)      |  [-1.068; 2.768]|  [-0.227; 1.747]|                 \n| 95% repeated confidence interval (3)      |  [-0.798; 2.998]|  [0.041 ; 2.051]|                 \n| Repeated p-value (1)                      |            >0.5 |                 |                 \n| Repeated p-value (2)                      |          0.2789 |          0.0518 |                 \n| Repeated p-value (3)                      |          0.1915 |          0.0189 |                 \n\nLegend:\n\n* *(i)*: results of treatment arm i vs. control arm\n* *(i, j, ...)*: comparison of treatment arms 'i, j, ...' vs. control arm\n\n:::\n:::\n\n\n***\n\n# Bonus Exercise 6 (Planning of survival design) {-}\n\nA survival trial is planned to be performed with one interim stage and using an O'Brien & Fleming type $\\alpha$-spending approach at $\\alpha = 0.025$. The interim is planned to be performed after half of the necessary events were observed. It is assumed that the median survival time is 18 months in the treatment group, and 12 months in the control.  Assume that the drop-out rate is 5% after 1 year and the drop-out time is exponentially distributed.\n\n## Exercise 6a (accrual and follow-up time given) {-}\n\nThe patients should be recruited within 12 months assuming uniform accrual. Assume an additional follow-up time of 12 months, i.e., the study should be conducted within 2 years. Calculate the necessary number of events and patients (total and per month) in order to reach power 90% with the assumed median survival times if the survival time is exponentially distributed. Under the postulated assumption, estimate interim and final analysis time.\n\n**Solution**\n\nIn this simplest example, accrual and follow-up time needs to be specified. The effect size is defined in terms of lambda1 and lambda2 (you can also specify lambda2 and hazardRatio). \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndGS <- getDesignGroupSequential(kMax = 2, typeOfDesign = \"asOF\", beta = 0.1)\n\nx1 <- getSampleSizeSurvival(dGS, lambda1 = getLambdaByMedian(18), lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = 12, followUpTime = 12)\n\nsummary(x1)\n```\n\n::: {.cell-output-display}\n*Sample size calculation for a survival endpoint*\n\nSequential analysis with a maximum of 2 looks (group sequential design), overall \nsignificance level 2.5% (one-sided).\nThe results were calculated for a two-sample logrank test, \nH0: hazard ratio = 1, H1: treatment lambda(1) = 0.039, control lambda(2) = 0.058, \naccrual time = 12, accrual intensity = 38.9, follow-up time = 12, \ndropout rate(1) = 0.05, dropout rate(2) = 0.05, dropout time = 12, power 90%.\n\n| Stage                                    |      1 |      2 |\n| ----- | ----- | ----- |\n| Planned information rate                 |    50% |   100% |\n| Efficacy boundary (z-value scale)        |  2.963 |  1.969 |\n| Cumulative power                         | 0.2525 | 0.9000 |\n| Number of subjects                       |  467.3 |  467.3 |\n| Expected number of subjects under H1     |  467.3 | |\n| Cumulative number of events              |  128.3 |  256.5 |\n| Analysis time                            |  13.14 |  24.00 |\n| Expected study duration                  |  21.26 | |\n| Cumulative alpha spent                   | 0.0015 | 0.0250 |\n| One-sided local significance level       | 0.0015 | 0.0245 |\n| Efficacy boundary (t)                    |  0.593 |  0.782 |\n| Exit probability for efficacy (under H0) | 0.0015 | |\n| Exit probability for efficacy (under H1) | 0.2525 | |\n\nLegend:\n\n* *(t)*: treatment effect scale\n\n:::\n\n```{.r .cell-code}\nceiling(x1$maxNumberOfEvents)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 257\n```\n\n\n:::\n\n```{.r .cell-code}\nceiling(x1$maxNumberOfSubjects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 468\n```\n\n\n:::\n\n```{.r .cell-code}\nceiling(x1$maxNumberOfSubjects)/12\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 39\n```\n\n\n:::\n\n```{.r .cell-code}\nx1$analysisTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 13.14114\n[2,] 24.00000\n```\n\n\n:::\n:::\n\n\n\n## Exercise 6b (follow-up time and absolue intensity given) {-}\n\nAssume that 25 patients can be recruited each month and that there is uniform accrual. Estimate the necessary accrual time if the planned follow-up time remains unchanged.\n\n**Solution**\n\nHere the end of accrual and the number of patients is calculated at given follow-up time and absolute accrual intensity:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx2 <- getSampleSizeSurvival(dGS, hazardRatio = 2/3, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = 0, accrualIntensity = 25, followUpTime = 12)\n\nceiling(x2$maxNumberOfSubjects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 435\n```\n\n\n:::\n\n```{.r .cell-code}\nx2$accrualTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 17.38334\n```\n\n\n:::\n\n```{.r .cell-code}\nx2$analysisTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 16.79806\n[2,] 29.38334\n```\n\n\n:::\n:::\n\n\n## Exercise 6c (accrual time and max number of patients given) {-}\n\nAssume that accrual stops after 16 months with 25 patients per month, i.e., after 400 patients were recruited. What is the estimated necessary follow-up time?\n\n**Solution**\n\nAt given accrual time and number of patients, the follow-up time is calculated:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx3 <- getSampleSizeSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = c(0, 16), accrualIntensity = 25)\n\nceiling(x3$maxNumberOfSubjects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 400\n```\n\n\n:::\n\n```{.r .cell-code}\nx3$followUpTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 15.96226\n```\n\n\n:::\n\n```{.r .cell-code}\nx3$analysisTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 16.82864\n[2,] 31.96226\n```\n\n\n:::\n:::\n\n\n## Exercise 6d (staggered patient entry) {-}\n\nHow do the results change if in the first 3 months 15 patients, in the second 3 months 20 patients, and after 6 months 25 patients per month can be accrued?\n\n**Solution**\n\nThis is the result from b), where the end of accrual is calculated:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx4 <- getSampleSizeSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = c(0, 3, 6), accrualIntensity = c(15, 20, 25), followUpTime = 12)\n    \nceiling(x4$maxNumberOfSubjects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 434\n```\n\n\n:::\n\n```{.r .cell-code}\nx4$accrualTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  3.00000  6.00000 19.14067\n```\n\n\n:::\n\n```{.r .cell-code}\nx4$analysisTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 18.48715\n[2,] 31.14067\n```\n\n\n:::\n:::\n\n\nThis is the result from c), where the follow-up time is calculated:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx5 <- getSampleSizeSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = c(0, 3, 6, 16), accrualIntensity = c(15, 20, 25))\n\nceiling(x5$maxNumberOfSubjects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 355\n```\n\n\n:::\n\n```{.r .cell-code}\nx5$followUpTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 23.60973\n```\n\n\n:::\n\n```{.r .cell-code}\nx5$analysisTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 18.83368\n[2,] 39.60973\n```\n\n\n:::\n:::\n\n\n***\n\n# Bonus Exercise 7 (Adaptive survival design) {-}\n\n## Exercise 7a (verify results by simulation) {-}\n\nAssume that the study from Example 6 is planned with 257 events and 400 patients under the assumptions that accrual stops after 16 months with 25 patients per month. Verify by simulation the correctness of the results obtained by the analytical formulae.\n\n**Solution**\n\nWe first calculate the analysis times by the analytical formulas and verify that the power is indeed exceeding 90%:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny3 <- getPowerSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = c(0, 3, 6, 16), accrualIntensity = c(15, 20, 25),\n  maxNumberOfEvents = 257, directionUpper = FALSE)\n\ny3$analysisTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 18.85699\n[2,] 39.74904\n```\n\n\n:::\n\n```{.r .cell-code}\ny3$overallReject  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9005251\n```\n\n\n:::\n:::\n\n\nPractically the same result is obtained with the simulation tool: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmaxiter <- 1000\n\nz3 <- getSimulationSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12, maxNumberOfIterations = maxiter,\n  accrualTime = c(0, 3, 6, 16), accrualIntensity = c(15, 20, 25),\n  plannedEvents = c(129, 257), directionUpper = FALSE)\n\nz3$analysisTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 18.91786\n[2,] 39.58647\n```\n\n\n:::\n\n```{.r .cell-code}\nz3$overallReject  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.903\n```\n\n\n:::\n:::\n\n\n\n## Exercise 7b (assess adaptive survival design) {-}\n\nAssume now that a sample size increase up to a ten-fold of the originally planned number of events is foreseen. \nConditional power 90% *based on the observed hazard ratios* is used to increase the number of events. \nAssess by simulation the magnitude of power increase when using the appropriate method.\n\nSimulate the Type I error rate when using \n\n- the group sequential method\n\n- the inverse normal method\n\nHint: Make sure that enough subjects are used in the simulation (set `maxNumberOfSubjects = 3000` and no drop-outs)\n\n**Solution**\n\nFirst define an inverse normal design with the same parameters as the original group sequential design:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndIN <- getDesignGroupSequential(kMax = 2, typeOfDesign = \"asOF\", beta = 0.1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nz4 <- getSimulationSurvival(dIN, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  maxNumberOfIterations = maxiter,\n  accrualTime = c(0,16), maxNumberOfSubjects = 3000, plannedEvents = c(129, 257), \n  directionUpper = FALSE, conditionalPower = 0.9, \n  minNumberOfEventsPerStage = c(NA,128), maxNumberOfEventsPerStage = 10*c(NA,128))\n\nz4$analysisTime\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]\n[1,]  5.586818\n[2,] 11.139290\n```\n\n\n:::\n\n```{.r .cell-code}\nz4$overallReject  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.982\n```\n\n\n:::\n:::\n\n\nThe following simulation compares the Type I error rate of the inverse normal method with the type I error rate of the (illegal) use of the group-sequential method:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmaxiter <- 10000\n\ndGS <- getDesignGroupSequential(kMax = 2, typeOfDesign = \"asOF\")\ndIN <- getDesignInverseNormal(kMax = 2, typeOfDesign = \"asOF\")\n\nIN <- getSimulationSurvival(dIN, hazardRatio = 1,\n  maxNumberOfIterations = maxiter,\n  accrualTime = c(0,16), maxNumberOfSubjects = 3000, plannedEvents = c(129, 257), \n  directionUpper = FALSE, conditionalPower = 0.9, \n  minNumberOfEventsPerStage = c(NA,128), maxNumberOfEventsPerStage = 10*c(NA,128))\n\nGS <- getSimulationSurvival(dGS, hazardRatio = 1,\n  maxNumberOfIterations = maxiter,\n  accrualTime = c(0,16), maxNumberOfSubjects = 3000, plannedEvents = c(129, 257), \n  directionUpper = FALSE, conditionalPower = 0.9, minNumberOfEventsPerStage = c(NA,128), \n  maxNumberOfEventsPerStage = 10*c(NA,128))\n  \nIN$overallReject  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0274\n```\n\n\n:::\n\n```{.r .cell-code}\nGS$overallReject  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0366\n```\n\n\n:::\n:::\n\n\n\n***\n\nSystem: rpact 4.0.0, R version 4.4.1 (2024-06-14 ucrt), platform: x86_64-w64-mingw32\n\n\nprint(citation(\"rpact\"), bibtex = FALSE)",
    "supporting": [
      "BBSadaptiveCourse03Sep2023_solutions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}