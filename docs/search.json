[
  {
    "objectID": "additional_docs.html",
    "href": "additional_docs.html",
    "title": "Basel Biometric Section (BBS): additional documents",
    "section": "",
    "text": "Position papers\nBBS position paper on student internships."
  },
  {
    "objectID": "board.html",
    "href": "board.html",
    "title": "BBS board",
    "section": "",
    "text": "Board\n\n\n\n\n\n\n\n\n\n\nName\nFunction\nCompany\n\n\n\n\nLilla Di Scala\n\nActelion Pharmaceuticals Ltd\n\n\nMarisa Bacchi\n\nActelion Pharmaceuticals Ltd\n\n\nBrian Hennessy\n\nActelion Pharmaceuticals Ltd\n\n\nRoland Marion-Gallois\n\nBMS\n\n\nDominik Heinzmann\n\nF. Hoffmann-La Roche Ltd\n\n\nHans Ulrich Burger\nPresident\nF. Hoffmann-La Roche Ltd\n\n\nJuliane Schaefer\n\nF. Hoffmann-La Roche Ltd\n\n\nKaspar Rufibach\n\nF. Hoffmann-La Roche Ltd\n\n\nMarcel Wolbers\n\nF. Hoffmann-La Roche Ltd\n\n\nPierre Verweij\n\nIdorsia Pharmaceuticals Ltd\n\n\nAchim Guettner\n\nNovartis Pharma AG\n\n\nMarc Vandemeulebroecke\n\nNovartis Pharma AG\n\n\nOlympia Papachristofi\n\nNovartis Pharma AG\n\n\nTracy Glass\n\nSwiss Tropical and Public Health Institute\n\n\nGiusi Moffa\n\nUniversity of Basel\n\n\nMarco Cattaneo\n\nUniversity of Basel\n\n\nFred Sorenson\nTreasurer\nXcenda"
  },
  {
    "objectID": "events_past.html",
    "href": "events_past.html",
    "title": "Past events: agendas, slidedecks, recordings",
    "section": "",
    "text": "12.04.2023: Quantification of risk: ask the right questions or time to apply the estimand framework to safety!\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nRima Izem\nNovartis\nWelcome, scene setting and “Let us put the scientific objective first!”\nNo presentation available\n\n\nKaspar Rufibach\nRoche\nStop the abuse: A plea for a more principled approach to the analysis of time-to-event endpoints with varying follow-up times and/or competing risks, with a focus on analysis of AEs.\nlink\n\n\n\n\n\n\n\n\n\n\n15.03.2023: Joint BES/BBS webinar: Real-World Data Quality\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nMassoud Toussi (starts at 5:38)\nIQVIA\nWhat is data quality, and how data types differ in terms of data quality\nlink\n\n\nNicole Mahoney (25:35)\nNovartis\nRWD for regulatory decisions\nlink\n\n\nClair Blacketer (39:48)\nJanssen\nEHDEN: Data Quality Dashboard\nlink\n\n\nDaniel Morales (59:40)\nEMA\nEU Data quality framework\nlink\n\n\nDalia Dawoud (1:18:43)\nNICE\nCOPD case study - The Use of the OMOP Common Data Model in Health Technology Assessment\nlink\n\n\nSpencer James (1:41:34)\nRoche/Genentech\nData quality in Flatiron\nlink\n\n\nGracy Crane (NB this talk in the panel discussion section was not recorded, but the slides are attached)\nRoche\nTranscelerate - How to bridge from framework to fitness for purpose demonstration?\nlink\n\n\n\n\n\n\n\n\n\n\n15.12.2022: Joint EFSPI & BBS virtual event - Addressing intercurrent events: Treatment policy and hypothetical strategies (day 2)\nAgenda\nRecording\nRecording 2\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nFrank Bretz & Mouna Akacha\nNovartis\nThe hypothetical strategy: why, how, when?\nlink\n\n\nJinglin Zhong\nOtsuka\nA case study of hypothetical strategies in acute pain\nlink\n\n\nJonathan Bartlett\nLSHTM\nHypothetical estimands – a unification of causal inference and missing data methods\nlink\n\n\nFlorian Lasch\nEMA\ng-estimation for the hypothetical strategy with an application to Alzheimer’s Disease and COVID-19-related intercurrent events\nlink\n\n\nIan White\nUniversity College London\nEstimation with multiple intercurrent events and mixed estimand strategies\nlink\n\n\nKelly van Lancker\nGhent University\nDiscussion\nlink\n\n\nLei Nie\nFDA\nDiscussion\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n08.12.2022: Joint EFSPI & BBS virtual event - Addressing intercurrent events: Treatment policy and hypothetical strategies (day 1)\nAgenda\nRecording\nRecording 2\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nDavid Wright\nAstraZeneca\nReflections on the estimands addendum with a focus on the treatment policy strategy\nlink\n\n\nThomas Drury\nGSK\nImplementation of the treatment policy strategy for continuous longitudinal endpoints: A Comparison of Estimation Methods\nlink\n\n\nMarcel Wolbers & Alessandro Noci\nRoche\nTreatment policy estimation based on standard and reference-based conditional mean imputation\nlink\n\n\nDaniel Sabanés Bové\nRoche\nOther statistical software for continuous longitudinal endpoints: mmrm R package\nlink\n\n\nJames Roger\nLSHTM\nOther statistical software for continuous longitudinal endpoints: SAS macros for multiple imputation\nlink\n\n\nSuzie Cro\nImperial College London\nDiscussion on treatment policy strategy\nlink\n\n\n\n\n\n\n\n\n\n\n30.11.2022: Next Generation Networking Seminar\nAgenda\nRecording\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nUli Burger\nRoche\nWelcome and Introduction to Event Series\nNo presentation available\n\n\nYouyou Hu & Antonella Mazzei\nRoche & BMS\nGetting started\nNo presentation available\n\n\nJulie Jones\nNovartis\nCommunicating statistics to a lay audience\nNo presentation available\n\n\nFrank Bretz & Uli Burger\nNovartis & Roche\nEvolution of Biometrics within and across Pharma: Current trends and future insights\nNo presentation available\n\n\nGabriele Bieska, Joerg Maurer, Valda Murphy, Simon Wandel, Marcel Wolbers\nRoche, Roche, Novartis, Novartis, Roche\nNot All Roads May Lead to Rome – Panelists’ Pitch on their career paths in industry\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n15.07.2022: On market approval and market access: Breaking the linear thinking or how to innovate in a crowded space?\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nFrank Bretz\nNovartis\nWelcome\nlink\n\n\nAnja Schiel (starts at 00:04:00)\nNOMA & EMA\nStart thinking HTA early\nlink\n\n\nNigel Yateman (01:01:15)\nNovartis\nChallenges in developing next generation CAR-T\nlink\n\n\nIain Bennett (01:22:30)\nRoche\nNo comparators no problem?\nlink\n\n\nKaren Facey (01:42:50)\nUniversity of Edinburgh and self-employed\nComments to introduce panel discussion\nlink\n\n\nSpeakers + Gorana Capkun, Lilla di Scala, Andrew Thomson (01:58:15)\n\nPanel discussion\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n23.06.2022: BBS / EFSPI Seminar Registry studies and HTA\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nFred Sorenson\nXcenda, Switzerland\nWelcome\nNo presentation available\n\n\nEric Faulkner and Omar Dabbous\nNovartis Gene Therapies, USA\nAn open dialog on the issues faced and lessons learned with respect to Novartis Gene Therapies’ Spinal Muscular Atrophy (SMA) registries\nNo presentation available\n\n\nEntela Xoxi\nUniversità Cattolica del Sacro Cuore, Italy\nAIFA registries: past and current & upcoming challenges\nlink\n\n\nJinma Ren and Friedhelm Leverkus\nPfizer, USA and Pfizer, Germany\nIssues in the design and analysis of registry-based studies for regulatory and HTA purposes\nlink\n\n\nMei Yang\nHappy Life Technology, China & USA\nRegistries in China: Guidelines, trends and new technologies\nlink\n\n\nRossella Di Bidino\nFondazione Policlinico Universitario Agostino Gemelli, Italy\nHospital Perspective on using Registry Data for HTA\nlink\n\n\nKirk Geale\nQuantify Research, Sweden\nCase studies using Registry Data for HTA in Scandinavia\nlink\n\n\nKat Belendiuk\nGenentech, USA\nFlywheelMS Case Study - A complete web-based digital registry of 5,000 patients with Multiple Sclerosis in the USA\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n24.05.2022: BBS Spring Seminar Transforming drug development and Assembly\nAgenda\nRecording\nRecording 2\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nUli Burger\nRoche, Basel\nWelcome\nNo presentation available\n\n\nPierre Verweij, Guy Braunstein, Colin Terry, Pavi Rallapalli, Dominik Heinzmann, Lisa Hampson, Marc Vandemeulebroecke, Heinz Schmidli, Sebastian Weber, Laurent Essioux\nIdorsia Pharmaceuticals, Deloitte, Novo Nordisk, Novartis, Roche\nBBS Spring Seminar Transforming drug development and assembly\nlink\n\n\n\n\n\n\n\n\n\n\n29.03.2022: Graphical approaches to multiple test problems\nAgenda\nRecording\nRecording 2\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nMarc Vandemeulebroecke\nNovartis, Basel\nWelcome\nNo presentation available\n\n\nEkkehard Glimm, Frank Bretz & Dong Xi\nNovartis & Gilead\nGraphical approaches to multiple test problems\nlink\n\n\n\n\n\n\n\n\n\n\n21.02.2022: Machine Learning in clinical drug development\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nMarkus Lange, Lorenz Uhlmann\nNovartis, Basel\nMachine Learning in clinical drug development\nlink\n\n\nMarkus Lange, Lorenz Uhlmann\nNovartis, Basel\nQuestions from the chat, with answers\nlink\n\n\nMarkus Lange, Lorenz Uhlmann\nNovartis, Basel\nR exercises\nlink\n\n\nMarkus Lange, Lorenz Uhlmann\nNovartis, Basel\nDataset used for exercises\nlink\n\n\n\n\n\n\n\n\n\n\n27.07.2021: Joint BBS/BES Webinar COVID-19 pandemic and how we deal with data\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nHans Ulrich Burger\nRoche, Basel\nWelcome\nNo presentation available\n\n\nTim Friede\nUniversity Medical Center Göttingen\nData and Statistics as a basis for decision making: A discussion of the Corona pandemic\nlink\n\n\nThorsten Lehr\nSaarland University\nForecasting: What do we learn?\nlink\n\n\nThierry Van Effelterre\nJ&J\nVaccination trials: What do we know about long-term efficacy measures and other questions\nlink\n\n\nFei Chen\nJanssen\nStatistical Considerations Underlying a COVID-19 Vaccine phase 3 design\nlink\n\n\n\n\n\n\n\n\n\n\n28.06.2021: Joint EFSPI/BBS Meeting Precision & Innovative Medicine and Health Technology Assessment\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nFred Sorensen\nXcenda\nWelcome\nlink\n\n\nDan O’Connor\nMHRA, UK\nThe UK’s Innovative Licensing and Access Pathway (ILAP) for medicines – A joint MHRA, NICE & SMC initiative\nlink\n\n\nKaren Facey\nUniversity of Edinburgh\nIMPACT HTA - Recommendations for Developing Rare Disease Treatments\nlink\n\n\nPaul Cislo, Jinma Ren and Joseph C. Cappelleri\nPfizer\nAdjusting Global Survival to Make Results More Relevant and Generalizable to Local Markets\nlink\n\n\nMarc Buyse\nIDDI and University of Hasselt, Belgium\nNet benefit and correlation between benefit and harms\nlink\n\n\nMark Belger and Marie-Ange Paget\nEli Lilly UK & France\nClosing the efficacy to effectiveness gap: Generalizing from RCTs to real world populations\nlink\n\n\nKirsten Herrmann\nExact Sciences, Germany\nAssessments and reimbursement of gene expression signature tests in Europe\nlink\n\n\nJanneke Boersma\nRoche, Netherlands\nBridging the gap between Regulatory & HTA approval for Precision Medicine therapies: a case study from the Netherlands\nlink\n\n\n\n\n\n\n\n\n\n\n16.06.2021: BBS Webinar Impact of the COVID-19 Pandemic on Clinical Trials\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nAnja Schiel\nChair Scientific Advice Working Party, EMA\nOverview on early experience of the impact of Covid-19 pandemic on clinical trials\nlink\n\n\nPaul Delmar\nRoche, Basel\nCOVID-19 pandemics : Impact on Clinical Trials in a chronic progressing disease\nlink\n\n\nEva Hua\nNovartis, Basel\nHypothetical strategy for a case study affected by COVID-19 pandemic\nlink\n\n\nKelly Van Lancker\nGhent University\nThe hypothetical estimand and its potential estimators in clinical trials impacted by COVID-19\nlink\n\n\n\n\n\n\n\n\n\n\n22.03.2021: BBS Webinar Statistical challenges in the clinical development of CAR T-cell therapies\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nRoland Marion-Gallois\nBMS, Switzerland\nWelcome and Introduction\nlink\n\n\nCaroline Aarber Bath\nCHUV, Switzerland\nIntroduction to Cell Therapies: A Clinical Perspective\nlink\n\n\nElina Asikanius\nFIMEA, Finland\nPerspective from EMA\nlink\n\n\nZhenzhen Xu\nFDA, USA\nPerspective from FDA\nlink\n\n\nKhadija Rantell\nMHRA, UK\nPhase 2 / Phase 3, Treatment effect or therapeutic strategy effect?\nlink\n\n\nAlessandro Previtali\nBMS, Switzerland\nPhase 2 / Phase 3, Estimands in the context of cell therapy development\nlink\n\n\nNigel Yateman\nNovartis, Switzerland\nChallenges for new CAR-T therapies\nlink\n\n\nOriana Ciani\nUniversità Bocconi, Italy\nIntroduction on Post-Approval challenges, reimbursement and HTA assessments\nlink\n\n\nAndrea Smith\nG-BA, Germany\nHTA-Perspective on the assessment of CAR-T-Cell Therapies\nlink\n\n\nMarcelo Pasquini and Zhenuan Hu\nCIBMTR, USA\nCAR-T cell therapy registries\nlink\n\n\n\n\n\n\n\n\n\n\n08.03.2021: Graphics for decision-making in biomedical research and drug development\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nDominik Heinzmann\nRoche, Basel\nWelcome\nNo presentation available\n\n\nHannah Diehl and Tamara Broderick / Andy Stein and Niladri Roy Chowdhury\nMIT and Novartis\nThe “See”-Value App: Visual Decision Making for Drug Development\nlink\n\n\nNeil McQuarrie\nFlatiron\nBetter understanding and reacting on impact of COVID-19 on RWD collection by combining statistics with visualization\nlink\n\n\nTadeusz Lewandowski\nRoche, Basel\nInteractive clinical study visualisation in enabling the faster decision making\nlink\n\n\nMarkus Lange\nNovartis, Basel\nUnraveling a single number – using graphics to explain Probability of Success\nlink\n\n\nAnne-Marie Meyer\nRoche, Basel\nPopulation Level Analytics for pandemic response: Predicting vaccine uptake and vaccine hesitancy\nlink\n\n\nGiusi Moffa\nUniversity of Basel\nClosure\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n03.11.2020: Joint EFSPI / BBS Webinar: The application of estimands from a Neuroscience perspective\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nHans Ulrich Burger\nRoche, Basel\nWelcome and introduction to the estimand framework\nlink\n\n\nNikolaos Sfikas\nNovartis, Basel\nOutline of an estimand strategy in MS\nlink\n\n\nMette Krog Josiassen and Peter Quarg\nLundbeck and Novartis\nOutline of an estimand proposal in migraine prevention and neuropathic pain\nlink\n\n\nPaul Delmar\nRoche, Basel\nUsing the Estimand Framework to address challenges in AD clinical trial with a closer look at the hypothetical strategy\nlink\n\n\nCarrie Li\nRoche, Basel\nEstimands in Huntington’s disease\nlink\n\n\nAndrew Hartley\nPPDI\nImpact of Covid-19 on studies in Neuroscience\nlink\n\n\nJoel Raffel and Khadija Rantell\nMHRA, UK\nRegulatory aspects of the estimand framework: Clinical and statistical perspectives\nlink\n\n\nAnja Schiel\nChair Scientific Advice Working Party, EMA\nPanel discussion including all speakers\nlink\n\n\n\n\n\n\n\n\n\n\n07.09.2020: BBS Webinar RCTs meeting causal inference: principal stratum strategy and beyond\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKaspar Rufibach\nRoche, Basel\nWelcome and scene setting\nlink\n\n\nVanessa Didelez\nKeynote speaker, Leibniz Institute for Prevention Research and Epidemiology, BIPS, Bremen\nTime-Varying Treatments in Observational Studies: Lessons for Clinical Trials\nlink\n\n\nJack Bowden\nUniversity of Exeter\nConnecting Instrumental Variable methods for causal inference to the Estimand Framework\nlink\n\n\nKelly van Lancker\nGhent University\nEfficient, doubly robust estimation of the effect of dose switching for switchers in a randomised clinical trial\nlink\n\n\nBjörn Bornkamp\nNovartis, Basel\nPrincipal Stratum Strategy: Potential Role in Drug Development\nlink\n\n\nDominik Heinzmann\nRoche, Basel\nPrincipal stratum strategy to investigate anti-drug antibody impact on cancer immunotherapy outcome\nlink\n\n\nAiesha Zia\nNovartis, Basel\nExploring estimation approaches for principal stratum estimands in Phase III randomized trials in CAR-T anti-cancer therapy\nlink\n\n\nFabrizia Mealli\nUniversity of Florence\nThe ICH E9 addendum from an academic causal inference perspective and feedback on the previous talks\nlink\n\n\nGiusi Moffa\nUniversity of Basel\nNext webinars and closure\nlink\n\n\nAll\n\nQuestion and Answers\nlink\n\n\n\n\n\n\n\n\n\n\n30.06.2020: BBS/EFSPI Webinar on HTA\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nChrissie Fletcher\nGSK, UK\nCelebrating 10 Years HTA SIG\nlink\n\n\nChristoph Schürmann\nIQWiG, Germany\nHealth-related quality of life endpoints in benefit assessments: Demands and challenges as seen by IQWiG in Germany\nlink\n\n\nLara Wolfson\nMerck, USA\nIssues related to transparency with HTA dossiers\nlink\n\n\nMark Nuijten\nA2M and Univ. of Maastricht, NL & ITU, Turkey\nAn innovative pricing model to assess the price of expensive drugs with an orphan indication\nlink\n\n\nFred Sorenson\nXcenda\nIntroduction to moderated panel discussion\nlink\n\n\n\n\n\n\n\n\n\n\n29.06.2020: Joint EFSPI / BBS Webinar: Estimands addendum is final: Anything new for oncology?\nAgenda\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKaspar Rufibach\nRoche, Basel\nWelcome and scene setting\nlink\n\n\nAnja Schiel\nChair Scientific Advice Working Party, EMA\nExperience with the estimand framework in oncology\nlink\n\n\nRenaud Capdeville\nNovartis, Basel\nChallenges and open questions in hematology: RATIFY\nlink\n\n\nTina Nielsen\nRoche, Basel\nChallenges and open questions in hematology: GALLIUM\nlink\n\n\nHannes Buchner and Ingolf Griebsch\nStaburo and Boehringer-Ingelheim\nTreatment switching: challenges, estimands, and estimators\nlink\n\n\nStefan Englert\nAbbvie\nCommentary on previous talks taking COVID-19 into account\nlink\n\n\nAll\n\nQuestion and Answers\nlink\n\n\n\n\n\n\n\n\n\n\n03.06.2020: BBS Webinar: Aspects of COVID-19 pandemic\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nJean Lang\nSanofi Pasteur\nOverview on SARS-CoV2 and Challenges for COVID-19 Vaccine Development at Pandemic Speed\nlink\n\n\nChristian Althaus\nISPM, University of Bern\nEarly transmission, pandemic spread and severity of COVID-19\nlink\n\n\nKarin Meiser\nNovartis, Basel\nSpecific aspects of a clinical trial targeting Covid-19\nlink\n\n\nJenny Devenport\nRoche, Basel\nThe influence of investigator initiated studies in the COVID-19 pandemic\nlink\n\n\n\n\n\n\n\n\n\n\n06.05.2020: BBS Virtual Seminar: Impact of COVID-19 on clinical trials\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nFrank Petavy\nEMA\nEMA perspective and guidance on COVID-19\nlink\n\n\nNatalie Dimier\nRoche, Welwyn\nIndustry perspective on COVID-19 (1/3)\nlink\n\n\nMouna Akacha\nNovartis, Basel\nIndustry perspective on COVID-19 (2/3)\nlink\n\n\nCristina Sotto\nJ&J\nIndustry perspective on COVID-19 (3/3)\nlink\n\n\nMarcel Wolbers\nRoche, Basel\nShort Overview of Pharmaceutical Industry COVID-19 Biostatistics Working Group\nlink\n\n\nEvgeny Degtyarev\nNovartis, Basel\nShort overview on COVID-19 from the Cross-Industry Oncology Estimands Working Group\nlink\n\n\n\n\n\n\n\n\n\n\n04.02.2020: BBS Seminar: Network meta-analysis: methods and applications\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nSylwia Bujkiewicz\n\n Bivariate network meta-analysis for surrogate endpoint evaluation\nlink\n\n\nGerta Rücker\n\n Component network meta-analysis compared to a matching method in a disconnected network: a case study\nlink\n\n\nGeorgia Salanti\n\n CINeMA: a framework and web application to evaluate the confidence in network meta-analysis results\nlink\n\n\nMark Pletscher\n\n Network meta-analysis of treatments for previously untreated metastatic PD-L1-positive triple-negative breast cancer\nlink\n\n\nBartosz Jenner\n\nAn experience with indirect treatment comparisons using MAIC methods in a rare disease\nNo presentation available\n\n\nMarius Thomas\n\n A network meta-analysis to compare efficacy of treatment options for relapsing-remitting multiple sclerosis\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n01.11.2019: BBS Seminar: Predictive modelling, machine learning and causality\nAgenda\nNo recording available\nSummary of the event\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nEwout Steyerberg\n\n Clinical prediction models in the age of artificial intelligence and big data\nlink\n\n\nWilli Sauerbrei\n\n The EQUATOR networkand guidelines for prediction models\nlink\n\n\nTorsten Hothorn\n\n Score-based transformation learning\nlink\n\n\nPeter Bühlmann\n\n Causal regularization for distributional robustness and replicability\nlink\n\n\nGiusi Moffa\n\n Predicting putative intervention effects after causal structure learning from survey data\nlink\n\n\nAndrew Shattock\n\nUsing machine learning and disease models to evaluate target product profiles of novel interventions (No slide deck available)\nNo presentation available\n\n\nFederico Mattiello\n\n Identifying high-risk patients in Non-Hodgkin lymphoma (and trying to get insights into the disease biology)\nlink\n\n\nMark Baillie\n\n Novartis benchmarking initiative: making sense of AI\nlink\n\n\nChris Harbron\n\n Experiences from running internal prediction challenges within a pharmaceutical company\nlink\n\n\n\n\n\n\n\n\n\n\n21.08.2019: BBS/BES Seminar: Causal inference in drug development: why, when, how?\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nMiguel Hernan\n\n Beyond intention-to-treat. Causal inference guidelines for causal inference\nlink\n\n\nChristine Fletcher\n\n The Final ICH E9(R1) E9 addendum\nlink\n\n\nFrank Pétavy\n\n A regulator’s perspective\nNo presentation available\n\n\nValentine Jehl\n\nAdverse reactions confounded by prior medication: (how) can causal inference solve the problem?\nNo presentation available\n\n\nThibaut Sanglier\n\nTreatment sequencing and effectiveness: challenges and considerations\nNo presentation available\n\n\nNikolaos Sfikas\n\nPrincipal stratification techniques in the context of regulatory decision making\nNo presentation available\n\n\nJack Bowden\n\n Implementing the Principal Stratum estimand strategy using Instrumental Variable methods: An emulation of the CANTOS trial\nlink\n\n\n\n\n\n\n\n\n\n\n04.06.2019: BBS/EFSPI Seminar: Precision medicine in drug development\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nNiko Beerenwinkel\n\nBioinformatics for precision oncology\nNo presentation available\n\n\nStephen Senn\n\n Precision medicine: The honeymoon is over. It’s high time for tough love\nlink\n\n\nTomasz Burzykowski\n\n Generalized pairwise comparisons for precision medicine\nlink\n\n\nAdam Heathfield\n\n Valuation of Regenerative Medicine/Advance Therapeutics (RM/ATs): Challenges and opportunities for creating a better framework\nlink\n\n\nJack Kuipers\n\n Mutational interactions define novel cancer subgroups: can they inform precision oncology?\nlink\n\n\nMario Ouwens\n\n Difficulties with network meta-analysis when starting to use PDL1 thresholds\nlink\n\n\nGeorgina Bermann\n\n Cardiovascular medicine: approaches to the use of early biomarker response to identify a patient subgroup with enhanced therapeutic benefit\nlink\n\n\nLaurent Essioux\n\n Examples of personalized Healthcare at Roche: statistical perspectives\nlink\n\n\n\n\n\n\n\n\n\n\n10.05.2019: BBS Spring Seminar: Synthetic controls - what do we need and how far can we go?\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nTom Brookland\n\n RWD/RWE Global Regulatory Overview\nlink\n\n\nKaspar Rufibach and Hans Ulrich Burger\n\n External controls in drug development\nlink\n\n\nSomnath Sarkar\n\n Considerations for Developing External Control Arm from Real-World Data\nlink\n\n\nLaurence Colin and Yue Li\n\n Making better use of early phase safety data\nlink\n\n\nCornelia Dunger-Baldauf\n\n For the sake of the patient – reducing placebo exposure by using historical controls\nlink\n\n\nGonzalo Duran-Pacheco\n\n Electronic Health Records used to derive Control Arms for Single-Arm oncology trials: Proof of concept using RCT’s in lung cancer\nlink\n\n\nChris Harbron\n\n A Decision Making Framework For Utilising External Control Arms\nlink\n\n\nMeinhard Kieser\n\n Synthetic controls – what do we need and how far can we go? Rejoinder\nlink\n\n\nNorbert Benda\n\n Synthetic controls – what do we need and how far can we go? Rejoinder\nlink\n\n\nKit Roes\n\n Synthetic controls – what do we need and how far can we go? Rejoinder\nlink\n\n\nJan Müller-Berghaus\n\n Synthetic controls – what do we need and how far can we go? Rejoinder\nNo presentation available\n\n\nAnja Schiel\n\n Synthetic controls – what do we need and how far can we go? Rejoinder\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n27.06.2018: BBS/EFSPI Seminar: Small populations and level of evidence\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nFred Sorensen\n\nEuropean Statistical Meeting on Small populations and level of evidence\nlink\n\n\nDaniel O’Connor\n\n Rare diseases and orphan drugs: A Regulator’s (clinical)Perspectives\nlink\n\n\nStephen Senn\n\n In search of the lost loss function\nlink\n\n\nHenriette Thole\n\n The potential and challenges of registry use when generating evidence in small populations\nlink\n\n\nAnja Schiel\n\n Rare diseases and orphan drugs:The HTA perspective\nlink\n\n\nAdele Morganti\n\n Borrowing external controls for an event-driven pediatric trial in PAH: a case study\nlink\n\n\nAndreas Kaiser\n\n Bayesian analysis for small sample size trials using informative priors derived from historical data\nlink\n\n\nElina Asikanius\n\n Using a non-interventional study to strengthen the evidence collected in a Phase III program: a Hemophilia A case Study\nlink\n\n\nHans Hockey and Kristian Brock\n\n Hockey sticks and broken sticks – a design for a single-treatment double-blind randomized clinical trial suitable for chronic diseases\nlink\n\n\n\n\n\n\n\n\n\n\n26.06.2018: BBS Seminar: RCTs, personalized medicine, and surrogacy\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nTomasz Burzykowski\n\nEvaluation of Time-to-event Surrogate Endpoints Using Accelerated Failure-time Models\nlink\n\n\nEverardo D. Saad\n\nPrecision Medicine Needs Randomized Trials\nlink\n\n\nMarc Buyse\n\nA statistical approach for personalized medicine and benefit / risk assessment\nlink\n\n\n\n\n\n\n\n\n\n\n17.04.2018: BBS Spring Seminar: New developments in HTA, adaptive designs and multiplicity – in remembrance of Willi Maurer\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nJason Wang\n\nSense and sensibility of estimands for health technology assessment (HTA)\nlink\n\n\nChristoph Gerlinger\n\nEQ-5D-5L Utility Index for different countries\nlink\n\n\nSusan Edwards\n\nWhose perspective? Implications on cost-effectiveness modelling of differences between country value sets (a case study)\nlink\n\n\nCarsten Schwenke\n\nReal World Evidence and HTA – Experiences with IQWiG\nlink\n\n\nTim Friede\n\nHTA AND SAFETY Some results of the ATF / APF Project Group\nlink\n\n\n\n\n\n\n\n\n\n\n20.03.2018: BBS Seminar: Competing Risks and Multi-State Models\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nClaudia Schmoor\n\n Competing risks with applications to oncology\nlink\n\n\nJan Beyersmann\n\n Analysis of co-time-to-event outcomes in randomized clinical trials\nlink\n\n\nEkkehard Glimm and Lillian Yau\n\n A discrete semi-Markov model for the effect of need-based treatments on the disease states\nlink\n\n\n\n\n\n\n\n\n\n\n14.11.2017: BBS Seminar: Future of Biomedical Research: Are we ready?\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nDamian Roqueiro\nMachine Learning and Computational Biology Lab ETH Zurich\nApplications of Machine Learning and Deep Learning\nNo presentation available\n\n\nJonas Dorn\nNovartis, Basel\nMachine learning when the ground truth isn’t truth and privacy is a problem – case study from the Assess MS project\nNo presentation available\n\n\nHans Ulrich Burger\nRoche, Basel\nBig clinical data: What should biometrician do with it?\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n11.09.2017: BBS Seminar Emerging topics for statistical methodology in drug development: Estimands and advanced analytics\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nStephen Ruberg\nEli Lilly\nThe patient perspective – the estimands they want\nNo presentation available\n\n\nStef van Buuren,\nNetherlands Organisation for Applied Scientific Research and University of Utrecht\nIndividual causal effect: What is it? Why we need it? How to estimate it?\nNo presentation available\n\n\nBaldur Magnusson\nNovartis, Basel\nUsing principal stratification to disentangle post-randomization outcomes in a randomized controlled phase 3 study\nNo presentation available\n\n\nTeresa Barata\nRoche, Basel\nEstimands in early Parkinson disease\nNo presentation available\n\n\nStephen Ruberg\nEli Lilly\nMaking what’s advanced today routine tomorrow\nNo presentation available\n\n\nJouni Kerman\nGoogle\nCausal Measurement using Geo Experiments in a Time-Based Regression Framework\nNo presentation available\n\n\nCornelia Dunger-Baldauf\nNovartis, Basel\nA Smartphone-Based Study Capturing Longitudinal Vision Test Data, Movement Scores and User-reported Outcomes\nNo presentation available\n\n\nFabio Pellegrini\nBiogen\nIndividualized medicine based on a treatment response continuous score\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n26.06.2017: BBS Seminar Innovative model-based dose escalation designs: what next?\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nDaniel Sabanés Bové\n\n Model-based D/E designs: Current status and next steps\nlink\n\n\nDaniel Lorand\n\n Tailoring dose escalation designs to early clinical development goals\nlink\n\n\nAndreas Krause\n\n Guiding dose escalation studies in Phase 1 with unblinded modeling\nlink\n\n\n\n\n\n\n\n\n\n\n15.06.2017: BBS / PSI 1-Day Scientific Meeting: Empower the immune system to fight cancer\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nJorge Martinalbo\n\n Realising the potential of cancer immunotherapy\nlink\n\n\nAndrew Stone\n\nStatistical issues in the development of cancer immunotherapy\nlink\n\n\nDaniel Sabanés Bové\n\nBayesian Learning in Early Phase Cancer Immunotherapy: A Case Study\nlink\n\n\nMatt Whiley\n\nAn adaptive phase II basket trial design\nlink\n\n\nDominik Heinzmann\n\nStatistical, clinical and ethical considerations when minimizing\nlink\n\n\nClaude Berge\n\nStatistical Challenges in Immunotherapy: Non Proportional Hazard Model\nlink\n\n\nSergio Fracchia\n\nChallenges in development and approval: the case of cell based therapeutics\nlink\n\n\nFred Sorenson\n\nCancer Immunotherapy from the Health Technology Assessment (HTA) and Payer Perspectives\nlink\n\n\nNicholas Latimer\n\nEstimating survival benefit for health technology assessment: New challenges presented by immuno-oncology treatments?\nlink\n\n\n\n\n\n\n\n\n\n\n05.05.2017: BBS Spring Seminar The use of external data for decision making\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nDavid Evans\n\nReality and Real-World Data\nlink\n\n\nRalf Bender\n\nUse of registries and observational data in the benefit assessment of medical interventions\nlink\n\n\nFrank Bretz\n\nThreshold-crossing: A Useful Way to Establish the Counterfactual in Clinical Trials?\nlink\n\n\nDavid Dejardin\n\nDynamic borrowing of historical data: Performance and comparison of existing methods based on a case study\nlink\n\n\nEva-Maria Didden\n\nGetReal: 3 Years on!\nlink\n\n\nTim Friede\n\nThe Use of External Data for Decision Making\nlink\n\n\n\n\n\n\n\n\n\n\n13.03.2017: BBS Seminar: Biomarker analyses\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nWerner Vach\nUniversitätsspital Basel\nStatistical perspectives on umbrella trials\nNo presentation available\n\n\nKaspar Rufibach\nRoche, Basel\nComparison of clinical development plans for a confirmatory trial with subpopulation selection\nlink\n\n\n\n\n\n\n\n\n\n\n29.11.2016: BBS Seminar: Safety monitoring during the life cycle of a drug\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nConny Berlin\n\nSafety monitoring during the life cycle of a drug\nlink\n\n\nYusuf Tanrikulu\n\nSignal Detection – Quantitative Analysis of Safety Data\nlink\n\n\nPritibha Singh\n\nAdverse Drug Reaction (ADR) screening in clinical trials\nlink\n\n\nGianmario Candore\n\nScreening for adverse reactions in EudraVigilance\nlink\n\n\nSoheila Aghlmandi\n\nChoice of priors in rare events meta-analysis\nlink\n\n\n\n\n\n\n\n\n\n\n14.11.2016: BBS Seminar: Synthesis of Evidence: Observational studies and Meta-analysis\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKay Brodersen\nGoogle, Zurich\nInferring causal effects in the absence of an experiment using CausalImpact\nNo presentation available\n\n\nDavid Rasmussen\nETH Zurich\nUsing HIV phylogenetics to quantify how human mobility impacts antiretroviral-based prevention strategies\nNo presentation available\n\n\nAlmut Mecke\nRoche, Basel\nDifferent endpoints for meta-analyses of safety information\nNo presentation available\n\n\nFriedhelm Leverkus\nPfizer Germany\nMeta-analysis in support of the German Benefit Assessment for Reimbursement (Arzneimittelmarkt-Neuordnungsgesetz – AMNOG\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n17.10.2016: BBS Seminar: Missing Data and Graphical Models\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nJane Hutton\nUni Warwick\nMissing data and how to see biased results using Chain Event Graphs\nNo presentation available\n\n\nGiusi Moffa\nNovartis, Basel\nCancer profiling and subtype discovery with Bayesian inference for acyclic digraphs\nNo presentation available\n\n\nMarkus Elze\nRoche, Basel\nPropensity scores methods and covariate adjustment in practice\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n14.09.2016: PSI/BBS One Day Meeting: Time-to-Event and Recurrent Event Endpoints\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nLilla Di Scala\nActelion, Basel\nInformative censoring in a rare disease: a regulatory experience in PAH\nNo presentation available\n\n\nDominic Magirr\nAstraZeneca\nUnblinded sample-size reassessment in time-to-event clinical trials\nNo presentation available\n\n\nTobias Bluhmki\nUniversität Ulm\nAnalyzing non-monotonous time-to-event outcome probabilities in randomized clinical trials\nNo presentation available\n\n\nJennifer Rogers\nUniversity of Oxford\nThe analysis of recurrent events: A summary of methodology\nNo presentation available\n\n\nMouna Akacha\nNovartis, Basel\nRecurrent event data endpoints in chronic heart failure studies: What is the estimand of interest?\nNo presentation available\n\n\nEkkehard Glimm\nNovartis, Basel\nSample size and interim analysis considerations for recurrent event data analyses\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n04.05.2016: BBS Seminar: Adaptive Designs\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nFranz König\n\nRegulatory and methodological issues in adaptive designs for confirmatory trials\nlink\n\n\nPeter Bauer\n\nDMC membership experience\nlink\n\n\nDavid Lawrence\n\nUsing a DMC for dose selection in a phase IIb/III adaptive design: the INHANCE study\nlink\n\n\nAlexander Strasak\n\nAdaptive seamless phase II/III study in gastric cancer\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n28.04.2016: BBS Spring Seminar\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKaspar Rufibach\n\nEvent projection: quantify uncertainty and manage expectations of broader teams\nlink\n\n\nBeat Neuenschwander\n\nPredicting milestone events for time-to-event trials\nlink\n\n\nMelissa Penny\n\nModel-based public health impact and cost-effectiveness estimates informing the WHO recommendation on malaria vaccine RTS\nNo presentation available\n\n\nIain Bennett\n\nDesigning in Treatment Switching (case study review and recommendations)\nlink\n\n\nViktoriya Stalbovskaya\n\nPractical aspects of handling treatment switching in randomized clinical trials\nlink\n\n\nDaniel Sabanes\n\nCancer immunotherapies: Which efficacy endpoints and statistical analyses to use?\nlink\n\n\nAndrew Stone\n\nNon-Proportional Hazards – So What?\nlink\n\n\nKarine Lheritier\n\nComplex study design in patients with Hereditary Periodic Fevers\nNo presentation available\n\n\nDavid Dejardin\n\nBayesian dual endpoint decision making in combination studies\nlink\n\n\nAlessandro Matano\n\nBayesian approach for Combination Phase I Trials in Oncology\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n13.01.2016: BBS Seminar: Disease and Product Registries\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nTim Friede\n\nClinical registries: Use and Emerging Best Practices\nlink\n\n\nEva‐Maria Didden\n\nLearning and Predicting Real‐World Treatment Effect based on Randomized Controlled Trials and Registry Data – A Case Study in Rheumatoid Arthritis\nlink\n\n\nHeiner C. Bucher\n\nMaking Better Use of Registry Data in Designing Pragmatic Trials\nlink\n\n\nYvonne Geissbühler\n\nUse of Registries to Collect Pregnancy Data\nlink\n\n\nBrian Hennessy\n\nRegistries in Rare Diseases / Orphan Drugs along with 2 Case Studies\nNo presentation available\n\n\nHelene Karcher\n\nLeveraging Real‐World Registry Data to Optimize the Design of Phase 3 Studies – a Case Study in Schizophrenia\nlink\n\n\n\n\n\n\n\n\n\n\n27.10.2015: BBS Seminar: Prediction\nNo agenda available\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKaspar Rufibach\n\nBayesian Predictive Power: the bathtub problem\nlink\n\n\nEvgeny Degtyarev\n\nDesigning Phase 2 to predict success in Phase 3 study\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n23.06.2015: Joint BBS/EFSPI Seminar: Health Technology Assessment\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nChrissie Fletcher & Matthias Egger\nAmgen & University of Bern\nIMI GetReal Initiative Update\nNo presentation available\n\n\nPanelists\n\nExpert panel discussion on trends and burning issues, eg. Structured benefit risk and real world evidence; dual EMA-HTA consultation\nNo presentation available\n\n\nPascale Brasseur\nMedtronic\nOverview of HTA for medical devices and diagnostics\nNo presentation available\n\n\nSheryl Warttig\nNICE\nNICE’s approach to the development of guidance for medical devices and diagnostics\nNo presentation available\n\n\nKarsten Berndt\nRoche Diagnostics\nEUnetHTA core model applied to Colorectal Cancer screening\nNo presentation available\n\n\nValéry Risson\nNovartis\nUses of Social Media for Outcomes Research – results of a real-world pilot\nNo presentation available\n\n\nClaire Watkins\nAstraZeneca\nAdjusting overall survival for treatment switch/crossover\nNo presentation available\n\n\nPierre Ducorneau\nRoche, Basel\nUsing the EUnetHTA HTA core model as a framework for planning, generating and presenting evidence\nNo presentation available\n\n\nYovanna Castro\nRoche, Basel\nPredicting long term survival using nonparametric Bayesian methods: the melanoma case\nNo presentation available\n\n\nNathalie Barbier\nNovartis\nReimbursement challenges with new emerging cancer therapies\nNo presentation available\n\n\nWon Lee\nXcenda\nThe value of Oncology therapies and emerging access hurdles in Canada and the United States\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n13.04.2015: BBS Seminar: Bayesian Methods in Adaptive Dose-Finding Trials\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nDaniel Sabanes Bove\n\nBayesian Learning in Oncology: A Case Study\nlink\n\n\nYing Yuan\n\nBayesian Data Augmentation Continual Reassessment Method (DA-CRM) for Phase I Trials with Delayed Toxicities\nlink\n\n\nDaniel Lorand\n\nBayesian modelling for combination dose-escalation trial that incorporates pharmacokinetic data\nlink\n\n\n\n\n\n\n\n\n\n\n13.11.2014: Joint BBS-EFSPI Seminar: Data Sharing in Clinical Development\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nSabine Atzor\n\n Clinical Trial Data Transparency – Environment & Expectations\nlink\n\n\nStefan Driessen\n\n EFSPI position on EMA policy on publication of clinical data\nlink\n\n\nFranz König\n\n Big thunder\nlink\n\n\nRebecca Sudlow\n\n Overview of Data Sharing Initiatives in Industry and Current Experiences\nlink\n\n\nJanice Branson\n\n Practicalities of accessing and using data – Advice for Researchers\nlink\n\n\nSally Hollis\n\n Considerations for analysis plans for data sharing requests\nlink\n\n\nKatherine Tucker\n\n Principles to maintain patient confidentiality+H211\nlink\n\n\nGuilliaume Breton\n\n Patient Confidentiality Implementation\nlink\n\n\n\n\n\n\n\n\n\n\n02.10.2014: BBS Seminar: Meta-Analysis of Clinical Safety Data\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nStephen Evans\n\n Do meta-analyses of adverse events have adverse effects?\nlink\n\n\nBrenda Crowe\n\n Comparison of Bayesian and Frequentist Meta-Analytical Approaches for Analyzing Time to Event Data\nlink\n\n\nMichael Gaffney\n\n Model Selection in Meta‐Analysis of Clinical Safety Data – Fixed or Random Study Effect\nlink\n\n\nAmy Xia\n\n Bayesian Meta-Analysis in Drug Safety Evaluation\nlink\n\n\nJim Slattery\n\n Meta-analysis in EU regulation\nlink\n\n\nTarek A. Hammad\n\n Sources of Bias in Meta-analysis of RCTs\nlink\n\n\nMark Levenson\n\n Meta‐Analysis for Safety: Context and Examples at US FDA\nlink\n\n\n\n\n\n\n\n\n\n\n07.05.2014: BBS Seminar: Applications for statisticians working with “Real-World Data”\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nPamela Landsman-Blumberg\n\nApplications for statisticians working with “Real-World Data”\nNo presentation available\n\n\nFred Sorensen\n\n\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n04.02.2014: BBS seminar: Adaptive / Flexible Designs in early development\nNo agenda available\nNo recording available\n\n\n\nNo slides available ::: {.cell}\n:::\n\n\n18.06.2013: BBS Seminar: IPD meta-analysis of treatment-covariate interaction with a continuous predictor\nNo agenda available\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nWilli Sauerbrei, Patrick Royston, Benjamin Kasenda and Matthias Briel\n\nA method for IPD meta-analysis of treatment-covariate interaction with a continuous predictor in randomised trials\nlink\n\n\nWilli Sauerbrei and Patrick Royston\n\nTowards stratified medicine – instead of dichotomization\nlink\n\n\nWilli Sauerbrei and Patrick Royston\n\nA new strategy for meta-analysis of continuous covariates in observational studies with IPD\nlink\n\n\n\n\n\n\n\n\n\n\n04.06.2013: Joint BBS/EFSPI Seminar: Health Technology Assessment\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nMike Branson\n\nWelcome\nlink\n\n\nFred Sorenson\n\n Health Technology Assessment – Why is it so important?\nlink\n\n\nMatthias Egger and Mike Chambers\n\n Moving HTA forward: The challenges of incorporating real world evidence into Health Technology Assessment\nlink\n\n\nMike Chambers and Matthias Egger\n\n GetReal: Clinical effectiveness in drug development\nlink\n\n\nClaudia Nicolay\n\n Health Technology Assessment – What’s in for Stats?\nlink\n\n\nJens Grüger\n\n HTA and personalized healthcare\nlink\n\n\nSkip Olson\n\n HTA – Use of observational\nlink\n\n\nBruno Falissard\n\n The place of subjectivity in the French system (HAS): a good thing or an archaism?\nlink\n\n\nRalf Bender\n\n Biometrical topics of Health Technology Assessment in Germany\nlink\n\n\nFriedhelm Leverkus\n\n 30 Months AMNOG Health Technology Assessment: Outcomes and Issues\nlink\n\n\nLou Garrison\n\n HTA in Emerging Markets: A Framework and Examples\nlink\n\n\nRichard Nixon\n\n Using early health economic models to support drug development decisions\nlink\n\n\nChrissie Fletcher\n\n Using indirect treatment comparisons to support an HTA\nlink\n\n\nAll\n\nSummary of event\nlink\n\n\n\n\n\n\n\n\n\n\n28.11.2012: BBS Seminar: Optimal Design for Non-linear Models\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nAnthony Atkinson\nLondon School of Economics\nExperiments for Building Enzyme Kinetic Models\nNo presentation available\n\n\nTobias Mielke\nAptiv Solutions\nOptimal Population Designs for Non-linear Mixed Effects Models\nNo presentation available\n\n\nBarbara Bogacka\nQueen Mary College, University of London\nPopulation Optimum Design for Non-linear Mixed Effects Models in the Presence of Covariates\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n25.09.2012: BBS Seminar: Benefit-Risk & Comparative Effectiveness\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nAndrea Beyer\n\nUnderstanding the risk tolerance of regulatory assessors in Europe: the role of quantitative models in risk communication\nlink\n\n\nChristoph Dierig and Richard Nixon\n\nA case study using the BRAT framework for benefit risk assessment\nlink\n\n\nChristian Hove Rasmussen\n\nBenefit-risk assessment from a clinical point of view: a structured approach with focus on transparency\nlink\n\n\nRalf Bender\n\nBiometrical requirements in (early) benefit assessments\nlink\n\n\nFred Sorenson\n\nBenefit-risk assessment and comparative effectiveness research: are they really converging?\nlink\n\n\n\n\n\n\n\n\n\n\n09.07.2012: BBS Seminar: Emerging Topics in Pharmaceutical Statistics\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nStephen A. Julious\n\nSample sizes for multiple must-win trials\nlink\n\n\nEric Derobert\n\nA parameterized strategy of gatekeeping\nlink\n\n\nMouna Akacha & Günther Müller-Velten\n\nRecurrent event approaches in cardiovascular outcome trials\nNo presentation available\n\n\nLisa Hampson\n\nGroup sequential tests for delayed responses\nlink\n\n\n\n\n\n\n\n\n\n\n22.05.2012: BBS Seminar: Experiences in the Development and Implementation of Flexible Designs\nNo agenda available\nNo recording available\n\n\n\nNo slides available ::: {.cell}\n:::\n\n\n29.11.2011: BBS Seminar\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nBoris Choy\nBusiness School The University of Sydney\nNonignorable dropout models for longitudinal binary data with random effects: An application of Monte Carlo approximation through the Gibbs output\nNo presentation available\n\n\nMouna Akacha\nNovartis, Basel\nImplementing Current Regulatory Guidance on the Treatment of Missing Data: An Industry Perspective\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n16.09.2011: BBS Fall Conference: Current Topics in Pharmaceutical Statistics: Dose Finding and Multiregional Trials\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nAndy Grieve\n\n Dose Selection in Drug Development: What Can Go Wrong? Can we put it Right?\nlink\n\n\nDidier Renard\n\n Use of modeling & simulation to support design and analysis of a new dose and regimen finding study\nlink\n\n\nBjoern Bornkamp\n\n On the efficiency of two-stage adaptive designs\nlink\n\n\nGeorg Gutjahr\n\nPowerful Modification of Step Down Procedures for Dose Finding\nNo presentation available\n\n\nH.M. James Hung\n\n Planning and Analyzing Multi-regional Clinical Trials: A Regulatory Perspective\nlink\n\n\nPhilip Hougaard\n\n Global drug development strategies\nlink\n\n\nJorgen Seldrup\n\n Designing clinical trials in a multiregional regulatory environment\nNo presentation available\n\n\nKevin J. Carroll\n\n Consistency of treatment effect across regions in a multi-regional trial: reasonable goal or unrealistic requirement?\nlink\n\n\n\n\n\n\n\n\n\n\n21.07.2011: BBS Seminar Quantitative Benefit-Risk: What Matters to Whom and How? – Getting the Values and Weights\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nJohn Ferguson\n\nStructured Benefit-Risk Optimization (BRO): A Framework Quantitative Decision Support Tools\nlink\n\n\nGordon Francis\n\nClinical Perspective on Benefit-Risk Assessments\nlink\n\n\nLawrence Phillips\n\nQuantitative Benefit-Risk: Determining Values & Assessing Weights\nlink\n\n\nAndrea Beyer\n\nBeyond the Probability of Risk: Measuring Perception\nlink\n\n\n\n\n\n\n\n\n\n\n10.05.2011: BBS Spring Conference: Comparative Quantitative Assessments: Benefit-Risk & Effectiveness\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nChrissie Fletcher\n\nIndustry Perspective on Comparative Effectiveness Research (CER) and the impact of Health Technology Assessment (HTA) in Europe\nlink\n\n\nMelvin (Skip) Olson\n\nSome Issues with Indirect Comparisons\nlink\n\n\nFriedhelm Leverkus\n\nHealth Care Reform in Germany and Update on IQWiG Requirements\nlink\n\n\nJohn Doyle\n\nEffect of Comparative Effectiveness Research on Drug Development Innovation: a 360° Appraisal and Summary Discussion\nlink\n\n\nDeborah Ashby\n\nCurrent Methodological Approaches to Benefit-Risk Decision-Making\nlink\n\n\nJohn Ferguson\n\nStructured Benefit-Risk Optimization (BRO): State-of-the-art and Role of Fully Quantitative Decision Support Tools\nlink\n\n\nMichael Forstner\n\nConsiderations for Implementing a Quantitative Benefit-Risk Assessment\nlink\n\n\nRichard Nixon\n\nBenefit-Risk Assessment of Multiple Sclerosis Treatments: Lessons Learnt in the use of Multi-Criteria Decision Analysis\nlink\n\n\nJohn Doyle\n\nConvergence of CER and BRA and Concluding Summary Discussion\nlink\n\n\n\n\n\n\n\n\n\n\n07.05.2011: BBS Spring Seminar: Multiplicity in Clinical Trials\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nHuque Mohammad\n\nSome key multiplicity questions on primary and secondary endpoints of RCCTs and possible answers\nlink\n\n\nFerber Georg\n\nConfirmatory statistics in PK/PD studies\nlink\n\n\nKornelius Rohmeyer\n\ngMCP: A GUI for graphical multiple test procedures\nNo presentation available\n\n\nWolf Michael\n\nControl of the false discovery rate under dependence using the bootstrap and sub sampling\nlink\n\n\nMaurer Willi / Glimm Ekkehard\n\nMultiple and repeated testing of primary\nlink\n\n\n\n\n\n\n\n\n\n\n13.01.2011: BBS Seminar: Statistical Challenges in Biomedical Research\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKalisch Markus\n\n Can one extract causal information from high-dimensional observational data?\nlink\n\n\nSauerbrei Willi\n\n Regression model-building with continuous variables – multivariable fractional polynomials\nlink\n\n\n\n\n\n\n\n\n\n\n30.11.2010: BBS Seminar\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nHarald Binder\n\nFitting and evaluating risk prediction models with high-dimensional molecular data\nNo presentation available\n\n\nMartin Wolkewitz\n\nHealthcare epidemiology hospital-acquired infections statistical modeling of outbreaks\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n04.10.2010: BBS Fall Conference\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nHelmut Schäfer\nUniversity of Marburg\nOptimized and flexible designs for genome-wide associations studies\nNo presentation available\n\n\nMaximo Carreras\nRoche, Basel\nPoint Estimation in Two-Stage Adaptive Designs With Mid-Trial Treatment Selection\nNo presentation available\n\n\nDavid Lawrence\nNovartis, Basel\nThe A to Z of DMC interaction in a phase II/III adaptive design with treatment selection\nNo presentation available\n\n\nReinhard Eisebitt\nClinResearch\nMethods to protect the blinding, including controlled emergency unblinding, in adaptive design trials with flexible randomization schemes\nNo presentation available\n\n\nTim Friede\nUniversity of Göttingen\nThe role of DMCs in adaptive design trials: The perspective of a DMC member\nNo presentation available\n\n\nSue-Jane Wang\nFDA\nAdaptive Design Consideration: A Regulatory Perspective on How to Maintain Validity and Integrity of Trials\nlink\n\n\nJames Hung\nFDA\nEmerging Challenges in Design and Analysis of Non-inferiority Trials\nlink\n\n\nFranz König\nEMA\n\nNo presentation available\n\n\nRalf Bender\nIQWiG\nThe importance of Non-inferiority testing in benefit assessments of medical interventions\nlink\n\n\nHeinz Schmidli\nNovartis, Basel\nEstimating the placebo-effect in a non-inferiority trial: a case study\nNo presentation available\n\n\nGeorg Gutjahr, Werner Brannath, Peter Bauer\nBremen and Vienna\nUnblinded SampleSize Modification for Fisher’s Exact Test\nlink\n\n\n\n\n\n\n\n\n\n\n24.06.2010: BBS/EFSPI European Statistical Meeting on Oncology\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nBertil Jonsson\nMedical Products Agency\nUnderstanding Progression-free Survival\nNo presentation available\n\n\nMarc Buyse\nIDDI and University of Hasselt\nThe Time to Progression Ratio for Phase II Trials of Personalized Medicine\nNo presentation available\n\n\nStuart Bailey\nNovartis, Basel\nAdaptive Bayesian Designs for Phase I Oncology Trials\nNo presentation available\n\n\nSimon Wandel\nNovartis, Basel\nBayesian Hierarchical Modelling of Clinical Response in NSCLC Subpopulations\nNo presentation available\n\n\nClaire Watkins\nAstraZeneca\nIRESSA: A Journey of Experience from Broad to Biomarker Populations\nNo presentation available\n\n\nCong Chen\nMerck\nOptimal Cost-Effective Go-No Go Decisions in Late-Stage Oncology Drug Development\nNo presentation available\n\n\nJonas Wiedemann\nRoche, Basel\nOncology Dose Finding – A Case Study\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n28.04.2010: BBS Seminar Epidemiology\nAgenda\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nNoah Jamie Robinson\nRoche, Basel\nEpidemiology: the basics and in practice (at Roche)\nNo presentation available\n\n\nJim Young\nBasel Institute for Clinical Epidemiology and Biostatistics\nApproximate Bayesian methods for the analysis of epidemiological data\nlink\n\n\n\n\n\n\n\n\n\n\n12.03.2010: BBS Seminar\nNo agenda available\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nBenda Norbert\n\nThe use of adaptive designs in dose finding studies\nlink\n\n\nBrannath Werner\n\nChallenges in the application of adaptive phase II/III designs in oncology\nlink\n\n\nFleischer Frank\n\nStatistical modeling in the context of progression-free survival\nlink\n\n\nFriede Tim\n\nBlinded sample size reestimation with count data\nlink\n\n\nGlimm Ekkehard\n\nSome lessons learned from designing and adaptive clinical trial with time-to-event as the primary endpoint\nlink\n\n\nGuthjahr Georg\n\nMultiple Type I error control in response adaptive Phase II/III designs with treatment selection\nlink\n\n\nWang Sue-Jane\n\nU.S. FDA Draft Guidance on Adaptive Design Clinical Trials – Statistical Considerations and Issues\nlink\n\n\n\n\n\n\n\n\n\n\n12.01.2010: BBS Seminar: Enhanced Statistical Methodology\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nLeonhard Held\nUniversity of Zürich\nA Nomogram for P Values\nNo presentation available\n\n\nKaspar Rufibach\nUniversity of Zürich\nEstimation of two ordered monotone regression curves\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n07.12.2009: BBS Seminar: Challenges and Evaluation of Biomarkers\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nEric Holmgren\nGenentech\nQuantifying the usefulness of PD biomarkers in phase 2 screening trials of oncology drugs\nNo presentation available\n\n\nMartin Schumacher\nNovartis, Basel\nClass prediction with gene expression data\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n26.10.2009: BBS Seminar: Operational and Implementation Considerations in Adaptive Designs\nAgenda\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nEva Miller\nICON Clinical Research\nLogistical Considerations in the Implementation of Adaptive Trial Designs\nNo presentation available\n\n\nNorbert Benda\nNovartis, Basel\nConsiderations and Experiences in Adaptive Dose Finding\nNo presentation available"
  },
  {
    "objectID": "events_upcoming.html",
    "href": "events_upcoming.html",
    "title": "Basel Biometric Society (BBS): Upcoming events",
    "section": "",
    "text": "Date\nEvent\nType of event\nAgenda\nRegistration\nComment\n\n\n\n\n19.04.2023\nAdaptive Designs and Multiple Testing Procedures Workshop\nWorkshop\nAgenda\nRegistration\n3 days, 19.-21.04.2023\n\n\n21.06.2023\nNext Generation event on soft-skills, professional development, and networking\nSeminar\nAgenda\n\n\n\n\n03.09.2023\nCEN2023 Conference: From Data to Knowledge. Advancing Life Sciences.\nConference\nAgenda\nRegistration\n5 days, 03.-07.09.2023"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Basel Biometric Society (BBS), a section of the Austrian-Swiss region of the international biometric society (ROeS)",
    "section": "",
    "text": "President\nHans Ulrich Burger, F. Hoffmann-La Roche, Basel.\nContact\n\n\nE-mail announcements of events\nIf you would like to receive e-mail announcements of upcoming events please send an email to Bibiana Blatna.\n\n\nPartner organizations\nBasel Epidemiology Seminar"
  },
  {
    "objectID": "purpose.html",
    "href": "purpose.html",
    "title": "BBS purpose",
    "section": "",
    "text": "Purpose\nThe Basel Biometric Society (BBS) is a section of the ROeS, the Austrian Swiss Region of the International Biometric Society (IBS). BBS is an independent, non-profit organization which provides a forum for discussions of how to apply statistical methods in biological and medical science.\nBBS statutes."
  },
  {
    "objectID": "trainings_past.html",
    "href": "trainings_past.html",
    "title": "Past trainings: agendas, slidedecks, recordings",
    "section": "",
    "text": "10.02.2023: Good Software Engineering Practice for R Packages\nProgram\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKevin Kunzmann, Friedrich Pahlke, Daniel Sabanés Bové\nBoehringer Ingelheim, rpact, Roche\nCollection of all materials\nlink\n\n\n\n\n\n\n\n\n\n\n13.09.2022: Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact\nProgram\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKaspar Rufibach, Marc Vandemeulebroecke, Gernot Wassmer, Marcel Wolbers\nRoche, Novartis, rpact, Roche\nCollection of all materials\nlink\n\n\n\n\n\n\n\n\n\n\n29.03.2022: Graphical approaches to multiple test problems\nProgram\nRecording\nRecording 2\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nMarc Vandemeulebroecke\nNovartis, Basel\nWelcome\nNo presentation available\n\n\nEkkehard Glimm, Frank Bretz & Dong Xi\nNovartis & Gilead\nGraphical approaches to multiple test problems\nlink\n\n\n\n\n\n\n\n\n\n\n21.02.2022: Machine Learning in clinical drug development\nProgram\nRecording\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nMarkus Lange, Lorenz Uhlmann\nNovartis, Basel\nMachine Learning in clinical drug development\nlink\n\n\nMarkus Lange, Lorenz Uhlmann\nNovartis, Basel\nQuestions from the chat, with answers\nlink\n\n\nMarkus Lange, Lorenz Uhlmann\nNovartis, Basel\nR exercises\nlink\n\n\nMarkus Lange, Lorenz Uhlmann\nNovartis, Basel\nDataset used for exercises\nlink\n\n\n\n\n\n\n\n\n\n\n02.02.2021: BBS Training Series 2021: A gentle Introduction to Causal Thinking\nProgram\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nGiusia Moffa\nUniversity of Basel\nA gentle introduction to causal thinking: concepts and definitions\nlink\n\n\nBjörn Bornkamp\nNovartis, Basel\nDrug development, the ICH E9 addendum and causal inference\nlink\n\n\nDominik Heinzmann\nRoche, Basel\nPractical application with implementation details: Estimating the causal treatment effect in a subgroup defined by a post-baseline biomarker\nlink\n\n\n\n\n\n\n\n\n\n\n19.08.2019: BBS/BES Causal inference course\nProgram\nNo recording available\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nMiguel Hernan\n\n\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n01.03.2018: BBS Course: Group-Sequential and Adaptive Designs\nProgram\nNo recording available\n\n\n\n\n\n\n\n\n\n\n\nSpeaker\nInstitution\nTitle\nDownload slides\n\n\n\n\nKaspar Rufibach, Daniel Sabanés Bové, Marc Vandemeulebroecke, Marcel Wolbers\n\n\nNo presentation available\n\n\n\n\n\n\n\n\n\n\n05.06.2014: Workshop Adaptive Designs and Multiple Testing Procedures\nProgram\nNo recording available"
  },
  {
    "objectID": "updates.html",
    "href": "updates.html",
    "title": "Updates on this page",
    "section": "",
    "text": "2023/04/12: Uploaded slides for BBS seminar “Quantification of risk: ask the right questions or time to apply the estimand framework to safety!”. Test!!!\n2023/03/21: Uploaded slides and added time stamps to recording for Joint BES / BBS seminar “Real-World Data Quality – Assessing data quality and demonstrating fitness-for-purpose”.\n2023/03/15: Uploaded link to recording for Joint BES / BBS seminar “Real-World Data Quality – Assessing data quality and demonstrating fitness-for-purpose”.\n2023/03/08: First announcement of seminar Next Generation event on soft-skills, professional development, and networking.\n2023/10/02: Added announcement of seminar Joint BES / BBS seminar “Real-World Data Quality – Assessing data quality and demonstrating fitness-for-purpose”.\n2023/10/02: Added materials of an amazing training Good Software Engineering Practice for R Packages.\n2023/01/17: Added announcement of workshop Adaptive Designs and Multiple Testing Procedures Workshop.\n2023/01/09: Added announcement of seminar Quantification of risk: ask the right questions or time to apply the estimand framework to safety!.\n2022/12/16: Added recording and slide decks of joint EFSPI & BBS virtual event on “Addressing intercurrent events: Treatment policy and hypothetical strategies (Day 2)”.\n2022/12/14: Added recording of Next Generation Networking Seminar.\n2022/12/09: Added recording and slide decks of joint EFSPI & BBS virtual event on “Addressing intercurrent events: Treatment policy and hypothetical strategies (Day 1)”.\n2022/11/25: Moved this page to quarto implying a slightly different look.\n2022/09/19: Added final version of material of BBS course Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact.\n2022/07/20: Added recording and slide decks of seminar “On market approval and market access: Breaking the linear thinking or how to innovate in a crowded space?”.\n2022/07/01: Added recording, slide decks of seminar on “Registry studies and health technology assessment (HTA)”.\n2022/06/15: Added 1st announcement of seminar on “On market approval and market access: Breaking the linear thinking or how to innovate in a crowded space?”.\n2022/05/31: Added recording, slidedeck of transforming drug development and BBS assembly.\n2022/05/21: Added 2nd announcement of seminar on “Registry studies and HTA”.\n2022/05/13: Location has changed for spring seminar on “Transforming drug development” and bi-yearly BBS assembly. Note, the new location is: Novartis Campus, Auditorium 510_U1\n2022/04/20: Training on advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact is FULLY BOOKED.\n2022/04/11: Added announcement of spring seminar on “Transforming drug development”.\n2022/03/30: Added recording, slidedeck of graphical approaches to multiple test problems training.\n2022/03/21: Added announcement of seminar on “Registry studies and health technology assessment (HTA)”.\n2022/03/15: Added recording, slidedeck, exercises (incl. dataset) of machine learning training.\n2022/02/28: Added new version of statutes with minor updates."
  },
  {
    "objectID": "trainings/20220913/20220913_gsd_adaptive.html",
    "href": "trainings/20220913/20220913_gsd_adaptive.html",
    "title": "Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact",
    "section": "",
    "text": "1 Purpose of this document\nMaterials for the BBS training Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact, held in Basel on 13th September 2022 by Kaspar Rufibach, Marc Vandemeulebroecke, Gernot Wassmer, and Marcel Wolbers.\n\n\n2 Documents\n\n\n\n\n\nPresenter\nTitle\nSlides\nMarkdown accompanying slides\n\n\n\n\nKaspar Rufibach\nEfficient use of futility and efficacy interim analyses in group-sequential designs\nX\nX\n\n\nMarc Vandemeulebroecke\nIntroduction adaptive trials & sample size re-calculation\nX\n\n\n\nGernot Wassmer\nIntroduction to rpact\nX\n\n\n\nGernot Wassmer\nClosed testing principle in adaptive trials\nX\n\n\n\nMarcel Wolbers\nMulti-arm multi-stage designs\nX\n\n\n\nFrank Bretz and Uli Burger\nAdaptive trials: Some general considerations\nX\n\n\n\n\n\n\n\nExercises and solutions for the entire course.\nDownload all files as .zip file."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "",
    "text": "This R markdown file contains the exercises of the BBS course “Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact”.\nAll materials related to this course are available on the BBS webpage at this link. Solutions to the exercises will also be available through that webpage after the course."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-1a-sample-size-calculation",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-1a-sample-size-calculation",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 1a (Sample size calculation)",
    "text": "Exercise 1a (Sample size calculation)\nCalculate the required number of events and timing of analysis for OS using the information fraction of 60%. Use the rpact functions getDesignGroupSequential and getSampleSizeSurvival.\nSolution:\n\n# basic parameters\ninfofrac <- c(0.6, 1)   # information fractions\nalpha <- 0.05\nbeta <- 0.2\naccrualTime <- c(0, 10)\naccrualIntensity <- 48  # 48 pts over 10 months\nrandoratio <- 2         # 2:1 randomization\nm2 <- 12                # median control\nm1 <- 16.9              # median treatment\ndo <- 0.05              # dropout same in both arms\ndoTime <- 12            # time at which dropout happens\n\n# provide your solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-1b-addition-of-a-futility-interim-analysis",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-1b-addition-of-a-futility-interim-analysis",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 1b (Addition of a futility interim analysis)",
    "text": "Exercise 1b (Addition of a futility interim analysis)\nNow add an interim analysis for futility ONLY (i.e. no stopping for efficacy possible) after 30% of information where we stop the trial if the observed hazard ratio is above 1.\nHint: Use significance levels from design with efficacy only, add futility interim with minimal alpha-spending. The argument userAlphaSpending in getDesignGroupSequential helps.\nSolution:\n\n# provide your solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-1c-power-loss-associated-with-the-futility-interim-analysis",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-1c-power-loss-associated-with-the-futility-interim-analysis",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 1c (Power loss associated with the futility interim analysis)",
    "text": "Exercise 1c (Power loss associated with the futility interim analysis)\nHow large is the power loss from adding this futility interim analysis, assuming we would not increase the number of events compared to the initial design above?\nTo compute the power loss of adding the futility, conservatively assuming it will be adhered to, i.e. we compute the power of the design with futility using the number of events of the design without futility.\nSolution:\n\n# provide your solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#bonus-exercise-1d-timing-of-os-events",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#bonus-exercise-1d-timing-of-os-events",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Bonus Exercise 1d (Timing of OS events)",
    "text": "Bonus Exercise 1d (Timing of OS events)\nHow many OS events would be expected to occur until exactly 16 and 24 months, respectively, from first patient randomized?\nHint: getEventProbabilities.\nSolution:\n\n# provide your solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-2a-the-alpha-calculus",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-2a-the-alpha-calculus",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 2a (the “alpha calculus”)",
    "text": "Exercise 2a (the “alpha calculus”)\nWe want to build in a “sanity check” mid-way through the trial. More precisely, we implement an interim analysis using the inverse normal method, with the following characteristics (all with respect to the primary endpoint):\n\nStop for futility if the investigational drug appears worse than Placebo\nStop for efficacy if the investigational drug appears “very significantly better” than Placebo (\\(p < 0.0001\\))\n\nWhich set of \\((\\alpha,\\alpha_0,\\alpha_1,\\alpha_2)\\) satisfies these conditions?\nHint: Use getDesignInverseNormal with a user-defined alpha-spending function and a binding futility boundary.\nSolution:\n\n# type solution here\n\nWhat regulatory issues could this raise?\nSolution"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-2b-early-stopping-and-sample-size-adaptation",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-2b-early-stopping-and-sample-size-adaptation",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 2b (early stopping and sample size adaptation)",
    "text": "Exercise 2b (early stopping and sample size adaptation)\n\nAt the interim analysis after \\(n_1\\) = 50 patients per group, we observe an average ADAS-Cog improvement of 4 points under the investigational drug and of 1 point under Placebo. Should we stop or continue the trial?\n\nHint: getDataset to define the input dataset and getAnalysisResults to analyse it.\nSolution\n\n# type solution here\n\n\nAt the same time, there is a change in strategy, and we now want 90% power at an improvement of 4 points over placebo. Determine the sample size per treatment group for the second stage of the trial, in light of the interim results.\n\nHint: Calculate second stage sample size using getSampleSizeMeans with type I error equal to the conditional rejection probability from the previous part.\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-2c-final-inference",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-2c-final-inference",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 2c (final inference)",
    "text": "Exercise 2c (final inference)\nIn the second stage of the trial, we observe an average ADAS-Cog improvement of only 3 points under the investigational drug and of 1 point under Placebo.\n\nCan we reject the null hypothesis and claim superiority of the investigational drug over placebo?\n\nSolution\n\n# type solution here\n\n\nCompute the overall (“exact”) p-value and confidence interval for the adaptive trial.\n\nSolution\n\nWhat would a “naive” z-test have concluded, based on all observations and ignoring the adaptive nature of the trial? What is your interpretation of the situation?\n\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-3a-sample-size-calculation",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-3a-sample-size-calculation",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 3a (sample size calculation)",
    "text": "Exercise 3a (sample size calculation)\nWhat is the necessary sample size to achieve 90% power if the failure rates are assumed to be \\(\\pi_1 = 0.40\\) and \\(\\pi_2 = 0.60\\)? What is the optimum allocation ratio?\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-3b-boundary-plots",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-3b-boundary-plots",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 3b (boundary plots)",
    "text": "Exercise 3b (boundary plots)\nIllustrate the decision boundaries on different scales.\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-3c-power-assessment",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-3c-power-assessment",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 3c (power assessment)",
    "text": "Exercise 3c (power assessment)\nSuppose that \\(N = 280\\) subjects were planned for the study. What is the power if the failure rate in the active treatment group is \\(\\pi_1 = 0.50\\)?\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-3d-power-illustration",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-3d-power-illustration",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 3d (power illustration)",
    "text": "Exercise 3d (power illustration)\nIllustrate power, expected sample size, and early/futility stop for a range of alternative values.\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-4a-assess-power",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-4a-assess-power",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 4a (assess power)",
    "text": "Exercise 4a (assess power)\nUse the inverse normal method to allow for the sample size increase and compare the test characteristics with the group sequential design from Example 3.\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-4b-illustrate-power-difference",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-4b-illustrate-power-difference",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 4b (illustrate power difference)",
    "text": "Exercise 4b (illustrate power difference)\nIllustrate the gain in power when using the adaptive sample size recalculation.\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-4c-histogram-of-sample-sizes",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-4c-histogram-of-sample-sizes",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 4c (histogram of sample sizes)",
    "text": "Exercise 4c (histogram of sample sizes)\nCreate a histogram for the attained sample size of the study when using the adaptive sample size recalculation. How often will the maximum sample size be achieved?\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-5a-first-stage-and-conditional-power",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-5a-first-stage-and-conditional-power",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 5a (First stage and conditional power)",
    "text": "Exercise 5a (First stage and conditional power)\nSuppose, at the first stage, the following results were obtained:\n\n\n\narm\nn\nmean\nstd\n\n\n\n\n1\n19\n3.11\n1.77\n\n\n2\n22\n3.87\n1.23\n\n\n3\n23\n4.12\n1.64\n\n\ncontrol\n21\n3.02\n1.72\n\n\n\nPerform the closed test and assess the conditional power in order to decide which treatment arm(s) should be selected and if the sample size should be redefined.\nSolution\n\n# Define input data (in rpact, the *last* group refers to control) and other parameters\ndataExample <- getDataset(\n  n1      = c(19),\n  n2      = c(22),\n  n3      = c(23),\n  n4      = c(21),\n  means1  = c(3.11),\n  means2  = c(3.87),\n  means3  = c(4.12),\n  means4  = c(3.02),\n  stDevs1 = c(1.77),\n  stDevs2 = c(1.23),\n  stDevs3 = c(1.64),\n  stDevs4 = c(1.72)\n)\n\nalpha <- 0.025\nintersectionTest <- \"Dunnett\"\nvarianceOption <- \"overallPooled\"\nnormalApproximation <- FALSE\n\n# Now define the design via getDesignInverseNormal,\n# then analyse the data using getAnalysisResults\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-5b-second-stage",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-5b-second-stage",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 5b (Second stage)",
    "text": "Exercise 5b (Second stage)\nSuppose it was decided to drop treatment arm 1 for stage 2 and leave the sample size for the remaining arms unchanged. For the second stage, the following results were obtained:\n\n\n\narm\nn\nmean\nstd\n\n\n\n\n2\n23\n3.66\n1.11\n\n\n3\n19\n3.98\n1.21\n\n\ncontrol\n22\n2.99\n1.82\n\n\n\nPerform the closed test and discuss whether or not to stop the study and determine overall \\(p\\,\\)-values and confidence intervals.\nSolution\n\ndataExample <- getDataset(\n  n1      = c(19, NA),\n  n2      = c(22, 23),\n  n3      = c(23, 19),\n  n4      = c(21, 22),\n  means1  = c(3.11, NA),\n  means2  = c(3.87, 3.66),\n  means3  = c(4.12, 3.98),\n  means4  = c(3.02, 2.99),\n  stDevs1 = c(1.77, NA),\n  stDevs2 = c(1.23, 1.11),\n  stDevs3 = c(1.64, 1.21),\n  stDevs4 = c(1.72, 1.82)\n)\n\n# Now analyse the data using getAnalysisResults\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-5c-intersection-tests",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-5c-intersection-tests",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 5c (Intersection tests)",
    "text": "Exercise 5c (Intersection tests)\nWould the Bonferroni and the Simes test intersection tests provide the same results?\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-6a-accrual-and-follow-up-time-given",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-6a-accrual-and-follow-up-time-given",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 6a (accrual and follow-up time given)",
    "text": "Exercise 6a (accrual and follow-up time given)\nThe patients should be recruited within 12 months assuming uniform accrual. Assume an additional follow-up time of 12 months, i.e., the study should be conducted within 2 years. Calculate the necessary number of events and patients (total and per month) in order to reach power 90% with the assumed median survival times if the survival time is exponentially distributed. Under the postulated assumption, estimate interim and final analysis time.\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-6b-follow-up-time-and-absolue-intensity-given",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-6b-follow-up-time-and-absolue-intensity-given",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 6b (follow-up time and absolue intensity given)",
    "text": "Exercise 6b (follow-up time and absolue intensity given)\nAssume that 25 patients can be recruited each month and that there is uniform accrual. Estimate the necessary accrual time if the planned follow-up time remains unchanged.\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-6c-accrual-time-and-max-number-of-patients-given",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-6c-accrual-time-and-max-number-of-patients-given",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 6c (accrual time and max number of patients given)",
    "text": "Exercise 6c (accrual time and max number of patients given)\nAssume that accrual stops after 16 months with 25 patients per month, i.e., after 400 patients were recruited. What is the estimated necessary follow-up time?\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-6d-staggered-patient-entry",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-6d-staggered-patient-entry",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 6d (staggered patient entry)",
    "text": "Exercise 6d (staggered patient entry)\nHow do the results change if in the first 3 months 15 patients, in the second 3 months 20 patients, and after 6 months 25 patients per month can be accrued?\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-7a-verify-results-by-simulation",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-7a-verify-results-by-simulation",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 7a (verify results by simulation)",
    "text": "Exercise 7a (verify results by simulation)\nAssume that the study from Example 6 is planned with 257 events and 400 patients under the assumptions that accrual stops after 16 months with 25 patients per month. Verify by simulation the correctness of the results obtained by the analytical formulae.\nSolution\n\n# type solution here"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-7b-assess-adaptive-survival-design",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_exercises.html#exercise-7b-assess-adaptive-survival-design",
    "title": "Exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 7b (assess adaptive survival design)",
    "text": "Exercise 7b (assess adaptive survival design)\nAssume now that a sample size increase up to a ten-fold of the originally planned number of events is foreseen. Conditional power 90% based on the observed hazard ratios is used to increase the number of events. Assess by simulation the magnitude of power increase when using the appropriate method.\nSimulate the Type I error rate when using\n\nthe group sequential method\nthe inverse normal method\n\nHint: Make sure that enough subjects are used in the simulation (set maxNumberOfSubjects = 3000 and no drop-outs)\nSolution\n\n# type solution here\n\n\nSystem: rpact 3.3.1, R version 4.2.2 (2022-10-31 ucrt), platform: x86_64-w64-mingw32\nUm Paket ‘rpact’ in Publikationen zu zitieren, nutzen Sie bitte:\nWassmer G, Pahlke F (2022). rpact: Confirmatory Adaptive Clinical Trial Design and Analysis. R package version 3.3.1, https://CRAN.R-project.org/package=rpact."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "",
    "text": "This R markdown file provides solutions to the exercises of the BBS course “Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact”.\nAll materials related to this course are available on the BBS webpage at this link."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-1a-sample-size-calculation",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-1a-sample-size-calculation",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 1a (Sample size calculation)",
    "text": "Exercise 1a (Sample size calculation)\nCalculate the required number of events and timing of analysis for OS using the information fraction of 60%. Use the rpact functions getDesignGroupSequential and getSampleSizeSurvival.\nSolution: We perform calculations at a one-sided significance level of 2.5% which gives the same sample size but is more compatible with the futility interim added in Part 1b.\n\n# basic parameters\ninfofrac <- c(0.6, 1)   # information fractions\nalpha <- 0.05/2         # one-sided\nbeta <- 0.2\naccrualTime <- c(0, 10)\naccrualIntensity <- 48  # 48 pts over 10 months\nrandoratio <- 2         # 2:1 randomization\nm2 <- 12                # median control\nm1 <- 16.9              # median treatment\ndo <- 0.05              # dropout same in both arms\ndoTime <- 12            # time at which dropout happens\n\nmaxn <- accrualIntensity * accrualTime[2]\n\n# Specify the group-sequential design \ndesign1 <- getDesignGroupSequential(sided = 1, alpha = alpha, beta = beta,\n    informationRates = infofrac, typeOfDesign = \"asOF\")\n\n# Calculate sample size for OS for this design\nsampleSizeOS1 <- getSampleSizeSurvival(design1,\n    allocationRatioPlanned = randoratio,    \n    median2 = m2, median1 = m1, \n    dropoutRate1 = do, dropoutRate2 = do, dropoutTime = doTime,\n    accrualTime = accrualTime, accrualIntensity = accrualIntensity)  \n\n# rpact summary\nsummary(sampleSizeOS1)\n\nSample size calculation for a survival endpoint\n\nSequential analysis with a maximum of 2 looks (group sequential design), overall \nsignificance level 2.5% (one-sided).\nThe sample size was calculated for a two-sample logrank test, \nH0: hazard ratio = 1, H1: treatment median(1) = 16.9, control median(2) = 12, \nplanned allocation ratio = 2, accrual time = 10, accrual intensity = 48, \ndropout rate(1) = 0.05, dropout rate(2) = 0.05, dropout time = 12, power 80%.\n\nStage                                         1      2 \nInformation rate                            60%   100% \nEfficacy boundary (z-value scale)         2.669  1.981 \nOverall power                            0.3123 0.8000 \nExpected number of subjects               480.0 \nNumber of subjects                        480.0  480.0 \nCumulative number of events               182.3  303.8 \nAnalysis time                              15.8   28.7 \nExpected study duration                    24.7 \nCumulative alpha spent                   0.0038 0.0250 \nOne-sided local significance level       0.0038 0.0238 \nEfficacy boundary (t)                     0.658  0.786 \nExit probability for efficacy (under H0) 0.0038 \nExit probability for efficacy (under H1) 0.3123 \n\nLegend:\n  (t): treatment effect scale"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-1b-addition-of-a-futility-interim-analysis",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-1b-addition-of-a-futility-interim-analysis",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 1b (Addition of a futility interim analysis)",
    "text": "Exercise 1b (Addition of a futility interim analysis)\nNow add an interim analysis for futility ONLY (i.e. no stopping for efficacy possible) after 30% of information where we stop the trial if the observed hazard ratio is above 1.\nHint: Use significance levels from design with efficacy only, add futility interim with minimal alpha-spending. The argument userAlphaSpending in getDesignGroupSequential helps.\nSolution:\nWe spend a minimal alpha of 0.00001 at the futility interim analysis and use the alpha-spending from the O’Brien-Fleming-type alpha-spending function for the efficacy interim and the final analysis. In rpact, the futilityBounds are specified on the \\(Z\\)-scale and an observed hazard ratio 1 at the futility interim corresponds to a \\(Z\\)-score of 0. This leads to the following code:\n\n# add the futility using the sig levels computed above and spending epsilon alpha at the futility\ndesign2 <- getDesignGroupSequential(informationRates = c(0.3, infofrac),\n                                    sided = 1, alpha = alpha, beta = beta,\n                                    typeOfDesign = \"asUser\", \n                                    userAlphaSpending = c(0, design1$alphaSpent),\n                                    futilityBounds = c(0, -Inf),\n                                    bindingFutility = FALSE)\n\n# Calculate sample size for this design\nsampleSizeOS2 <- getSampleSizeSurvival(design2,\n    allocationRatioPlanned = randoratio,    \n    median2 = m2, median1 = m1, \n    dropoutRate1 = do, dropoutRate2 = do, dropoutTime = doTime,\n    accrualTime = accrualTime, accrualIntensity = accrualIntensity)  \n\n# rpact summary\nsummary(sampleSizeOS2)\n\nSample size calculation for a survival endpoint\n\nSequential analysis with a maximum of 3 looks (group sequential design), overall \nsignificance level 2.5% (one-sided).\nThe sample size was calculated for a two-sample logrank test, \nH0: hazard ratio = 1, H1: treatment median(1) = 16.9, control median(2) = 12, \nplanned allocation ratio = 2, accrual time = 10, accrual intensity = 48, \ndropout rate(1) = 0.05, dropout rate(2) = 0.05, dropout time = 12, power 80%.\n\nStage                                         1      2      3 \nInformation rate                            30%    60%   100% \nEfficacy boundary (z-value scale)           Inf  2.669  1.981 \nFutility boundary (z-value scale)             0   -Inf \nOverall power                                 0 0.3361 0.8000 \nExpected number of subjects               480.0 \nNumber of subjects                        480.0  480.0  480.0 \nCumulative number of events                96.9  193.7  322.9 \nAnalysis time                              10.1   16.7   31.7 \nExpected study duration                    25.5 \nCumulative alpha spent                        0 0.0038 0.0250 \nOne-sided local significance level            0 0.0038 0.0238 \nEfficacy boundary (t)                         0  0.666  0.791 \nFutility boundary (t)                     1.000        \nOverall exit probability (under H0)      0.5000 0.0038 \nOverall exit probability (under H1)      0.0561 0.3361 \nExit probability for efficacy (under H0)      0 0.0038 \nExit probability for efficacy (under H1)      0 0.3361 \nExit probability for futility (under H0) 0.5000      0 \nExit probability for futility (under H1) 0.0561      0 \n\nLegend:\n  (t): treatment effect scale\n\n\nWe see that by adding the futility interim we increase the maximal number of events from 303.827705 to 322.8702626."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-1c-power-loss-associated-with-the-futility-interim-analysis",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-1c-power-loss-associated-with-the-futility-interim-analysis",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 1c (Power loss associated with the futility interim analysis)",
    "text": "Exercise 1c (Power loss associated with the futility interim analysis)\nHow large is the power loss from adding this futility interim analysis, assuming we would not increase the number of events compared to the initial design above?\nTo compute the power loss of adding the futility, conservatively assuming it will be adhered to, i.e. we compute the power of the design with futility using the number of events of the design without futility.\nSolution:\n\n# power of design with futility at the number of events without futility\npower <- getPowerSurvival(design2, allocationRatioPlanned = randoratio, \n    maxNumberOfEvents = ceiling(sampleSizeOS1$maxNumberOfEvents),\n    median2 = m2, median1 = m1, \n    dropoutRate1 = do, dropoutRate2 = do, dropoutTime = doTime,\n    accrualTime = accrualTime, accrualIntensity = accrualIntensity,\n    directionUpper = FALSE)\n\n# power, as compared to the specified 80%\npower$overallReject\n\n[1] 0.7763167\n\n\nSo the power loss of adding the futility amounts to 0.0236833."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#bonus-exercise-1d-timing-of-os-events",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#bonus-exercise-1d-timing-of-os-events",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Bonus Exercise 1d (Timing of OS events)",
    "text": "Bonus Exercise 1d (Timing of OS events)\nHow many OS events would be expected to occur until exactly 16 and 24 months, respectively, from first patient randomized?\nHint: getEventProbabilities.\nSolution:\n\n# Probability of an event until 16 months and 24 months  \nprobOS <- getEventProbabilities(time = c(16, 24), \n    allocationRatioPlanned = randoratio,    \n    lambda2 = getLambdaByMedian(m2),lambda1 = getLambdaByMedian(m1),\n    dropoutRate1 = do, dropoutRate2 = do, dropoutTime = doTime,\n    accrualTime = accrualTime, accrualIntensity = accrualIntensity)\nprobOS\n\nEvent probabilities at given time:\n\nUser defined parameters:\n  Time                                         : 16.00, 24.00 \n  Accrual time                                 : 10.00 \n  Accrual intensity                            : 48.0 \n  lambda(1)                                    : 0.041 \n  lambda(2)                                    : 0.0578 \n  Planned allocation ratio                     : 2 \n  Drop-out rate (1)                            : 0.050 \n  Drop-out rate (2)                            : 0.050 \n\nDefault parameters:\n  kappa                                        : 1 \n  Drop-out time                                : 12.00 \n\nTime and output:\n  Hazard ratio                                 : 0.710 \n  Maximum number of subjects                   : 480 \n  Cumulative event probabilities               : 0.3847, 0.5595 \n  Event probabilities (1)                      : 0.3506, 0.5193 \n  Event probabilities (2)                      : 0.4529, 0.6400 \n\nLegend:\n  (i): values of treatment arm i\n\n# Expected number of OS events \nmaxn * probOS$overallEventProbabilities\n\n[1] 184.6677 268.5770\n\n\nExpected number of events are 185 and 269 until months 16 and 24, respecticely."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-2a-the-alpha-calculus",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-2a-the-alpha-calculus",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 2a (the “alpha calculus”)",
    "text": "Exercise 2a (the “alpha calculus”)\nWe want to build in a “sanity check” mid-way through the trial. More precisely, we implement an interim analysis using the inverse normal method, with the following characteristics (all with respect to the primary endpoint):\n\nStop for futility if the investigational drug appears worse than Placebo\nStop for efficacy if the investigational drug appears “very significantly better” than Placebo (\\(p < 0.0001\\))\n\nWhich set of \\((\\alpha,\\alpha_0,\\alpha_1,\\alpha_2)\\) satisfies these conditions?\nHint: Use getDesignInverseNormal with a user-defined alpha-spending function and a binding futility boundary.\nSolution:\nThe exercise specifies alpha=0.025, alpha0=0.5 (equivalent to a binding futility boundary at a \\(Z\\)-score of 0), and alpha1=0.0001. We compute alpha2 as follows.\n\nd <- getDesignInverseNormal(typeOfDesign = \"asUser\", userAlphaSpending = c(0.0001,0.025), \n  futilityBounds = 0, bindingFutility = TRUE)\nd\n\nDesign parameters and output of inverse normal combination test design:\n\nUser defined parameters:\n  Type of design                               : User defined alpha spending \n  Futility bounds (binding)                    : 0.000 \n  Binding futility                             : TRUE \n  User defined alpha spending                  : 0.0001, 0.0250 \n\nDerived from user defined parameters:\n  Maximum number of stages                     : 2 \n  Stages                                       : 1, 2 \n  Information rates                            : 0.500, 1.000 \n\nDefault parameters:\n  Significance level                           : 0.0250 \n  Type II error rate                           : 0.2000 \n  Two-sided power                              : FALSE \n  Test                                         : one-sided \n  Tolerance                                    : 1e-08 \n  Type of beta spending                        : none \n\nOutput:\n  Cumulative alpha spending                    : 0.0001, 0.0250 \n  Critical values                              : 3.719, 1.955 \n  Stage levels (one-sided)                     : 0.00010, 0.02531 \n\n\nThis yields \\(\\alpha_2\\) = d$stageLevels[2] = 0.0253.\nWhat regulatory issues could this raise?\nSolution The Regulator may not like that the final test is performed at a greater level (\\(\\alpha_2\\)) than the overall level (\\(\\alpha\\)). This is caused by cutting off a greater rejection region by the futility stop (right of \\(\\alpha_0\\)) than adding to it by the efficacy stop (left of \\(\\alpha_1\\)), and by compensating for this imbalance through a higher conditional error function (\\(\\alpha_2 > \\alpha\\); so-called “buy-back alpha” from the futility stop)."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-2b-early-stopping-and-sample-size-adaptation",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-2b-early-stopping-and-sample-size-adaptation",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 2b (early stopping and sample size adaptation)",
    "text": "Exercise 2b (early stopping and sample size adaptation)\n\nAt the interim analysis after \\(n_1\\) = 50 patients per group, we observe an average ADAS-Cog improvement of 4 points under the investigational drug and of 1 point under Placebo. Should we stop or continue the trial?\n\nHint: getDataset to define the input dataset and getAnalysisResults to analyse it.\nSolution\nWe should continue the trial, since our drug is neither worse nor very significantly better than Placebo:\n\ndat <- getDataset(means1 = 4, means2 = 1, \n                  stDev1 = 10, stDev2 = 10, \n                  n1 = 50, n2 = 50)\n\nresult1 <- getAnalysisResults(design = d, dataInput = dat, nPlanned = 100,normalApproximation = TRUE)\n\nsummary(result1)\n\nAnalysis results for a continuous endpoint\n\nSequential analysis with 2 looks (inverse normal combination test design).\nThe results were calculated using a two-sample t-test (one-sided), \nnormal approximation test, equal variances option.\nH0: mu(1) - mu(2) = 0 against H1: mu(1) - mu(2) > 0. \nThe conditional power calculation with planned sample size is based on \noverall effect = 3 and overall standard deviation = 10.\n\nStage                                                 1                2 \nFixed weight                                      0.707            0.707 \nEfficacy boundary (z-value scale)                 3.719            1.955 \nFutility boundary (z-value scale)                     0 \nCumulative alpha spent                          <0.0001           0.0250 \nStage level                                     <0.0001           0.0253 \nCumulative effect size                            3.000                  \nCumulative (pooled) standard deviation           10.000                  \nStage-wise test statistic                         1.500                  \nStage-wise p-value                               0.0668                  \nInverse normal combination                        1.500                  \nTest action                                    continue                  \nConditional rejection probability                0.1030                  \nPlanned sample size                                                  100 \nConditional power                                                 0.5931 \n95% repeated confidence interval        [-4.438; 10.438]                 \nRepeated p-value                                                         \n\n\n\\(\\rightarrow\\) \\(p_1=0.0668\\), and \\(\\alpha_1=0.0001<0.0668<0.5=\\alpha_0\\).\n\nAt the same time, there is a change in strategy, and we now want 90% power at an improvement of 4 points over placebo. Determine the sample size per treatment group for the second stage of the trial, in light of the interim results.\n\nHint: Calculate second stage sample size using getSampleSizeMeans with type I error equal to the conditional rejection probability from the previous part.\nSolution\nWe compute the sample size necessary for 90% conditional power; we round up and check:\n\ngetSampleSizeMeans(alpha=result1$conditionalRejectionProbabilities[1], beta = 0.1, \n  alternative = 4, stDev = 10, normalApproximation = TRUE)$nFixed\n\n[1] 162.0456\n\nresult2 <- getAnalysisResults(design = d, dataInput = dat, nPlanned = 164, thetaH1 = 4,\n  assumedStDev = 10, normalApproximation = TRUE)\n\nsummary(result2)\n\nAnalysis results for a continuous endpoint\n\nSequential analysis with 2 looks (inverse normal combination test design).\nThe results were calculated using a two-sample t-test (one-sided), \nnormal approximation test, equal variances option.\nH0: mu(1) - mu(2) = 0 against H1: mu(1) - mu(2) > 0. \nThe conditional power calculation with planned sample size is based on \nassumed effect = 4 and assumed standard deviation = 10.\n\nStage                                                 1                2 \nFixed weight                                      0.707            0.707 \nEfficacy boundary (z-value scale)                 3.719            1.955 \nFutility boundary (z-value scale)                     0 \nCumulative alpha spent                          <0.0001           0.0250 \nStage level                                     <0.0001           0.0253 \nCumulative effect size                            3.000                  \nCumulative (pooled) standard deviation           10.000                  \nStage-wise test statistic                         1.500                  \nStage-wise p-value                               0.0668                  \nInverse normal combination                        1.500                  \nTest action                                    continue                  \nConditional rejection probability                0.1030                  \nPlanned sample size                                                  164 \nConditional power                                                 0.9027 \n95% repeated confidence interval        [-4.438; 10.438]                 \nRepeated p-value                                                         \n\n\n\\(\\rightarrow\\) \\(n_2=82\\) per treatment group"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-2c-final-inference",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-2c-final-inference",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 2c (final inference)",
    "text": "Exercise 2c (final inference)\nIn the second stage of the trial, we observe an average ADAS-Cog improvement of only 3 points under the investigational drug and of 1 point under Placebo.\n\nCan we reject the null hypothesis and claim superiority of the investigational drug over placebo?\n\nSolution\nUsing the inverse normal method as planned, we can reject the null hypothesis and claim superiority of the investigational drug over placebo. More precisely, the combination test statistic after the second stage is 1.966, exceeding the critical value \\(u_{0.0253}=1.955\\) (where \\(u_\\alpha\\) is the \\((1-\\alpha)\\)-quantile of \\(N(0,1)\\)). Note that we test at the local level \\(\\alpha_2=0.0253\\).\n\ndat2 <- getDataset(means1 = c(4,3), means2 = c(1,1), \n                   stDev1 = c(10,10), stDev2 = c(10,10),\n                   n1 = c(50,82), n2 = c(50,82))\n\nsummary(getAnalysisResults(design = d, dataInput = dat2, normalApproximation = TRUE))\n\nAnalysis results for a continuous endpoint\n\nSequential analysis with 2 looks (inverse normal combination test design).\nThe results were calculated using a two-sample t-test (one-sided), \nnormal approximation test, equal variances option.\nH0: mu(1) - mu(2) = 0 against H1: mu(1) - mu(2) > 0.\n\nStage                                                 1                2 \nFixed weight                                      0.707            0.707 \nEfficacy boundary (z-value scale)                 3.719            1.955 \nFutility boundary (z-value scale)                     0 \nCumulative alpha spent                          <0.0001           0.0250 \nStage level                                     <0.0001           0.0253 \nCumulative effect size                            3.000            2.379 \nCumulative (pooled) standard deviation           10.000            9.968 \nStage-wise test statistic                         1.500            1.281 \nStage-wise p-value                               0.0668           0.1002 \nInverse normal combination                        1.500            1.966 \nTest action                                    continue           reject \nConditional rejection probability                0.1030                  \n95% repeated confidence interval        [-4.438; 10.438] [0.014 ; 4.863 ]\nRepeated p-value                                                         \nFinal p-value                                                     0.0243 \nFinal confidence interval                                  [0.014; 4.933]\nMedian unbiased estimate                                           2.450 \n\n\n\nCompute the overall (“exact”) p-value and confidence interval for the adaptive trial.\n\nSolution\nFrom the commands above we also obtain: \\(p=0.02435; \\; CI=(0.014,4.93)\\)\n\nWhat would a “naive” z-test have concluded, based on all observations and ignoring the adaptive nature of the trial? What is your interpretation of the situation?\n\nSolution\nA “naive” z-test would not have been able to reject the null hypothesis:\n\\[z = \\sqrt{\\frac{n_1 + n_2}{2}}\\frac{\\bar x - \\bar y}{\\sigma} = \\sqrt{\\frac{132}{2}} \\frac{\\frac{50\\cdot 4 + 82 \\cdot 3}{132}- 1}{10} = 1.9325 < 1.960 = u_{0.025}\\]\nIn rpact, use the following commands:\n\ndGS <- getDesignGroupSequential(typeOfDesign = \"asUser\", userAlphaSpending = c(0.0001,0.025),\n  futilityBounds = 0, bindingFutility = TRUE)\n\ndat3 <- getDataset(cumulativeMeans1 = c(4,(50*4+82*3)/132), cumulativeMeans2 = c(1,1),\n  cumulativeStDev1 = c(10,10), cumulativeStDev2 = c(10,10), \n  cumulativeN1 = c(50,132), cumulativeN2 = c(50,132))\n\nsummary(getAnalysisResults(design = dGS, dataInput = dat3, normalApproximation = TRUE))\n\nAnalysis results for a continuous endpoint\n\nSequential analysis with 2 looks (group sequential design).\nThe results were calculated using a two-sample t-test (one-sided), \nnormal approximation test, equal variances option.\nH0: mu(1) - mu(2) = 0 against H1: mu(1) - mu(2) > 0.\n\nStage                                                 1                2 \nFixed weight                                        0.5                1 \nEfficacy boundary (z-value scale)                 3.719            1.955 \nFutility boundary (z-value scale)                     0 \nCumulative alpha spent                          <0.0001           0.0250 \nStage level                                     <0.0001           0.0253 \nCumulative effect size                            3.000            2.379 \nCumulative (pooled) standard deviation           10.000           10.000 \nOverall test statistic                            1.500            1.933 \nOverall p-value                                  0.0668           0.0266 \nTest action                                    continue           accept \nConditional rejection probability                0.1030                  \n95% repeated confidence interval        [-4.438; 10.438] [-0.027; 4.785 ]\nRepeated p-value                                                         \nFinal p-value                                                     0.0263 \nFinal confidence interval                                 [-0.027; 4.816]\nMedian unbiased estimate                                           2.390 \n\n\nNote that the definition of dat3 with the “cumulative” commands is necessary because otherwise always a “global” variance (accounting for the mean difference in the stages) is calculated.\nHere we ignore the adaptive nature of the trial: we lump all data together (ignoring the sample size adaptation), and we test at the nominal level \\(\\alpha =0.025\\) (ignoring the possibility of early stopping). The second stage of the trial, showing less of a treatment effect, carries greater weight in this “naive” (that is, incorrect) version of the test. Note that it can go both ways: in other examples, the adaptive (correct) version of the test may be the one that fails to reject the null hypothesis. In less borderline situations, both tests will lead to the same conclusion. Proposals have been made in the literature for dealing with borderline situations."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-3a-sample-size-calculation",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-3a-sample-size-calculation",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 3a (sample size calculation)",
    "text": "Exercise 3a (sample size calculation)\nWhat is the necessary sample size to achieve 90% power if the failure rates are assumed to be \\(\\pi_1 = 0.40\\) and \\(\\pi_2 = 0.60\\)? What is the optimum allocation ratio?\nSolution\nThe summary command provides a table for the study design parameters:\n\ndGS <- getDesignGroupSequential(informationRates = c(0.5,0.75,1), alpha = 0.025, beta = 0.1,\n    typeOfDesign = \"OF\", futilityBounds = c(0,0.5))\nr <- getSampleSizeRates(dGS, pi1 = 0.4, pi2 = 0.6)\n\nsummary(r)\n\nSample size calculation for a binary endpoint\n\nSequential analysis with a maximum of 3 looks (group sequential design), overall \nsignificance level 2.5% (one-sided).\nThe sample size was calculated for a two-sample test for rates \n(normal approximation),\nH0: pi(1) - pi(2) = 0, H1: treatment rate pi(1) = 0.4, control rate pi(2) = 0.6, \npower 90%.\n\nStage                                         1      2      3 \nInformation rate                            50%    75%   100% \nEfficacy boundary (z-value scale)         2.863  2.337  2.024 \nFutility boundary (z-value scale)             0  0.500 \nOverall power                            0.2958 0.6998 0.9000 \nExpected number of subjects               198.3 \nNumber of subjects                        133.1  199.7  266.3 \nCumulative alpha spent                   0.0021 0.0105 0.0250 \nOne-sided local significance level       0.0021 0.0097 0.0215 \nEfficacy boundary (t)                    -0.248 -0.165 -0.124 \nFutility boundary (t)                     0.000 -0.035 \nOverall exit probability (under H0)      0.5021 0.2275 \nOverall exit probability (under H1)      0.3058 0.4095 \nExit probability for efficacy (under H0) 0.0021 0.0083 \nExit probability for efficacy (under H1) 0.2958 0.4040 \nExit probability for futility (under H0) 0.5000 0.2191 \nExit probability for futility (under H1) 0.0100 0.0056 \n\nLegend:\n  (t): treatment effect scale\n\n\nThe optimum allocation ratio is 1 in this case but calculated numerically, therefore slightly unequal 1:\n\nr <- getSampleSizeRates(dGS, pi1 = 0.4, pi2 = 0.6, allocationRatioPlanned = 0)\nr$allocationRatioPlanned\n\n[1] 0.9999976\n\nround(r$allocationRatioPlanned,5)\n\n[1] 1"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-3b-boundary-plots",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-3b-boundary-plots",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 3b (boundary plots)",
    "text": "Exercise 3b (boundary plots)\nIllustrate the decision boundaries on different scales.\nSolution\n\nplot(r, type = 1)\n\n\n\nplot(r, type = 2)\n\n\n\nplot(r, type = 3)"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-3c-power-assessment",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-3c-power-assessment",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 3c (power assessment)",
    "text": "Exercise 3c (power assessment)\nSuppose that \\(N = 280\\) subjects were planned for the study. What is the power if the failure rate in the active treatment group is \\(\\pi_1 = 0.50\\)?\nSolution\nThe power is much reduced as compared to the case pi1 = 0.4 (where it exceeds 90%):\n\npower <- getPowerRates(dGS, maxNumberOfSubjects = 280, pi1 = c(0.4, 0.5), pi2 = 0.6, \n      directionUpper = FALSE)\n\npower$overallReject\n\n[1] 0.914045 0.377853"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-3d-power-illustration",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-3d-power-illustration",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 3d (power illustration)",
    "text": "Exercise 3d (power illustration)\nIllustrate power, expected sample size, and early/futility stop for a range of alternative values.\nSolution\nSpecifying pi1 = c(0.3,0.6) provides a range of power and ANS values:\n\npower <- getPowerRates(dGS, maxNumberOfSubjects = 280, pi1 = c(0.3,0.6), pi2 = 0.6,\n     directionUpper = FALSE)\n\nplot(power, type = 6)"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-4a-assess-power",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-4a-assess-power",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 4a (assess power)",
    "text": "Exercise 4a (assess power)\nUse the inverse normal method to allow for the sample size increase and compare the test characteristics with the group sequential design from Example 3.\nSolution\nDefine the inverse normal design and perform two simulations, one without and one with SSR:\n\ndIN <- getDesignInverseNormal(informationRates = c(0.5,0.75,1), alpha = 0.025, beta = 0.1,\n    futilityBounds = c(0,0.5))\n\nmaxiter <- 1000\n\nsim1 <- getSimulationRates(dIN, plannedSubjects = c(140,210,280), pi1 = seq(0.4,0.5,0.01), pi2 = 0.6,\n  directionUpper = FALSE, maxNumberOfIterations = maxiter, conditionalPower = 0.9,\n  minNumberOfSubjectsPerStage = c(140,70,70), maxNumberOfSubjectsPerStage = c(140,70,70),\n  seed = 1234)\n\nsim2 <- getSimulationRates(dIN, plannedSubjects = c(140,210,280), pi1 = seq(0.4,0.5,0.01), pi2 = 0.6,\n  directionUpper = FALSE, maxNumberOfIterations = maxiter, conditionalPower = 0.9, \n  minNumberOfSubjectsPerStage = c(NA,70,70), maxNumberOfSubjectsPerStage = c(NA,70,4*70),\n  seed = 5678)\n\nNote that the sample sizes will be calculated under the assumption that the conditional power for the subsequent stage is 90%. If the resulting sample size is larger, the upper bound (4*70 = 280) is used."
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-4b-illustrate-power-difference",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-4b-illustrate-power-difference",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 4b (illustrate power difference)",
    "text": "Exercise 4b (illustrate power difference)\nIllustrate the gain in power when using the adaptive sample size recalculation.\nSolution\nWe use ggplot2 for doing this. First, a data set df is defined with the additional variable SSR. Using mytheme and the following ggplots commands, the difference in power and ASN of the two strategies is illustrated. It shows that at least for effect difference > 0.15 an overall power of more than around 85% can be achieved with the proposed sample size recalculation strategy.\n\nlibrary(ggplot2)\n\ndataSim1 <- as.data.frame(sim1, niceColumnNamesEnabled = FALSE)\ndataSim2 <- as.data.frame(sim2, niceColumnNamesEnabled = FALSE)\n\ndataSim1$SSR <- rep(\"no SSR\", nrow(dataSim1))\ndataSim2$SSR <- rep(\"SSR\", nrow(dataSim2))\ndf <- rbind(dataSim1, dataSim2)\n\nmyTheme = theme(\n  axis.title.x = element_text(size = 12), axis.text.x = element_text(size = 12),\n  axis.title.y = element_text(size = 12), axis.text.y = element_text(size = 12),\n  plot.title = element_text(size = 14,hjust = 0.5), \n    plot.subtitle = element_text(size = 12,hjust = 0.5))\n\np <- ggplot(data = df,aes(x = effect,y = overallReject, group = SSR, color = SSR)) +\n  geom_line(size = 1.1) +\n  geom_line(aes(x = effect,y = expectedNumberOfSubjects/400, group = SSR, color = SSR), size = 1.1, \n    linetype = \"dashed\") +\n  scale_y_continuous( \"Power\",  sec.axis = sec_axis(~ . * 400, name = \"ASN\"), limits = c(0.2,1)) +\n  theme_classic() +  xlab(\"effect\") +  ggtitle(\"Power and ASN\",\"Power solid, ASN dashed\") +\n  geom_hline(size = 0.5, yintercept = 0.8, linetype = \"dotted\") +\n  geom_hline(size = 0.5, yintercept = 0.9, linetype = \"dotted\") +\n  geom_vline(size = 0.5, xintercept = c(-0.2, -0.15), linetype = \"dashed\") +\n  myTheme\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nplot(p)\n\n\n\n# Note: for saving the plot, you could e.g. use the commented code below\n# ggplot2::ggsave(filename = \"C:/yourdirectory/comparison.png\",\n#        plot = ggplot2::last_plot(), device = NULL, path = NULL,\n#        scale = 1.2, width = 20, height = 12, units = \"cm\", dpi = 600, limitsize = TRUE)"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-4c-histogram-of-sample-sizes",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-4c-histogram-of-sample-sizes",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 4c (histogram of sample sizes)",
    "text": "Exercise 4c (histogram of sample sizes)\nCreate a histogram for the attained sample size of the study when using the adaptive sample size recalculation. How often will the maximum sample size be achieved?\nSolution\nWith the getData command the simulation results are obtained. Depending on pi1, you can create the histogram of the simulated total sample size\n\nlibrary(tictoc)\n\nsimdata<- getData(sim2)\nstr(simdata)\n\n'data.frame':   24488 obs. of  18 variables:\n $ iterationNumber          : num  1 1 2 3 4 4 5 6 6 6 ...\n $ stageNumber              : num  1 2 1 1 1 2 1 1 2 3 ...\n $ pi1                      : num  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 ...\n $ pi2                      : num  0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 ...\n $ numberOfSubjects         : num  140 70 140 140 140 70 140 140 70 280 ...\n $ numberOfCumulatedSubjects: num  140 210 140 140 140 210 140 140 210 490 ...\n $ rejectPerStage           : num  0 1 1 1 0 1 1 0 0 1 ...\n $ futilityPerStage         : num  0 0 0 0 0 0 0 0 0 0 ...\n $ testStatistic            : num  2.7 3.45 3.39 3.38 2.22 ...\n $ testStatisticsPerStage   : num  2.7 2.15 3.39 3.38 2.22 ...\n $ overallRate1             : num  0.386 0.381 0.386 0.343 0.343 ...\n $ overallRate2             : num  0.614 0.619 0.671 0.629 0.529 ...\n $ stagewiseRates1          : num  0.386 0.371 0.386 0.343 0.343 ...\n $ stagewiseRates2          : num  0.614 0.629 0.671 0.629 0.529 ...\n $ sampleSizesPerStage1     : num  70 35 70 70 70 35 70 70 35 140 ...\n $ sampleSizesPerStage2     : num  70 35 70 70 70 35 70 70 35 140 ...\n $ trialStop                : logi  FALSE TRUE TRUE TRUE FALSE TRUE ...\n $ conditionalPowerAchieved : num  NA 0.959 NA NA NA ...\n\nsimPart <- simdata[simdata$pi1 == 0.5,] \ntic()\noverallSampleSizes <- sapply(1:maxiter, function(i) sum(simPart[simPart$iterationNumber==i,]$numberOfSubjects))\ntoc()\n\n0.47 sec elapsed\n\n# tic()\n# overallSampleSizes <- numeric(maxiter)\n# for (i in 1:maxiter) overallSampleSizes[i] <- sum(simPart[simPart$iterationNumber==i,]$numberOfSubjects)\n# toc()\n\nhist(overallSampleSizes)\n\n\n\n\nHow often the maximum sample size is reached can be obtained as follows:\n\nsimdata<- getData(sim2)\n\nsimdataPart <- simdata[simdata$pi1 == 0.5,] \n\nsubjectsRange <- cut(simdataPart$numberOfSubjects, c(69, 70, 139, 140, 210, 279, 280))\n\nround(prop.table(table(simdataPart$stageNumber,subjectsRange), margin = 1)*100,1)\n\n   subjectsRange\n    (69,70] (70,139] (139,140] (140,210] (210,279] (279,280]\n  1     0.0      0.0     100.0       0.0       0.0       0.0\n  2   100.0      0.0       0.0       0.0       0.0       0.0\n  3     0.0      9.0       0.3       8.8       4.7      77.2"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-5a-first-stage-and-conditional-power",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-5a-first-stage-and-conditional-power",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 5a (First stage and conditional power)",
    "text": "Exercise 5a (First stage and conditional power)\nSuppose, at the first stage, the following results were obtained:\n\n\n\narm\nn\nmean\nstd\n\n\n\n\n1\n19\n3.11\n1.77\n\n\n2\n22\n3.87\n1.23\n\n\n3\n23\n4.12\n1.64\n\n\ncontrol\n21\n3.02\n1.72\n\n\n\nPerform the closed test and assess the conditional power in order to decide which treatment arm(s) should be selected and if the sample size should be redefined.\nSolution\n\ndataExample <- getDataset(\n  n1      = c(19),\n  n2      = c(22),\n  n3      = c(23),\n  n4      = c(21),\n  means1  = c(3.11),\n  means2  = c(3.87),\n  means3  = c(4.12),\n  means4  = c(3.02),\n  stDevs1 = c(1.77),\n  stDevs2 = c(1.23),\n  stDevs3 = c(1.64),\n  stDevs4 = c(1.72)\n)\n\nalpha <- 0.025\nintersectionTest <- \"Dunnett\"\nvarianceOption <- \"overallPooled\"\nnormalApproximation <- FALSE\n\ndesign <- getDesignInverseNormal(kMax = 3, alpha = alpha, typeOfDesign = \"OF\")\n\nstageResults <- getAnalysisResults(design = design,\n  dataInput = dataExample, thetaH0 = 0, stage = 1,\n  directionUpper = TRUE, normalApproximation = normalApproximation,\n  intersectionTest = intersectionTest, varianceOption = varianceOption,\n  nPlanned = c(40, 40))\n\nsummary(stageResults)\n\nMulti-arm analysis results for a continuous endpoint (3 active arms vs. control)\n\nSequential analysis with 3 looks (inverse normal combination test design).\nThe results were calculated using a multi-arm t-test (one-sided), \nDunnett intersection test, overall pooled variances option.\nH0: mu(i) - mu(control) = 0 against H1: mu(i) - mu(control) > 0. \nThe conditional power calculation with planned sample size is based on \noverall effect: thetaH1(1) = 0.09, thetaH1(2) = 0.85, thetaH1(3) = 1.1 and \noverall standard deviation: sd(1) = 1.74, sd(2) = 1.49, sd(3) = 1.68.\n\nStage                                                   1               2               3 \nFixed weight                                        0.577           0.577           0.577 \nEfficacy boundary (z-value scale)                   3.471           2.454           2.004 \nCumulative alpha spent                             0.0003          0.0072          0.0250 \nStage level                                        0.0003          0.0071          0.0225 \nCumulative effect size (1)                          0.090                                 \nCumulative effect size (2)                          0.850                                 \nCumulative effect size (3)                          1.100                                 \nCumulative (pooled) standard deviation              1.597                                 \nStage-wise test statistic (1)                       0.178                                 \nStage-wise test statistic (2)                       1.745                                 \nStage-wise test statistic (3)                       2.283                                 \nStage-wise p-value (1)                             0.4296                                 \nStage-wise p-value (2)                             0.0424                                 \nStage-wise p-value (3)                             0.0125                                 \nAdjusted stage-wise p-value (1, 2, 3)              0.0325                                 \nAdjusted stage-wise p-value (1, 2)                 0.0751                                 \nAdjusted stage-wise p-value (1, 3)                 0.0232                                 \nAdjusted stage-wise p-value (2, 3)                 0.0231                                 \nAdjusted stage-wise p-value (1)                    0.4296                                 \nAdjusted stage-wise p-value (2)                    0.0424                                 \nAdjusted stage-wise p-value (3)                    0.0125                                 \nOverall adjusted test statistic (1, 2, 3)           1.845                                 \nOverall adjusted test statistic (1, 2)              1.439                                 \nOverall adjusted test statistic (1, 3)              1.991                                 \nOverall adjusted test statistic (2, 3)              1.994                                 \nOverall adjusted test statistic (1)                 0.177                                 \nOverall adjusted test statistic (2)                 1.724                                 \nOverall adjusted test statistic (3)                 2.240                                 \nTest action: reject (1)                             FALSE                                 \nTest action: reject (2)                             FALSE                                 \nTest action: reject (3)                             FALSE                                 \nConditional rejection probability (1)              0.0101                                 \nConditional rejection probability (2)              0.0831                                 \nConditional rejection probability (3)              0.1432                                 \nPlanned sample size                                                    40              40 \nConditional power (1)                                              0.0009          0.0182 \nConditional power (2)                                              0.4102          0.8723 \nConditional power (3)                                              0.6722          0.9652 \n95% repeated confidence interval (1)       [-1.896; 2.076]                                \n95% repeated confidence interval (2)       [-1.064; 2.764]                                \n95% repeated confidence interval (3)       [-0.793; 2.993]                                \nRepeated p-value (1)                                 >0.5                                 \nRepeated p-value (2)                               0.2633                                 \nRepeated p-value (3)                               0.1794                                 \n\nLegend:\n  (i): results of treatment arm i vs. control arm\n  (i, j, ...): comparison of treatment arms 'i, j, ...' vs. control arm"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-5b-second-stage",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-5b-second-stage",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 5b (Second stage)",
    "text": "Exercise 5b (Second stage)\nSuppose it was decided to drop treatment arm 1 for stage 2 and leave the sample size for the remaining arms unchanged. For the second stage, the following results were obtained:\n\n\n\narm\nn\nmean\nstd\n\n\n\n\n2\n23\n3.66\n1.11\n\n\n3\n19\n3.98\n1.21\n\n\ncontrol\n22\n2.99\n1.82\n\n\n\nPerform the closed test and discuss whether or not to stop the study and determine overall \\(p\\,\\)-values and confidence intervals.\nSolution\n\ndataExample <- getDataset(\n  n1      = c(19, NA),\n  n2      = c(22, 23),\n  n3      = c(23, 19),\n  n4      = c(21, 22),\n  means1  = c(3.11, NA),\n  means2  = c(3.87, 3.66),\n  means3  = c(4.12, 3.98),\n  means4  = c(3.02, 2.99),\n  stDevs1 = c(1.77, NA),\n  stDevs2 = c(1.23, 1.11),\n  stDevs3 = c(1.64, 1.21),\n  stDevs4 = c(1.72, 1.82)\n)\n\nstageResults <- getAnalysisResults(design = design,\n  dataInput = dataExample, thetaH0 = 0, stage = 2,\n  directionUpper = TRUE, normalApproximation = normalApproximation,\n  intersectionTest = intersectionTest, varianceOption = varianceOption)\n\nsummary(stageResults)\n\nMulti-arm analysis results for a continuous endpoint (3 active arms vs. control)\n\nSequential analysis with 3 looks (inverse normal combination test design).\nThe results were calculated using a multi-arm t-test (one-sided), \nDunnett intersection test, overall pooled variances option.\nH0: mu(i) - mu(control) = 0 against H1: mu(i) - mu(control) > 0.\n\nStage                                                   1               2               3 \nFixed weight                                        0.577           0.577           0.577 \nEfficacy boundary (z-value scale)                   3.471           2.454           2.004 \nCumulative alpha spent                             0.0003          0.0072          0.0250 \nStage level                                        0.0003          0.0071          0.0225 \nCumulative effect size (1)                          0.090                                 \nCumulative effect size (2)                          0.850           0.758                 \nCumulative effect size (3)                          1.100           1.052                 \nCumulative (pooled) standard deviation              1.597           1.468                 \nStage-wise test statistic (1)                       0.178                                 \nStage-wise test statistic (2)                       1.745           1.582                 \nStage-wise test statistic (3)                       2.283           2.226                 \nStage-wise p-value (1)                             0.4296                                 \nStage-wise p-value (2)                             0.0424          0.0594                 \nStage-wise p-value (3)                             0.0125          0.0149                 \nAdjusted stage-wise p-value (1, 2, 3)              0.0325          0.0274                 \nAdjusted stage-wise p-value (1, 2)                 0.0751          0.0594                 \nAdjusted stage-wise p-value (1, 3)                 0.0232          0.0149                 \nAdjusted stage-wise p-value (2, 3)                 0.0231          0.0274                 \nAdjusted stage-wise p-value (1)                    0.4296                                 \nAdjusted stage-wise p-value (2)                    0.0424          0.0594                 \nAdjusted stage-wise p-value (3)                    0.0125          0.0149                 \nOverall adjusted test statistic (1, 2, 3)           1.845           2.662                 \nOverall adjusted test statistic (1, 2)              1.439           2.121                 \nOverall adjusted test statistic (1, 3)              1.991           2.945                 \nOverall adjusted test statistic (2, 3)              1.994           2.767                 \nOverall adjusted test statistic (1)                 0.177                                 \nOverall adjusted test statistic (2)                 1.724           2.322                 \nOverall adjusted test statistic (3)                 2.240           3.121                 \nTest action: reject (1)                             FALSE           FALSE                 \nTest action: reject (2)                             FALSE           FALSE                 \nTest action: reject (3)                             FALSE            TRUE                 \nConditional rejection probability (1)              0.0101                                 \nConditional rejection probability (2)              0.0831          0.3184                 \nConditional rejection probability (3)              0.1432          0.6154                 \n95% repeated confidence interval (1)       [-1.896; 2.076]                                \n95% repeated confidence interval (2)       [-1.064; 2.764] [-0.203; 1.716]                \n95% repeated confidence interval (3)       [-0.793; 2.993] [0.066 ; 2.022]                \nRepeated p-value (1)                                 >0.5                                 \nRepeated p-value (2)                               0.2633          0.0476                 \nRepeated p-value (3)                               0.1794          0.0162                 \n\nLegend:\n  (i): results of treatment arm i vs. control arm\n  (i, j, ...): comparison of treatment arms 'i, j, ...' vs. control arm"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-5c-intersection-tests",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-5c-intersection-tests",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 5c (Intersection tests)",
    "text": "Exercise 5c (Intersection tests)\nWould the Bonferroni and the Simes test intersection tests provide the same results?\nSolution\n\nstageResults <- getAnalysisResults(design = design,\n  dataInput = dataExample, thetaH0 = 0, stage = 2,\n  directionUpper = TRUE, normalApproximation = normalApproximation,\n  intersectionTest = \"Bonferroni\", varianceOption = varianceOption)\nsummary(stageResults)\n\nMulti-arm analysis results for a continuous endpoint (3 active arms vs. control)\n\nSequential analysis with 3 looks (inverse normal combination test design).\nThe results were calculated using a multi-arm t-test (one-sided), \nBonferroni intersection test, overall pooled variances option.\nH0: mu(i) - mu(control) = 0 against H1: mu(i) - mu(control) > 0.\n\nStage                                                   1               2               3 \nFixed weight                                        0.577           0.577           0.577 \nEfficacy boundary (z-value scale)                   3.471           2.454           2.004 \nCumulative alpha spent                             0.0003          0.0072          0.0250 \nStage level                                        0.0003          0.0071          0.0225 \nCumulative effect size (1)                          0.090                                 \nCumulative effect size (2)                          0.850           0.758                 \nCumulative effect size (3)                          1.100           1.052                 \nCumulative (pooled) standard deviation              1.597           1.468                 \nStage-wise test statistic (1)                       0.178                                 \nStage-wise test statistic (2)                       1.745           1.582                 \nStage-wise test statistic (3)                       2.283           2.226                 \nStage-wise p-value (1)                             0.4296                                 \nStage-wise p-value (2)                             0.0424          0.0594                 \nStage-wise p-value (3)                             0.0125          0.0149                 \nAdjusted stage-wise p-value (1, 2, 3)              0.0376          0.0297                 \nAdjusted stage-wise p-value (1, 2)                 0.0848          0.0594                 \nAdjusted stage-wise p-value (1, 3)                 0.0251          0.0149                 \nAdjusted stage-wise p-value (2, 3)                 0.0251          0.0297                 \nAdjusted stage-wise p-value (1)                    0.4296                                 \nAdjusted stage-wise p-value (2)                    0.0424          0.0594                 \nAdjusted stage-wise p-value (3)                    0.0125          0.0149                 \nOverall adjusted test statistic (1, 2, 3)           1.779           2.591                 \nOverall adjusted test statistic (1, 2)              1.374           2.074                 \nOverall adjusted test statistic (1, 3)              1.959           2.922                 \nOverall adjusted test statistic (2, 3)              1.959           2.718                 \nOverall adjusted test statistic (1)                 0.177                                 \nOverall adjusted test statistic (2)                 1.724           2.322                 \nOverall adjusted test statistic (3)                 2.240           3.121                 \nTest action: reject (1)                             FALSE           FALSE                 \nTest action: reject (2)                             FALSE           FALSE                 \nTest action: reject (3)                             FALSE            TRUE                 \nConditional rejection probability (1)              0.0101                                 \nConditional rejection probability (2)              0.0756          0.2954                 \nConditional rejection probability (3)              0.1317          0.5764                 \n95% repeated confidence interval (1)       [-1.901; 2.081]                                \n95% repeated confidence interval (2)       [-1.068; 2.768] [-0.227; 1.747]                \n95% repeated confidence interval (3)       [-0.798; 2.998] [0.041 ; 2.051]                \nRepeated p-value (1)                                 >0.5                                 \nRepeated p-value (2)                               0.2789          0.0518                 \nRepeated p-value (3)                               0.1915          0.0189                 \n\nLegend:\n  (i): results of treatment arm i vs. control arm\n  (i, j, ...): comparison of treatment arms 'i, j, ...' vs. control arm\n\nstageResults <- getAnalysisResults(design = design,\n  dataInput = dataExample, thetaH0 = 0, stage = 2,\n  directionUpper = TRUE, normalApproximation = normalApproximation,\n  intersectionTest = \"Simes\", varianceOption = varianceOption)\nsummary(stageResults)\n\nMulti-arm analysis results for a continuous endpoint (3 active arms vs. control)\n\nSequential analysis with 3 looks (inverse normal combination test design).\nThe results were calculated using a multi-arm t-test (one-sided), \nSimes intersection test, overall pooled variances option.\nH0: mu(i) - mu(control) = 0 against H1: mu(i) - mu(control) > 0.\n\nStage                                                   1               2               3 \nFixed weight                                        0.577           0.577           0.577 \nEfficacy boundary (z-value scale)                   3.471           2.454           2.004 \nCumulative alpha spent                             0.0003          0.0072          0.0250 \nStage level                                        0.0003          0.0071          0.0225 \nCumulative effect size (1)                          0.090                                 \nCumulative effect size (2)                          0.850           0.758                 \nCumulative effect size (3)                          1.100           1.052                 \nCumulative (pooled) standard deviation              1.597           1.468                 \nStage-wise test statistic (1)                       0.178                                 \nStage-wise test statistic (2)                       1.745           1.582                 \nStage-wise test statistic (3)                       2.283           2.226                 \nStage-wise p-value (1)                             0.4296                                 \nStage-wise p-value (2)                             0.0424          0.0594                 \nStage-wise p-value (3)                             0.0125          0.0149                 \nAdjusted stage-wise p-value (1, 2, 3)              0.0376          0.0297                 \nAdjusted stage-wise p-value (1, 2)                 0.0848          0.0594                 \nAdjusted stage-wise p-value (1, 3)                 0.0251          0.0149                 \nAdjusted stage-wise p-value (2, 3)                 0.0251          0.0297                 \nAdjusted stage-wise p-value (1)                    0.4296                                 \nAdjusted stage-wise p-value (2)                    0.0424          0.0594                 \nAdjusted stage-wise p-value (3)                    0.0125          0.0149                 \nOverall adjusted test statistic (1, 2, 3)           1.779           2.591                 \nOverall adjusted test statistic (1, 2)              1.374           2.074                 \nOverall adjusted test statistic (1, 3)              1.959           2.922                 \nOverall adjusted test statistic (2, 3)              1.959           2.718                 \nOverall adjusted test statistic (1)                 0.177                                 \nOverall adjusted test statistic (2)                 1.724           2.322                 \nOverall adjusted test statistic (3)                 2.240           3.121                 \nTest action: reject (1)                             FALSE           FALSE                 \nTest action: reject (2)                             FALSE           FALSE                 \nTest action: reject (3)                             FALSE            TRUE                 \nConditional rejection probability (1)              0.0101                                 \nConditional rejection probability (2)              0.0756          0.2954                 \nConditional rejection probability (3)              0.1317          0.5764                 \n95% repeated confidence interval (1)       [-1.901; 2.081]                                \n95% repeated confidence interval (2)       [-1.068; 2.768] [-0.227; 1.747]                \n95% repeated confidence interval (3)       [-0.798; 2.998] [0.041 ; 2.051]                \nRepeated p-value (1)                                 >0.5                                 \nRepeated p-value (2)                               0.2789          0.0518                 \nRepeated p-value (3)                               0.1915          0.0189                 \n\nLegend:\n  (i): results of treatment arm i vs. control arm\n  (i, j, ...): comparison of treatment arms 'i, j, ...' vs. control arm"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-6a-accrual-and-follow-up-time-given",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-6a-accrual-and-follow-up-time-given",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 6a (accrual and follow-up time given)",
    "text": "Exercise 6a (accrual and follow-up time given)\nThe patients should be recruited within 12 months assuming uniform accrual. Assume an additional follow-up time of 12 months, i.e., the study should be conducted within 2 years. Calculate the necessary number of events and patients (total and per month) in order to reach power 90% with the assumed median survival times if the survival time is exponentially distributed. Under the postulated assumption, estimate interim and final analysis time.\nSolution\nIn this simplest example, accrual and follow-up time needs to be specified. The effect size is defined in terms of lambda1 and lambda2 (you can also specify lambda2 and hazardRatio).\n\ndGS <- getDesignGroupSequential(kMax = 2, typeOfDesign = \"asOF\", beta = 0.1)\n\nx1 <- getSampleSizeSurvival(dGS, lambda1 = getLambdaByMedian(18), lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = 12, followUpTime = 12)\n\nsummary(x1)\n\nSample size calculation for a survival endpoint\n\nSequential analysis with a maximum of 2 looks (group sequential design), overall \nsignificance level 2.5% (one-sided).\nThe sample size was calculated for a two-sample logrank test, \nH0: hazard ratio = 1, H1: treatment lambda(1) = 0.039, control lambda(2) = 0.058, \naccrual time = 12, accrual intensity = 38.9, dropout rate(1) = 0.05, \ndropout rate(2) = 0.05, dropout time = 12, power 90%.\n\nStage                                         1      2 \nInformation rate                            50%   100% \nEfficacy boundary (z-value scale)         2.963  1.969 \nOverall power                            0.2525 0.9000 \nExpected number of subjects               467.3 \nNumber of subjects                        467.3  467.3 \nCumulative number of events               128.3  256.5 \nAnalysis time                              13.1   24.0 \nExpected study duration                    21.3 \nCumulative alpha spent                   0.0015 0.0250 \nOne-sided local significance level       0.0015 0.0245 \nEfficacy boundary (t)                     0.593  0.782 \nExit probability for efficacy (under H0) 0.0015 \nExit probability for efficacy (under H1) 0.2525 \n\nLegend:\n  (t): treatment effect scale\n\nceiling(x1$maxNumberOfEvents)\n\n[1] 257\n\nceiling(x1$maxNumberOfSubjects)\n\n[1] 468\n\nceiling(x1$maxNumberOfSubjects)/12\n\n[1] 39\n\nx1$analysisTime\n\n         [,1]\n[1,] 13.14114\n[2,] 24.00000"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-6b-follow-up-time-and-absolue-intensity-given",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-6b-follow-up-time-and-absolue-intensity-given",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 6b (follow-up time and absolue intensity given)",
    "text": "Exercise 6b (follow-up time and absolue intensity given)\nAssume that 25 patients can be recruited each month and that there is uniform accrual. Estimate the necessary accrual time if the planned follow-up time remains unchanged.\nSolution\nHere the end of accrual and the number of patients is calculated at given follow-up time and absolute accrual intensity:\n\nx2 <- getSampleSizeSurvival(dGS, hazardRatio = 2/3, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = 0, accrualIntensity = 25, followUpTime = 12)\n\nceiling(x2$maxNumberOfSubjects)\n\n[1] 435\n\nx2$accrualTime\n\n[1] 17.38334\n\nx2$analysisTime\n\n         [,1]\n[1,] 16.79806\n[2,] 29.38334"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-6c-accrual-time-and-max-number-of-patients-given",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-6c-accrual-time-and-max-number-of-patients-given",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 6c (accrual time and max number of patients given)",
    "text": "Exercise 6c (accrual time and max number of patients given)\nAssume that accrual stops after 16 months with 25 patients per month, i.e., after 400 patients were recruited. What is the estimated necessary follow-up time?\nSolution\nAt given accrual time and number of patients, the follow-up time is calculated:\n\nx3 <- getSampleSizeSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = c(0, 16), accrualIntensity = 25)\n\nceiling(x3$maxNumberOfSubjects)\n\n[1] 400\n\nx3$followUpTime\n\n[1] 15.96226\n\nx3$analysisTime\n\n         [,1]\n[1,] 16.82864\n[2,] 31.96226"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-6d-staggered-patient-entry",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-6d-staggered-patient-entry",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 6d (staggered patient entry)",
    "text": "Exercise 6d (staggered patient entry)\nHow do the results change if in the first 3 months 15 patients, in the second 3 months 20 patients, and after 6 months 25 patients per month can be accrued?\nSolution\nThis is the result from b), where the end of accrual is calculated:\n\nx4 <- getSampleSizeSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = c(0, 3, 6), accrualIntensity = c(15, 20, 25), followUpTime = 12)\n    \nceiling(x4$maxNumberOfSubjects)\n\n[1] 434\n\nx4$accrualTime\n\n[1]  3.00000  6.00000 19.14067\n\nx4$analysisTime\n\n         [,1]\n[1,] 18.48715\n[2,] 31.14067\n\n\nThis is the result from c), where the follow-up time is calculated:\n\nx5 <- getSampleSizeSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = c(0, 3, 6, 16), accrualIntensity = c(15, 20, 25))\n\nceiling(x5$maxNumberOfSubjects)\n\n[1] 355\n\nx5$followUpTime\n\n[1] 23.60973\n\nx5$analysisTime\n\n         [,1]\n[1,] 18.83368\n[2,] 39.60973"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-7a-verify-results-by-simulation",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-7a-verify-results-by-simulation",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 7a (verify results by simulation)",
    "text": "Exercise 7a (verify results by simulation)\nAssume that the study from Example 6 is planned with 257 events and 400 patients under the assumptions that accrual stops after 16 months with 25 patients per month. Verify by simulation the correctness of the results obtained by the analytical formulae.\nSolution\nWe first calculate the analysis times by the analytical formulas and verify that the power is indeed exceeding 90%:\n\ny3 <- getPowerSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12,\n  accrualTime = c(0, 3, 6, 16), accrualIntensity = c(15, 20, 25),\n  maxNumberOfEvents = 257, directionUpper = FALSE)\n\ny3$analysisTime\n\n         [,1]\n[1,] 18.85699\n[2,] 39.74904\n\ny3$overallReject  \n\n[1] 0.9005251\n\n\nPractically the same result is obtained with the simulation tool:\n\nmaxiter <- 1000\n\nz3 <- getSimulationSurvival(dGS, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  dropoutRate1 = 0.05, dropoutRate2 = 0.05, dropoutTime = 12, maxNumberOfIterations = maxiter,\n  accrualTime = c(0, 3, 6, 16), accrualIntensity = c(15, 20, 25),\n  plannedEvents = c(129, 257), directionUpper = FALSE)\n\nz3$analysisTime\n\n         [,1]\n[1,] 18.91786\n[2,] 39.58647\n\nz3$overallReject  \n\n[1] 0.903"
  },
  {
    "objectID": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-7b-assess-adaptive-survival-design",
    "href": "trainings/20220913/BBSadaptiveCourse13Sep2022_solutions.html#exercise-7b-assess-adaptive-survival-design",
    "title": "Solutions to the exercises for the BBS course ‘Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact’ on 13Sep2022",
    "section": "Exercise 7b (assess adaptive survival design)",
    "text": "Exercise 7b (assess adaptive survival design)\nAssume now that a sample size increase up to a ten-fold of the originally planned number of events is foreseen. Conditional power 90% based on the observed hazard ratios is used to increase the number of events. Assess by simulation the magnitude of power increase when using the appropriate method.\nSimulate the Type I error rate when using\n\nthe group sequential method\nthe inverse normal method\n\nHint: Make sure that enough subjects are used in the simulation (set maxNumberOfSubjects = 3000 and no drop-outs)\nSolution\nFirst define an inverse normal design with the same parameters as the original group sequential design:\n\ndIN <- getDesignGroupSequential(kMax = 2, typeOfDesign = \"asOF\", beta = 0.1)\n\n\nz4 <- getSimulationSurvival(dIN, lambda1 = log(2)/18, lambda2 = log(2)/12,\n  maxNumberOfIterations = maxiter,\n  accrualTime = c(0,16), maxNumberOfSubjects = 3000, plannedEvents = c(129, 257), \n  directionUpper = FALSE, conditionalPower = 0.9, \n  minNumberOfEventsPerStage = c(NA,128), maxNumberOfEventsPerStage = 10*c(NA,128))\n\nz4$analysisTime\n\n          [,1]\n[1,]  5.586818\n[2,] 11.139290\n\nz4$overallReject  \n\n[1] 0.982\n\n\nThe following simulation compares the Type I error rate of the inverse normal method with the type I error rate of the (illegal) use of the group-sequential method:\n\nmaxiter <- 10000\n\ndGS <- getDesignGroupSequential(kMax = 2, typeOfDesign = \"asOF\")\ndIN <- getDesignInverseNormal(kMax = 2, typeOfDesign = \"asOF\")\n\nIN <- getSimulationSurvival(dIN, hazardRatio = 1,\n  maxNumberOfIterations = maxiter,\n  accrualTime = c(0,16), maxNumberOfSubjects = 3000, plannedEvents = c(129, 257), \n  directionUpper = FALSE, conditionalPower = 0.9, \n  minNumberOfEventsPerStage = c(NA,128), maxNumberOfEventsPerStage = 10*c(NA,128))\n\nGS <- getSimulationSurvival(dGS, hazardRatio = 1,\n  maxNumberOfIterations = maxiter,\n  accrualTime = c(0,16), maxNumberOfSubjects = 3000, plannedEvents = c(129, 257), \n  directionUpper = FALSE, conditionalPower = 0.9, minNumberOfEventsPerStage = c(NA,128), \n  maxNumberOfEventsPerStage = 10*c(NA,128))\n  \nIN$overallReject  \n\n[1] 0.0274\n\nGS$overallReject  \n\n[1] 0.0366\n\n\n\nSystem: rpact 3.3.1, R version 4.2.2 (2022-10-31 ucrt), platform: x86_64-w64-mingw32\nprint(citation(“rpact”), bibtex = FALSE)"
  },
  {
    "objectID": "trainings/20220913/RufibachWolbers_efficient_interims.html",
    "href": "trainings/20220913/RufibachWolbers_efficient_interims.html",
    "title": "Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact: Efficient use of futility and efficacy interim analyses in group-sequential designs",
    "section": "",
    "text": "This R markdown file provides the code accompanying the first theory block in the BBS course Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact."
  },
  {
    "objectID": "trainings/20220913/RufibachWolbers_efficient_interims.html#efficacy",
    "href": "trainings/20220913/RufibachWolbers_efficient_interims.html#efficacy",
    "title": "Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact: Efficient use of futility and efficacy interim analyses in group-sequential designs",
    "section": "5.1 Efficacy",
    "text": "5.1 Efficacy\n\n5.1.1 Bias\nFor code and recommendationas how to handle bias in group-sequential designs we refer to Vignette #7 on the rpact vignettes webpage.\nThe standard rpact output provides a median unbiased estimate. For details on the various types of biases in group-sequential designs and approaches we refer to Wassmer and Brannath (2016).\n\n\n5.1.2 Adding a late efficacy interim\nIn what follows, we generate the table used in the slide deck to illustrate addition of a late efficacy interim analysis.\n\n# illustrate effect of late efficacy on MDD and local significance level\n\n# timing of interims (information fraction)\nj1 <- 2 / 3\nj2 <- 0.85\ninfofrac_late <- c(j1, j2, 1)\n\n# OBF standard design\ndesign_late1 <- getDesignGroupSequential(informationRates = infofrac_late[c(1, 3)],\n                                   typeOfDesign = \"asOF\", sided = 2, alpha = alpha, \n                                   beta = beta)\nss_late1 <- myGetSampleSizeSurvival(design_late1)\nnevents_late1 <- ceiling(nevent * c(j1, 1))\n\n# add late interim\ndesign_late2 <- getDesignGroupSequential(informationRates = infofrac_late,\n                                         typeOfDesign = \"asOF\", sided = 2, alpha = alpha, \n                                         beta = beta)\nss_late2 <- myGetSampleSizeSurvival(design_late2)\nnevents_late2 <- ceiling(nevent * c(j1, j2, 1))\n\n# assemble table\ntab_late <- data.frame(matrix(NA, ncol = 5, nrow = 4))\ncolnames(tab_late) <- c(\"\", \"quantity\", paste(\"info = \", \n                                              round(infofrac_late, 2)[1:2], sep = \"\"), \"final\")\ntab_late[c(1, 3), 1] <- paste(\"Design \", 1:2, sep = \"\")\ntab_late[c(1, 3), 2] <- \"MDD\"\ntab_late[c(2, 4), 2] <- \"local significance level\"\ntab_late[1, c(3, 5)] <- round(ss_late1$criticalValuesEffectScaleLower, 3)\ntab_late[2, c(3, 5)] <- format.pval(ss_late1$criticalValuesPValueScale, 3)\ntab_late[3, 3:5] <- round(ss_late2$criticalValuesEffectScaleLower, 3)\ntab_late[4, 3:5] <- format.pval(ss_late2$criticalValuesPValueScale, 3)\nkable(tab_late)\n\n\n\n\n\nquantity\ninfo = 0.67\ninfo = 0.85\nfinal\n\n\n\n\nDesign 1\nMDD\n0.731\nNA\n0.816\n\n\nNA\nlocal significance level\n0.0121\nNA\n0.0463\n\n\nDesign 2\nMDD\n0.733\n0.784\n0.813\n\n\nNA\nlocal significance level\n0.0121\n0.0265\n0.0404"
  },
  {
    "objectID": "trainings/20220913/RufibachWolbers_efficient_interims.html#futility",
    "href": "trainings/20220913/RufibachWolbers_efficient_interims.html#futility",
    "title": "Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact: Efficient use of futility and efficacy interim analyses in group-sequential designs",
    "section": "5.2 Futility",
    "text": "5.2 Futility\nSee backup of this file for the table from the slides."
  },
  {
    "objectID": "trainings/20220913/RufibachWolbers_efficient_interims.html#efficacy-1",
    "href": "trainings/20220913/RufibachWolbers_efficient_interims.html#efficacy-1",
    "title": "Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact: Efficient use of futility and efficacy interim analyses in group-sequential designs",
    "section": "6.1 Efficacy",
    "text": "6.1 Efficacy\n\n6.1.1 MDD\nMinimal detectable differences can easily be extracted from getSampleSizeSurvival objects:\n\nhrMDD <- as.vector(samplesize$criticalValuesEffectScale)\nhrMDD\n\n[1] 0.4625061 0.7375959 0.8209002"
  },
  {
    "objectID": "trainings/20220913/RufibachWolbers_efficient_interims.html#futility-1",
    "href": "trainings/20220913/RufibachWolbers_efficient_interims.html#futility-1",
    "title": "Advanced group-sequential and adaptive confirmatory clinical trial designs, with R practicals using rpact: Efficient use of futility and efficacy interim analyses in group-sequential designs",
    "section": "6.2 Futility",
    "text": "6.2 Futility\n\n6.2.1 Conditional power\nAs a first approach to determine an interim boundary for futility we reproduce the conditional power plot.\n\n# calculate condition power for interim HR ranging from 0.6 to 1.5\nhrs <- seq(0.6, 1.5, by = 0.01)\ncpower0 <- rep(NA,length(hrs))\ncpower <- cpower0\n\nfor (i in 1:length(hrs)){\n  \n  # generate dataset that contains result up to interim\n  results <- getDataset(\n    overallEvents = nevents_i1[1],\n    overallLogRanks = log(hrs[i]) / sqrt(kappa /nevents_i1[1]),\n    overallAllocationRatio = 1)\n  \n  # proper object that can be used by rpact\n  stageResults <- getStageResults(design, dataInput = results, directionUpper = FALSE)\n  \n  # compute conditional power under H1: theta_1 = 0.75\n  cpower[i] <- getConditionalPower(stageResults, nPlanned = diff(nevents_i1), \n                                   thetaH1 = hr)$conditionalPower[3]\n  \n  # compute conditional power under H0: theta_1 = 1\n  cpower0[i] <- getConditionalPower(stageResults, nPlanned = diff(nevents_i1), \n                                    thetaH1 = 1)$conditionalPower[3]\n}\n\n# what interim effect gives a conditional power of 20%?\ncondpow <- 0.2\nhr_int_cp <- min(hrs[cpower <= condpow])\nhr_int_cp\n\n[1] 1.28\n\n# p-value corresponding to that effect\n# z = log(hr_int_cp) / sqrt(kappa / D_int) --> p = P(N(0, 1) <= z) = 1 - Phi(|z|)\nz <- - log(hr_int_cp) / sqrt(kappa / nevents_i1[1])\np_int_cp <- 1 - pnorm(z)\np_int_cp\n\n[1] 0.9144856\n\n# check this p-value using rpact:\ndesign_cp <- getDesignGroupSequential(informationRates = infofrac,\n                                   typeOfDesign = \"asOF\", sided = 1, \n                                   alpha = alpha / 2, \n                                   beta = beta,\n                                   futilityBounds = c(z, -6), \n                                   bindingFutility = FALSE)\n\nsamplesize_cp <- myGetSampleSizeSurvival(design_cp)\nsamplesize_cp$futilityBoundsPValueScale[1, 1]\n\n[1] 0.9144856\n\n\nHere you can find more details on conditional power computations in rpact, and also how to switch between different scales, i.e. Z-score, hazard ratio, etc.\nAnd now plot the conditional power functions compute above:\n\npar(las = 1, mfrow = c(1, 1), mar = c(4.5, 4.5, 2, 1))\nplot(hrs, cpower, type = \"n\", xlab = expression(\"hazard ratio observed at interim\"),\n     ylab = \"conditional power\", ylim = c(0, 1), axes = FALSE, main = \n       expression(\"CP(\"*theta*\") after futility interim, under treatment effect \"*theta[1]*\" used for powering\"))\naxis(1, at = seq(0.6, 10, by = 0.1))\naxis(2, at = seq(0, 1, by = 0.1))\nabline(v = seq(0.6, 10, by = 0.1), h = seq(0, 1, by = 0.1), col = gray(0.9))\nsegments(0, condpow, hr_int_cp, condpow, lty = 2, col = 3, lwd = 3)\nsegments(hr_int_cp, 0, hr_int_cp, condpow, lty = 2, col = 3, lwd = 3)\nlines(hrs, cpower, col = 2, lwd = 4)\nlines(hrs, cpower0, col = 4, lwd = 4)\nlegend(0.9, 0.9, paste(\"hazard ratio after interim: \", c(hr, 1), sep = \"\"), \n       col = c(2, 4), lwd = 4, bty = \"n\")\n\n\n\n\n\n\n6.2.2 Stopping probabilities\nAn alternative way of defining an interim boundary for futility, especially when we use the pivotal Phase 3 with futility interim for the LIP, is to find a sweet spot by trading off false-decision probabilities at the interim. To this end, assume \\[\n  \\hat \\theta \\sim N(\\theta, \\sqrt{4 / d_1}).\n\\] We are then interested in the probability of continuation (or stopping, simply one minus) computed as: \\[\n  P_\\theta(\\hat \\theta \\le \\theta_\\text{int}) \\ = \\ \\Phi\\left(\\frac{\\theta_\\text{int} - \\theta}{\\sqrt{4 / d_1}}\\right),\n\\] where \\(\\theta_\\text{int}\\) is an interim boundary. Below the corresponding plot.\n\n# calculate stopping probabilities for interim HR ranging from 0.6 to 1.5\nhrs2 <- seq(0.6, 1.2, by = 0.01)\n\n# under H0\nstopprob0 <- 1 - pnorm((log(hrs2) - log(1)) / sqrt(kappa / nevents_i1[1]))\n\n# under H1\nstopprob1 <- 1 - pnorm((log(hrs2) - log(hr)) / sqrt(kappa / nevents_i1[1]))\n\n# interim boundary\nsp_bound <- 0.9\nfp <- max((1 - stopprob0)[hrs <= sp_bound]) \nfn <- min(stopprob1[hrs <= sp_bound])\nc(fp, fn)\n\n[1] 0.2795253 0.1560030\n\n\nWith these quantities, generate the plot.\n\npar(las = 1, mfrow = c(1, 1), mar = c(4.5, 4.5, 2, 4.5))\nplot(hrs2, stopprob0, type = \"n\", xlab = expression(\"interim boundary \"*hat(theta)[int]),\n     ylab = \"\", ylim = c(0, 1), axes = FALSE, main = \"interim stopping probabilities\")\naxis(1, at = seq(0.6, 10, by = 0.1))\nabline(v = seq(0.6, 10, by = 0.05), h = seq(0, 1, by = 0.1), col = gray(0.9))\nlegend(0.75, 1, paste(\"false-\", c(\"negative\", \"positive\"), \": hazard ratio: \", c(hr, 1), sep = \"\"), \n       col = c(2, 4), lwd = 4, bty = \"n\")\n\naxis(2, at = seq(0, 1, by = 0.1), labels = seq(0, 1, by = 0.1), col.axis = 2, line = 0.5)\nmtext(\"false-negative probability\", 2, line = 3, col = 2, las = 3)\naxis(4, at = seq(0, 1, by = 0.1), labels = seq(0, 1, by = 0.1), col.axis = 4, line = 0.5)\nmtext(\"false-positive probability\", 4, line = 3, col = 4, las = 3)\n\nlines(hrs2, stopprob1, col = 2, lwd = 4)\nlines(hrs2, 1 - stopprob0, col = 4, lwd = 4)\n\nsegments(min(hrs2), fn, sp_bound, fn, col = 2, lty = 2, lwd = 4)\nsegments(sp_bound, fn, sp_bound, 0, col = 2, lty = 2, lwd = 4)\n\nsegments(max(hrs2), fp, sp_bound, fp, col = 4, lty = 2, lwd = 4)\n\n\n\n\n\n\n6.2.3 \\(\\beta\\)-spending\nFinally, we illustrate how \\(\\beta-\\)-spending can be specified.\n\n# compare designs with no futility vs. a design with beta-spending\n\n# no futility\ndesign0 <- getDesignGroupSequential(sided = 1, alpha = alpha / 2, beta = beta,\n                                        informationRates = infofrac,\n                                        typeOfDesign = \"asOF\", bindingFutility = FALSE)\n\nWarning: 'bindingFutility' (FALSE) will be ignored\n\nsamplesize0 <- myGetSampleSizeSurvival(design0)\n\n# beta-spending, non-binding\ndesign_beta <- getDesignGroupSequential(sided = 1, alpha = alpha / 2, beta = beta,\n                                   informationRates = infofrac,\n                                   typeOfDesign = \"asOF\",\n                                   typeBetaSpending = \"bsOF\")\nsamplesize_beta <- myGetSampleSizeSurvival(design_beta)\nnevent_beta <- ceiling(samplesize_beta$maxNumberOfEvents)\n\n# generate table \ntab_beta <- data.frame(matrix(NA, nrow = 11, ncol = 3))\ncolnames(tab_beta) <- c(\"quantity\", \"no futility interim\", \"beta-spending\")\ntab_beta[, 1] <- c(\"number of events\", \n                   \"efficacy boundary 1 (effect size)\", \"efficacy boundary 1 (p-value)\",\n                   \"efficacy boundary 2 (effect size)\", \"efficacy boundary 2 (p-value)\",\n                   \"efficacy boundary 3 (effect size)\", \"efficacy boundary 3 (p-value)\",\n                   \"futility boundary 1 (effect size)\", \"futility boundary 1 (p-value)\",\n                   \"futility boundary 2 (effect size)\", \"futility boundary 2 (p-value)\")\n\ntab_beta[1, 2:3] <- ceiling(c(samplesize0$maxNumberOfEvents, samplesize_beta$maxNumberOfEvents))\ntab_beta[c(2, 4, 6), 2] <- round(samplesize0$criticalValuesEffectScale, 2)\ntab_beta[c(2, 4, 6), 3] <- round(samplesize_beta$criticalValuesEffectScale, 2)\n\ntab_beta[c(2, 4, 6) + 1, 2] <- round(samplesize0$criticalValuesPValueScale, 2)\ntab_beta[c(2, 4, 6) + 1, 3] <- round(samplesize_beta$criticalValuesPValueScale, 2)\n\ntab_beta[c(8, 10), 3] <- round(samplesize_beta$futilityBoundsEffectScale, 2)\ntab_beta[c(9, 11), 3] <- format.pval(samplesize_beta$futilityBoundsPValueScale, 2)\nkable(tab_beta, align = \"lrr\")\n\n\n\n\nquantity\nno futility interim\nbeta-spending\n\n\n\n\nnumber of events\n385.00\n419\n\n\nefficacy boundary 1 (effect size)\n0.48\n0.5\n\n\nefficacy boundary 1 (p-value)\n0.00\n0\n\n\nefficacy boundary 2 (effect size)\n0.73\n0.74\n\n\nefficacy boundary 2 (p-value)\n0.01\n0.01\n\n\nefficacy boundary 3 (effect size)\n0.82\n0.82\n\n\nefficacy boundary 3 (p-value)\n0.02\n0.02\n\n\nfutility boundary 1 (effect size)\nNA\n1.09\n\n\nfutility boundary 1 (p-value)\nNA\n0.68\n\n\nfutility boundary 2 (effect size)\nNA\n0.87\n\n\nfutility boundary 2 (p-value)\nNA\n0.12\n\n\n\n\n\nWe see that by adding two futility interims based on \\(\\beta\\)-spending, we increase the maximal number of events from 385 to `tab_beta[1, 3]’. To compute the power loss of adding the futilities, conservatively assuming they will be adhered to, we compute the power of the design with futilities using the number of events of the design without futilities.\n\n# power of beta-spending design at the number of events without beta-spending\npower <- getPowerSurvival(design_beta, \n                          maxNumberOfEvents = ceiling(samplesize0$maxNumberOfEvents),\n                          maxNumberOfSubjects = maxNumberOfSubjects,\n                          lambda2 = log(2) / m1, hazardRatio = hr,\n                          dropoutRate1 = dout1, dropoutRate2 = dout2, dropoutTime = douttime,\n                          accrualTime = accrualTime, accrualIntensity = accrualIntensity,\n                          directionUpper = FALSE)\n\n# power, as compared to the specified 80%\npower$overallReject\n\n[1] 0.7664614\n\n\n\n\n6.2.4 Power loss\nFinally, we specify the power loss of adding the various futility boundaries. To this, we proceed as follows:\n\nGenerate a set of trials with hazard ratio at interim and final, without any interim analysis stopping. The nice thing about rpact is that we can still add informationRates, i.e. we get a set of datasets that simulate trials until the prespecified maximal number of events, and these simulation datasets contain the hazard ratio estimates at the time when we have reached informationRates% of events.\nFrom these datasets we can then extract those that jump over the interim boundary and are significant at the end. Simply computing their proportion with respect to the number of simulations gives an estimate of the power.\n\n\n# generate a set of trials with HR at interim and final, without futility interim stopping\ndesign_sim <- getDesignGroupSequential(informationRates = infofrac[c(1, 3)],\n                                   sided = 1, alpha = alpha / 2, \n                                   beta = beta,\n                                   typeOfDesign = \"asUser\",\n                                   userAlphaSpending = c(0, 0.025),\n                                   futilityBounds = -6)\n\nChanged type of design to 'noEarlyEfficacy'\n\nsamplesize_sim <- myGetSampleSizeSurvival(design_sim)\n\nnsim <- 10 ^ 4\nsimulationResult <- \n  getSimulationSurvival(design_sim, \n                        lambda2 = log(2) / m1, hazardRatio = hr,\n                        dropoutRate1 = dout1, dropoutRate2 = dout2, dropoutTime = douttime,\n                        accrualTime = accrualTime, accrualIntensity = accrualIntensity,\n                        maxNumberOfSubjects = maxNumberOfSubjects,\n                        plannedEvents = as.vector(ceiling(samplesize_sim$eventsPerStage)),\n                        directionUpper = FALSE, maxNumberOfIterations = nsim,\n                        maxNumberOfRawDatasetsPerStage = 1, seed = 2)\n\n# get aggregate datasets from all simulation runs\naggregateSimulationData <- getData(simulationResult)\n\n# power taking futility into account is proportion of significant trials that ran to the end\n# use MDD from initial design with efficacy interim for final analysis\nhrs_interim <- subset(aggregateSimulationData, stageNumber == 1, select = \"hazardRatioEstimateLR\")\nhrs_final <- subset(aggregateSimulationData, stageNumber == 2, select = \"hazardRatioEstimateLR\")\n\n# now assess power loss for the two interim boundaries we discuss\n\n# futility interim analysis informal boundary of 1\nsurvive_interim <- (hrs_interim <= inform_bound)\nsurvive_final <- (hrs_final <= samplesize$criticalValuesEffectScale[3])\nloss_inform <- mean(survive_interim & survive_final)\n\n# futility interim analysis based on conditional power\nsurvive_interim <- (hrs_interim <= hr_int_cp)\nsurvive_final <- (hrs_final <= samplesize$criticalValuesEffectScale[3])\nloss_cp <- mean(survive_interim & survive_final)\n\n# stopping probabilities\nsurvive_interim <- (hrs_interim <= sp_bound)\nsurvive_final <- (hrs_final <= samplesize$criticalValuesEffectScale[3])\nloss_sp <- mean(survive_interim & survive_final)\n\n# power loss from beta-spending design\npl_spending <- power$overallReject\n\n# generate output table\ntab_pl <- data.frame(matrix(NA, ncol = 2, nrow = 4))\ncolnames(tab_pl) <- c(\"boundary\", \"power\")\nrownames(tab_pl) <- c(\"Design 1 (informal)\", \"Design 2 (conditional power)\", \n                      \"Design 3 (stopping probabilities)\", \"Design 4 (beta-spending)\")\ntab_pl[, 1] <- round(c(inform_bound, hr_int_cp, sp_bound, NA), 2)\ntab_pl[, 2] <- round(c(loss_inform, loss_cp, loss_sp, 1 - design_beta$beta), 2)\ntab_pl[tab_pl == \"NA\"] <- \"\"\nkable(tab_pl)\n\n\n\n\n\nboundary\npower\n\n\n\n\nDesign 1 (informal)\n1.00\n0.78\n\n\nDesign 2 (conditional power)\n1.28\n0.80\n\n\nDesign 3 (stopping probabilities)\n0.90\n0.72\n\n\nDesign 4 (beta-spending)\nNA\n0.80"
  },
  {
    "objectID": "talks/20191101/20191101_summary.html",
    "href": "talks/20191101/20191101_summary.html",
    "title": "BBS seminar 1st November 2019: Predictive modelling, machine learning, and causality",
    "section": "",
    "text": "On 1st November 2019, the BBS organized a seminar on Predictive modelling, machine learning, and causality with several eminent speakers. The full program including abstracts of all talks is available here."
  },
  {
    "objectID": "talks/20191101/20191101_summary.html#by-institution",
    "href": "talks/20191101/20191101_summary.html#by-institution",
    "title": "BBS seminar 1st November 2019: Predictive modelling, machine learning, and causality",
    "section": "4.1 By institution",
    "text": "4.1 By institution\n\n\n\n\n\n\n\n\n\nInstitutions with a frequency of at most 1:\nXcenda / Univ. of Neuchatel / Univ. of Lausanne / Univ. of Heidelberg / Univ. of Freiburg / Univ. de Cote d’Azur / Univ, of Lucerne / PWC / Merck Group / Medtronic / Livanova / Janssen / ISPM / Imito / HTWG Konstanz / Genentech / FHNW / Feinstein Institute / Erasmus Univ. / EAWEG / DFFZ Heidelberg / Corteva / Constat / ClinStat / Certara / CEB / Biogen / Bern Hochschule / BBS / AZ / Ava / Arete / AbbVie"
  },
  {
    "objectID": "talks/20191101/20191101_summary.html#by-sector-manually-categorized",
    "href": "talks/20191101/20191101_summary.html#by-sector-manually-categorized",
    "title": "BBS seminar 1st November 2019: Predictive modelling, machine learning, and causality",
    "section": "4.2 By sector (manually categorized)",
    "text": "4.2 By sector (manually categorized)"
  },
  {
    "objectID": "upcoming/20230412/20230412_analysis.html",
    "href": "upcoming/20230412/20230412_analysis.html",
    "title": "BBS seminar risk quantification: analysis of registrations",
    "section": "",
    "text": "Data status\nData as of 2023-04-12 at 09:50:46.\n\n\nRegistrations by type of institution\n\n\n\n\n\n\n\n\n\n\n\nRegistrations by background\n\n\n\n\n\n\n\n\n\n\n\nRegistrations by institution\n\n\n\n\n\n\n\n\n\n\n\nRegistrations of regulatory colleagues\n\n\n\n\n\n\n\n\n\n\n\nRegistrations by countries\n\n\n\n\n\n\n\n\n\n\n\nRegistrations by countries - map\n\n\n\n\n\n\n\n\n\n\n\nRegistrations by mode of attendance"
  }
]